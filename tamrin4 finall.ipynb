{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uSBa8YY4F0ZO"
      },
      "outputs": [],
      "source": [
        "##################### بررسی خوشه بندی های مختلف بر روی متن اول(Aggregation.txt)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bfTA9h4hGD6e"
      },
      "outputs": [],
      "source": [
        "###################با جابه جایی یکی از مراکز با نقاط داده k_median محاسبه"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrQm8jR9duvw",
        "outputId": "fe7a6a03-1109-4af4-8317-8e460a6e1da7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Purity: 0.8946700507614214\n",
            "F-measure: 0.0761402186204297\n",
            "Execution time: 0.24234461784362793\n",
            "Dataset with new labels:\n",
            "      x1     x2  labels  new_labels\n",
            "0  15.55  28.65       2           2\n",
            "1  14.90  27.55       2           2\n",
            "2  14.45  28.35       2           2\n",
            "3  14.15  28.80       2           2\n",
            "4  13.75  28.05       2           2\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import requests\n",
        "from io import StringIO\n",
        "import time\n",
        "# بارگذاری داده‌ها\n",
        "link= [\"http://cs.joensuu.fi/sipu/datasets/Aggregation.txt\"]\n",
        "numbers = []\n",
        "read = requests.get(link[0])\n",
        "content = read.text\n",
        "data = StringIO(content)\n",
        "df = pd.read_csv(data, sep=\"\\s+\", header=None, names=[\"x1\", \"x2\", \"labels\"])\n",
        "numbers.append(df)\n",
        "dataset = pd.concat(numbers, ignore_index=True)\n",
        "# تعریف تابع k_median\n",
        "def k_median(data, k, max_iterations=200):\n",
        "    centers = data.sample(n=k, random_state=42).to_numpy()\n",
        "    for _ in range(max_iterations):\n",
        "        distances = np.linalg.norm(data.to_numpy()[:, np.newaxis] - centers, axis=2)\n",
        "        labels = np.argmin(distances, axis=1)\n",
        "        new_centers = np.array([np.median(data[labels == i].to_numpy(), axis=0) for i in range(k)])\n",
        "        if np.all(centers == new_centers):\n",
        "            break\n",
        "        centers = new_centers\n",
        "    return centers, labels\n",
        "k=7\n",
        "# زمان شروع\n",
        "start_time = time.time()\n",
        "centers, labels = k_median(dataset[[\"x1\", \"x2\"]], k)\n",
        "labels += 1\n",
        "dataset[\"new_labels\"] = labels\n",
        "# تعریف purity\n",
        "def purity_score(dataset):\n",
        "    total = 0\n",
        "    for i in range(k):\n",
        "        cluster_labels = dataset[dataset[\"new_labels\"] == (i + 1)][\"labels\"]\n",
        "        if len(cluster_labels) > 0:\n",
        "            most_common = Counter(cluster_labels).most_common(1)[0][1]\n",
        "            total += most_common\n",
        "    return total / len(dataset)\n",
        "purity = purity_score(dataset)\n",
        "# تعریف f_measure\n",
        "def f_measure(dataset):\n",
        "    precision_list = []\n",
        "    recall_list = []\n",
        "    for i in range(k):\n",
        "        true_labels = dataset[\"labels\"].to_numpy()\n",
        "        predicted_labels = (dataset[\"new_labels\"] == (i + 1)).to_numpy()\n",
        "        tp = np.sum((true_labels[predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fp = np.sum((true_labels[predicted_labels] != dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fn = np.sum((true_labels[~predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        precision_list.append(precision)\n",
        "        recall_list.append(recall)\n",
        "    precision = np.mean(precision_list)\n",
        "    recall = np.mean(recall_list)\n",
        "    f_measure_value = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    return f_measure_value\n",
        "f_measure_value = f_measure(dataset)\n",
        "#زمان پابان\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(\"Purity:\", purity)\n",
        "print(\"F-measure:\", f_measure_value)\n",
        "print(\"Execution time:\", execution_time)\n",
        "print(\"Dataset with new labels:\")\n",
        "print(dataset[[\"x1\", \"x2\", \"labels\", \"new_labels\"]].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cRXeedxyJGHj"
      },
      "outputs": [],
      "source": [
        "###################### با جابه جایی دو تا از مراکز با نقاط داده k_median محاسبه"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYMuz04ET4XO",
        "outputId": "a0c00b9b-cef6-4eee-c4f0-707723a8353e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Purity: 0.8946700507614214\n",
            "F-measure: 0.0761402186204297\n",
            "Execution time: 0.8209073543548584\n",
            "Dataset with new labels:\n",
            "      x1     x2  labels  new_labels\n",
            "0  15.55  28.65       2           2\n",
            "1  14.90  27.55       2           2\n",
            "2  14.45  28.35       2           2\n",
            "3  14.15  28.80       2           2\n",
            "4  13.75  28.05       2           2\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import requests\n",
        "from io import StringIO\n",
        "import time\n",
        "# بارگذاری داده‌ها\n",
        "link = [\"http://cs.joensuu.fi/sipu/datasets/Aggregation.txt\"]\n",
        "numbers = []\n",
        "read = requests.get(link[0])\n",
        "content = read.text\n",
        "data = StringIO(content)\n",
        "df = pd.read_csv(data, sep=\"\\s+\", header=None, names=[\"x1\", \"x2\", \"labels\"])\n",
        "numbers.append(df)\n",
        "dataset = pd.concat(numbers, ignore_index=True)\n",
        "# تعریف تابع k_median\n",
        "def k_median(data, k, max_iterations=200):\n",
        "    centers = data.sample(n=k, random_state=42).to_numpy()\n",
        "    for _ in range(max_iterations):\n",
        "        distances = np.linalg.norm(data.to_numpy()[:, np.newaxis] - centers, axis=2)\n",
        "        labels = np.argmin(distances, axis=1)\n",
        "        for i in range(0, k, 2):\n",
        "            if i < k and np.any(labels == i):\n",
        "                centers[i] = data.iloc[labels == i].median(axis=0).to_numpy()\n",
        "            if i + 1 < k and np.any(labels == (i + 1)):\n",
        "                centers[i + 1] = data.iloc[labels == (i + 1)].median(axis=0).to_numpy()\n",
        "        if np.allclose(centers, centers.mean(axis=0)):\n",
        "            break\n",
        "    return centers, labels\n",
        "k = 7\n",
        "# زمان شروع\n",
        "start_time = time.time()\n",
        "centers, labels = k_median(dataset[[\"x1\", \"x2\"]], k)\n",
        "labels += 1\n",
        "dataset[\"new_labels\"] = labels\n",
        "# تعریف purity\n",
        "def purity_score(dataset):\n",
        "    total = 0\n",
        "    for i in range(k):\n",
        "        cluster_labels = dataset[dataset[\"new_labels\"] == (i + 1)][\"labels\"]\n",
        "        if len(cluster_labels) > 0:\n",
        "            most_common = Counter(cluster_labels).most_common(1)[0][1]\n",
        "            total += most_common\n",
        "    return total / len(dataset)\n",
        "purity = purity_score(dataset)\n",
        "# تعریف f_measure\n",
        "def f_measure(dataset):\n",
        "    precision_list = []\n",
        "    recall_list = []\n",
        "    for i in range(k):\n",
        "        true_labels = dataset[\"labels\"].to_numpy()\n",
        "        predicted_labels = (dataset[\"new_labels\"] == (i + 1)).to_numpy()\n",
        "        tp = np.sum((true_labels[predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fp = np.sum((true_labels[predicted_labels] != dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fn = np.sum((true_labels[~predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        precision_list.append(precision)\n",
        "        recall_list.append(recall)\n",
        "    precision = np.mean(precision_list)\n",
        "    recall = np.mean(recall_list)\n",
        "    f_measure_value = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    return f_measure_value\n",
        "f_measure_value = f_measure(dataset)\n",
        "# زمان پایان\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(\"Purity:\", purity)\n",
        "print(\"F-measure:\", f_measure_value)\n",
        "print(\"Execution time:\", execution_time)\n",
        "print(\"Dataset with new labels:\")\n",
        "print(dataset[[\"x1\", \"x2\", \"labels\", \"new_labels\"]].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fTqPmaokeF3v"
      },
      "outputs": [],
      "source": [
        "############## با کرنل دو جمله ای k_median محاسبه"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRAn9T-2oKyO",
        "outputId": "8a0002ce-8a50-4c2c-84fe-3a721b7eb386"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Purity: 0.47588832487309646\n",
            "F-measure: 0.08567743520452033\n",
            "Execution time: 1.4684431552886963\n",
            "Dataset with new labels:\n",
            "      x1     x2  labels  new_labels\n",
            "0  15.55  28.65       2           3\n",
            "1  14.90  27.55       2           3\n",
            "2  14.45  28.35       2           3\n",
            "3  14.15  28.80       2           3\n",
            "4  13.75  28.05       2           3\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import requests\n",
        "from io import StringIO\n",
        "import time\n",
        "from sklearn.metrics.pairwise import polynomial_kernel\n",
        "\n",
        "# بارگذاری داده‌ها\n",
        "link = [\"http://cs.joensuu.fi/sipu/datasets/Aggregation.txt\"]\n",
        "numbers = []\n",
        "read = requests.get(link[0])\n",
        "content = read.text\n",
        "data = StringIO(content)\n",
        "df = pd.read_csv(data, sep=\"\\s+\", header=None, names=[\"x1\", \"x2\", \"labels\"])\n",
        "numbers.append(df)\n",
        "dataset = pd.concat(numbers, ignore_index=True)\n",
        "# تعریف تابع k_median_polynomial\n",
        "def k_median_polynomial(data, k, max_iterations=200):\n",
        "    centers = data.sample(n=k, random_state=42).to_numpy()\n",
        "    for _ in range(max_iterations):\n",
        "        similarity_matrix = polynomial_kernel(data, centers)\n",
        "        labels = np.argmax(similarity_matrix, axis=1)\n",
        "        new_centers = []\n",
        "        for i in range(k):\n",
        "            cluster_points = data.iloc[np.where(labels == i)]\n",
        "            if len(cluster_points) > 0:\n",
        "                new_centers.append(cluster_points.median(axis=0).to_numpy())\n",
        "            else:\n",
        "                new_centers.append(data.sample(n=1, random_state=42).to_numpy().flatten())\n",
        "        new_centers = np.array(new_centers)\n",
        "        if np.allclose(centers, new_centers, atol=1e-4):\n",
        "            break\n",
        "        centers = new_centers\n",
        "    return centers, labels\n",
        "\n",
        "k = 7\n",
        "# زمان شروع\n",
        "start_time = time.time()\n",
        "centers, labels = k_median_polynomial(dataset[[\"x1\", \"x2\"]], k)\n",
        "labels += 1\n",
        "dataset[\"new_labels\"] = labels\n",
        "# تعریف purity\n",
        "def purity_score(dataset):\n",
        "    total = 0\n",
        "    for i in range(k):\n",
        "        cluster_labels = dataset[dataset[\"new_labels\"] == (i + 1)][\"labels\"]\n",
        "        if len(cluster_labels) > 0:\n",
        "            most_common = Counter(cluster_labels).most_common(1)[0][1]\n",
        "            total += most_common\n",
        "    return total / len(dataset)\n",
        "\n",
        "purity = purity_score(dataset)\n",
        "\n",
        "# تعریف f_measure\n",
        "def f_measure(dataset):\n",
        "    precision_list = []\n",
        "    recall_list = []\n",
        "    for i in range(k):\n",
        "        true_labels = dataset[\"labels\"].to_numpy()\n",
        "        predicted_labels = (dataset[\"new_labels\"] == (i + 1)).to_numpy()\n",
        "        tp = np.sum((true_labels[predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fp = np.sum((true_labels[predicted_labels] != dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fn = np.sum((true_labels[~predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        precision_list.append(precision)\n",
        "        recall_list.append(recall)\n",
        "\n",
        "    precision = np.mean(precision_list)\n",
        "    recall = np.mean(recall_list)\n",
        "    f_measure_value = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    return f_measure_value\n",
        "\n",
        "f_measure_value = f_measure(dataset)\n",
        "\n",
        "# زمان پایان\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "\n",
        "print(\"Purity:\", purity)\n",
        "print(\"F-measure:\", f_measure_value)\n",
        "print(\"Execution time:\", execution_time)\n",
        "print(\"Dataset with new labels:\")\n",
        "print(dataset[[\"x1\", \"x2\", \"labels\", \"new_labels\"]].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kEtAYy23pGHv"
      },
      "outputs": [],
      "source": [
        "##############    با کرنل گوسی k_median محاسبه"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "leCoVDWppbH2",
        "outputId": "dde3b148-9441-46f6-aa5e-8218fd93c377"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Purity: 0.8946700507614214\n",
            "F-measure: 0.0761402186204297\n",
            "Execution time: 0.04657554626464844\n",
            "Dataset with new labels:\n",
            "      x1     x2  labels  new_labels\n",
            "0  15.55  28.65       2           2\n",
            "1  14.90  27.55       2           2\n",
            "2  14.45  28.35       2           2\n",
            "3  14.15  28.80       2           2\n",
            "4  13.75  28.05       2           2\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import requests\n",
        "from io import StringIO\n",
        "import time\n",
        "from sklearn.metrics.pairwise import rbf_kernel\n",
        "# بارگذاری داده‌ها\n",
        "link = [\"http://cs.joensuu.fi/sipu/datasets/Aggregation.txt\"]\n",
        "numbers = []\n",
        "read = requests.get(link[0])\n",
        "content = read.text\n",
        "data = StringIO(content)\n",
        "df = pd.read_csv(data, sep=\"\\s+\", header=None, names=[\"x1\", \"x2\", \"labels\"])\n",
        "numbers.append(df)\n",
        "dataset = pd.concat(numbers, ignore_index=True)\n",
        "# تعریف تابع k_median\n",
        "def k_median_rbf(data, k, max_iterations=100, gamma=0.5):\n",
        "    centers = data.sample(n=k, random_state=42).to_numpy()\n",
        "    for _ in range(max_iterations):\n",
        "        similarity_matrix = rbf_kernel(data, centers, gamma=gamma)\n",
        "        labels = np.argmax(similarity_matrix, axis=1)\n",
        "        new_centers = np.array([data[labels == i].median(axis=0) for i in range(k)])\n",
        "        if np.allclose(centers, new_centers):\n",
        "            break\n",
        "        centers = new_centers\n",
        "    return centers, labels\n",
        "k = 7\n",
        "# زمان شروع\n",
        "start_time = time.time()\n",
        "centers, labels = k_median(dataset[[\"x1\", \"x2\"]], k)\n",
        "labels += 1\n",
        "dataset[\"new_labels\"] = labels\n",
        "# تعریف purity\n",
        "def purity_score(dataset):\n",
        "    total = 0\n",
        "    for i in range(k):\n",
        "        cluster_labels = dataset[dataset[\"new_labels\"] == (i + 1)][\"labels\"]\n",
        "        if len(cluster_labels) > 0:\n",
        "            most_common = Counter(cluster_labels).most_common(1)[0][1]\n",
        "            total += most_common\n",
        "    return total / len(dataset)\n",
        "purity = purity_score(dataset)\n",
        "# تعریف f_measure\n",
        "def f_measure(dataset):\n",
        "    precision_list = []\n",
        "    recall_list = []\n",
        "    for i in range(k):\n",
        "        true_labels = dataset[\"labels\"].to_numpy()\n",
        "        predicted_labels = (dataset[\"new_labels\"] == (i + 1)).to_numpy()\n",
        "        tp = np.sum((true_labels[predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fp = np.sum((true_labels[predicted_labels] != dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fn = np.sum((true_labels[~predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        precision_list.append(precision)\n",
        "        recall_list.append(recall)\n",
        "        precision = np.mean(precision_list)\n",
        "    recall = np.mean(recall_list)\n",
        "    f_measure_value = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    return f_measure_value\n",
        "f_measure_value = f_measure(dataset)\n",
        "# زمان پایان\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(\"Purity:\", purity)\n",
        "print(\"F-measure:\", f_measure_value)\n",
        "print(\"Execution time:\", execution_time)\n",
        "print(\"Dataset with new labels:\")\n",
        "print(dataset[[\"x1\", \"x2\", \"labels\", \"new_labels\"]].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Asr7emU17mpc"
      },
      "outputs": [],
      "source": [
        "#################         الگوریتم خوشه بندی طیفی"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQanz6Vf7uDL",
        "outputId": "990ad342-b6d6-4a54-fbd0-9ed03e41a9ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Purity: 0.9543147208121827\n",
            "F-measure: 0.3281789783088576\n",
            "Execution time: 0.24765944480895996\n",
            "Dataset with new labels:\n",
            "      x1     x2  labels  new_labels\n",
            "0  15.55  28.65       2           7\n",
            "1  14.90  27.55       2           7\n",
            "2  14.45  28.35       2           7\n",
            "3  14.15  28.80       2           7\n",
            "4  13.75  28.05       2           7\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import requests\n",
        "from io import StringIO\n",
        "import time\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "from sklearn.cluster import KMeans\n",
        "from scipy.sparse.linalg import eigsh\n",
        "# بارگذاری داده‌ها\n",
        "link = [\"http://cs.joensuu.fi/sipu/datasets/Aggregation.txt\"]\n",
        "numbers = []\n",
        "read = requests.get(link[0])\n",
        "content = read.text\n",
        "data = StringIO(content)\n",
        "df = pd.read_csv(data, sep=\"\\s+\", header=None, names=[\"x1\", \"x2\", \"labels\"])\n",
        "numbers.append(df)\n",
        "dataset = pd.concat(numbers, ignore_index=True)\n",
        "# تابع خوشه‌بندی طیفی\n",
        "def spectral_clustering(data, k):\n",
        "    adjacency_matrix = kneighbors_graph(data, n_neighbors=l, mode='connectivity', include_self=False).toarray()\n",
        "    weight_matrix = adjacency_matrix * adjacency_matrix.T\n",
        "    degree_matrix = np.diag(weight_matrix.sum(axis=1))\n",
        "    laplacian_matrix = degree_matrix - weight_matrix\n",
        "    eigvals, eigvecs = eigsh(laplacian_matrix, k=l, which='SM')\n",
        "    kmeans = KMeans(n_clusters=k)\n",
        "    labels = kmeans.fit_predict(eigvecs)\n",
        "    return labels\n",
        "l=9\n",
        "k = 7\n",
        "# زمان شروع\n",
        "start_time = time.time()\n",
        "labels = spectral_clustering(dataset[[\"x1\", \"x2\"]], k)\n",
        "labels += 1\n",
        "dataset[\"new_labels\"] = labels\n",
        "# تعریف purity\n",
        "def purity_score(dataset):\n",
        "    total = 0\n",
        "    for i in range(k):\n",
        "        cluster_labels = dataset[dataset[\"new_labels\"] == (i + 1)][\"labels\"]\n",
        "        if len(cluster_labels) > 0:\n",
        "            most_common = Counter(cluster_labels).most_common(1)[0][1]\n",
        "            total += most_common\n",
        "    return total / len(dataset)\n",
        "purity = purity_score(dataset)\n",
        "# تعریف f_measure\n",
        "def f_measure(dataset):\n",
        "    precision_list = []\n",
        "    recall_list = []\n",
        "    for i in range(k):\n",
        "        true_labels = dataset[\"labels\"].to_numpy()\n",
        "        predicted_labels = (dataset[\"new_labels\"] == (i + 1)).to_numpy()\n",
        "        tp = np.sum((true_labels[predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fp = np.sum((true_labels[predicted_labels] != dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fn = np.sum((true_labels[~predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        precision_list.append(precision)\n",
        "        recall_list.append(recall)\n",
        "    precision = np.mean(precision_list)\n",
        "    recall = np.mean(recall_list)\n",
        "    f_measure_value = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    return f_measure_value\n",
        "f_measure_value = f_measure(dataset)\n",
        "# زمان پایان\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(\"Purity:\", purity)\n",
        "print(\"F-measure:\", f_measure_value)\n",
        "print(\"Execution time:\", execution_time)\n",
        "print(\"Dataset with new labels:\")\n",
        "print(dataset[[\"x1\", \"x2\", \"labels\", \"new_labels\"]].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "njO2F8F8-2GH"
      },
      "outputs": [],
      "source": [
        "###############مقایسه الگوریتم ها"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t14jb_cC5fgh",
        "outputId": "996bc527-df04-445f-e2e0-8e220e1289f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "مقایسه نتایج الگوریتم‌ها:\n",
            "             Algorithm    Purity  F-measure  Execution Time\n",
            "0             k_median  0.894670   0.076140        0.024602\n",
            "1            k_median2  0.894670   0.076140        0.476010\n",
            "2  spectral_clustering  0.897208   0.209552        0.249812\n",
            "3  k_median_polynomial  0.475888   0.085677        0.905868\n",
            "4         k_median_rbf  0.894670   0.076140        0.043948\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import requests\n",
        "from io import StringIO\n",
        "import time\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics.pairwise import polynomial_kernel, rbf_kernel\n",
        "from scipy.sparse.linalg import eigsh\n",
        "\n",
        "# بارگذاری داده‌ها\n",
        "link = [\"http://cs.joensuu.fi/sipu/datasets/Aggregation.txt\"]\n",
        "numbers = []\n",
        "read = requests.get(link[0])\n",
        "content = read.text\n",
        "data = StringIO(content)\n",
        "df = pd.read_csv(data, sep=\"\\s+\", header=None, names=[\"x1\", \"x2\", \"labels\"])\n",
        "numbers.append(df)\n",
        "dataset = pd.concat(numbers, ignore_index=True)\n",
        "k=7\n",
        "l=9\n",
        "\n",
        "# تعریف تابع k_median\n",
        "def k_median(data, k, max_iterations=200):\n",
        "    centers = data.sample(n=k, random_state=42).to_numpy()\n",
        "    for _ in range(max_iterations):\n",
        "        distances = np.linalg.norm(data.to_numpy()[:, np.newaxis] - centers, axis=2)\n",
        "        labels = np.argmin(distances, axis=1)\n",
        "        new_centers = np.array([np.median(data[labels == i].to_numpy(), axis=0) for i in range(k)])\n",
        "        if np.all(centers == new_centers):\n",
        "            break\n",
        "        centers = new_centers\n",
        "    return centers, labels\n",
        "\n",
        "# نسخه دوم k_median (با فواصل مشابه نسخه اول شما)\n",
        "def k_median2(data, k, max_iterations=200):\n",
        "    centers = data.sample(n=k, random_state=42).to_numpy()\n",
        "    for _ in range(max_iterations):\n",
        "        distances = np.linalg.norm(data.to_numpy()[:, np.newaxis] - centers, axis=2)\n",
        "        labels = np.argmin(distances, axis=1)\n",
        "        for i in range(0, k, 2):\n",
        "            if i < k and np.any(labels == i):\n",
        "                centers[i] = data.iloc[labels == i].median(axis=0).to_numpy()\n",
        "            if i + 1 < k and np.any(labels == (i + 1)):\n",
        "                centers[i + 1] = data.iloc[labels == (i + 1)].median(axis=0).to_numpy()\n",
        "        if np.allclose(centers, centers.mean(axis=0)):\n",
        "            break\n",
        "    return centers, labels\n",
        "\n",
        "# K-Median با کرنل چندجمله‌ای\n",
        "def k_median_polynomial(data, k, max_iterations=200):\n",
        "    centers = data.sample(n=k, random_state=42).to_numpy()\n",
        "    for _ in range(max_iterations):\n",
        "        similarity_matrix = polynomial_kernel(data, centers)\n",
        "        labels = np.argmax(similarity_matrix, axis=1)\n",
        "        new_centers = []\n",
        "        for i in range(k):\n",
        "            cluster_points = data.iloc[np.where(labels == i)]\n",
        "            if len(cluster_points) > 0:\n",
        "                new_centers.append(cluster_points.median(axis=0).to_numpy())\n",
        "            else:\n",
        "                new_centers.append(data.sample(n=1, random_state=42).to_numpy().flatten())\n",
        "        new_centers = np.array(new_centers)\n",
        "        if np.allclose(centers, new_centers, atol=1e-4):\n",
        "            break\n",
        "        centers = new_centers\n",
        "    return centers, labels\n",
        "\n",
        "# K-Median با کرنل گوسی\n",
        "def k_median_rbf(data, k, max_iterations=100, gamma=0.5):\n",
        "    centers = data.sample(n=k, random_state=42).to_numpy()\n",
        "    for _ in range(max_iterations):\n",
        "        similarity_matrix = rbf_kernel(data, centers, gamma=gamma)\n",
        "        labels = np.argmax(similarity_matrix, axis=1)\n",
        "        new_centers = np.array([data[labels == i].median(axis=0) for i in range(k)])\n",
        "        if np.allclose(centers, new_centers):\n",
        "            break\n",
        "        centers = new_centers\n",
        "    return centers, labels\n",
        "\n",
        "# خوشه‌بندی طیفی\n",
        "def spectral_clustering(data, k):\n",
        "    adjacency_matrix = kneighbors_graph(data, n_neighbors=l, mode='connectivity', include_self=False).toarray()\n",
        "    weight_matrix = adjacency_matrix * adjacency_matrix.T\n",
        "    degree_matrix = np.diag(weight_matrix.sum(axis=1))\n",
        "    laplacian_matrix = degree_matrix - weight_matrix\n",
        "    eigvals, eigvecs = eigsh(laplacian_matrix, k=l, which='SM')\n",
        "    kmeans = KMeans(n_clusters=k)\n",
        "    labels = kmeans.fit_predict(eigvecs)\n",
        "    return labels\n",
        "\n",
        "# محاسبه Purity\n",
        "def purity_score(dataset):\n",
        "    total = 0\n",
        "    for i in range(k):\n",
        "        cluster_labels = dataset[dataset[\"new_labels\"] == (i + 1)][\"labels\"]\n",
        "        if len(cluster_labels) > 0:\n",
        "            most_common = Counter(cluster_labels).most_common(1)[0][1]\n",
        "            total += most_common\n",
        "    return total / len(dataset)\n",
        "\n",
        "# محاسبه F-measure\n",
        "def f_measure(dataset):\n",
        "    precision_list = []\n",
        "    recall_list = []\n",
        "    for i in range(k):\n",
        "        true_labels = dataset[\"labels\"].to_numpy()\n",
        "        predicted_labels = (dataset[\"new_labels\"] == (i + 1)).to_numpy()\n",
        "        tp = np.sum((true_labels[predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fp = np.sum((true_labels[predicted_labels] != dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fn = np.sum((true_labels[~predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        precision_list.append(precision)\n",
        "        recall_list.append(recall)\n",
        "    precision = np.mean(precision_list)\n",
        "    recall = np.mean(recall_list)\n",
        "    f_measure_value = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    return f_measure_value\n",
        "\n",
        "# اجرای الگوریتم‌ها\n",
        "def run_algorithm(algorithm, dataset, k):\n",
        "    start_time = time.time()\n",
        "    if algorithm == spectral_clustering:\n",
        "        labels = algorithm(dataset[[\"x1\", \"x2\"]], k)\n",
        "        centers = None\n",
        "    else:\n",
        "        centers, labels = algorithm(dataset[[\"x1\", \"x2\"]], k)\n",
        "    labels += 1\n",
        "    dataset[\"new_labels\"] = labels\n",
        "    purity = purity_score(dataset)\n",
        "    f_measure_value = f_measure(dataset)\n",
        "    end_time = time.time()\n",
        "    execution_time = end_time - start_time\n",
        "    return purity, f_measure_value, execution_time, dataset\n",
        "\n",
        "# نتایج\n",
        "results = []\n",
        "algorithms = [k_median, k_median2, spectral_clustering, k_median_polynomial, k_median_rbf]\n",
        "for algorithm in algorithms:\n",
        "    purity, f_measure_value, execution_time, dataset_with_labels = run_algorithm(algorithm, dataset.copy(), k)\n",
        "    results.append({\n",
        "        \"Algorithm\": algorithm.__name__,\n",
        "        \"Purity\": purity,\n",
        "        \"F-measure\": f_measure_value,\n",
        "        \"Execution Time\": execution_time\n",
        "    })\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "# مقایسه نتایج\n",
        "print(\"مقایسه نتایج الگوریتم‌ها:\")\n",
        "print(results_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p8lp1Ue--Xr8"
      },
      "outputs": [],
      "source": [
        "############## مشاهدات برروی متن اول به این شکل است که خوشه بندی طیفی در این مثال از هر نظر بهتر عمل میکند"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wyN3gHqv-k9q"
      },
      "outputs": [],
      "source": [
        "########################## انجام الگوریتم ها در تکست دوم(Compound.txt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hBIdQCRiBVqS"
      },
      "outputs": [],
      "source": [
        "###################با جابه جایی یکی از مراکز با نقاط داده k_median محاسبه"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZ_ErAr6-1uq",
        "outputId": "a00904de-1236-46a6-ae5c-cd9b32febce3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Purity: 0.87468671679198\n",
            "F-measure: 0.1647940074906367\n",
            "Execution time: 0.04902195930480957\n",
            "Dataset with new labels:\n",
            "      x1     x2  labels  new_labels\n",
            "0  26.75  22.15       1           5\n",
            "1  29.80  22.15       1           5\n",
            "2  31.55  21.10       1           5\n",
            "3  27.70  20.85       1           5\n",
            "4  29.90  19.95       1           5\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import requests\n",
        "from io import StringIO\n",
        "import time\n",
        "# بارگذاری داده‌ها\n",
        "link= [\"http://cs.joensuu.fi/sipu/datasets/Compound.txt\"]\n",
        "numbers = []\n",
        "read = requests.get(link[0])\n",
        "content = read.text\n",
        "data = StringIO(content)\n",
        "df = pd.read_csv(data, sep=\"\\s+\", header=None, names=[\"x1\", \"x2\", \"labels\"])\n",
        "numbers.append(df)\n",
        "dataset = pd.concat(numbers, ignore_index=True)\n",
        "# تعریف تابع k_media\n",
        "def k_median(data, k, max_iterations=200):\n",
        "    centers = data.sample(n=k, random_state=42).to_numpy()\n",
        "    for _ in range(max_iterations):\n",
        "        distances = np.linalg.norm(data.to_numpy()[:, np.newaxis] - centers, axis=2)\n",
        "        labels = np.argmin(distances, axis=1)\n",
        "        new_centers = np.array([np.median(data[labels == i].to_numpy(), axis=0) for i in range(k)])\n",
        "        if np.all(centers == new_centers):\n",
        "            break\n",
        "        centers = new_centers\n",
        "    return centers, labels\n",
        "k=6\n",
        "# زمان شروع\n",
        "start_time = time.time()\n",
        "centers, labels = k_median(dataset[[\"x1\", \"x2\"]], k)\n",
        "labels += 1\n",
        "dataset[\"new_labels\"] = labels\n",
        "# تعریف purity\n",
        "def purity_score(dataset):\n",
        "    total = 0\n",
        "    for i in range(k):\n",
        "        cluster_labels = dataset[dataset[\"new_labels\"] == (i + 1)][\"labels\"]\n",
        "        if len(cluster_labels) > 0:\n",
        "            most_common = Counter(cluster_labels).most_common(1)[0][1]\n",
        "            total += most_common\n",
        "    return total / len(dataset)\n",
        "purity = purity_score(dataset)\n",
        "# تعریف f_measure\n",
        "def f_measure(dataset):\n",
        "    precision_list = []\n",
        "    recall_list = []\n",
        "    for i in range(k):\n",
        "        true_labels = dataset[\"labels\"].to_numpy()\n",
        "        predicted_labels = (dataset[\"new_labels\"] == (i + 1)).to_numpy()\n",
        "        tp = np.sum((true_labels[predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fp = np.sum((true_labels[predicted_labels] != dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fn = np.sum((true_labels[~predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        precision_list.append(precision)\n",
        "        recall_list.append(recall)\n",
        "    precision = np.mean(precision_list)\n",
        "    recall = np.mean(recall_list)\n",
        "    f_measure_value = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    return f_measure_value\n",
        "f_measure_value = f_measure(dataset)\n",
        "#زمان پابان\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(\"Purity:\", purity)\n",
        "print(\"F-measure:\", f_measure_value)\n",
        "print(\"Execution time:\", execution_time)\n",
        "print(\"Dataset with new labels:\")\n",
        "print(dataset[[\"x1\", \"x2\", \"labels\", \"new_labels\"]].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8s4XY9w9Bnfc"
      },
      "outputs": [],
      "source": [
        "###################### با جابه جایی دو تا از مراکز با نقاط داده k_median محاسبه"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEOdde6kBFnk",
        "outputId": "b03fc2f3-b596-4d69-cdf8-072508240f1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Purity: 0.87468671679198\n",
            "F-measure: 0.1647940074906367\n",
            "Execution time: 1.2920897006988525\n",
            "Dataset with new labels:\n",
            "      x1     x2  labels  new_labels\n",
            "0  26.75  22.15       1           5\n",
            "1  29.80  22.15       1           5\n",
            "2  31.55  21.10       1           5\n",
            "3  27.70  20.85       1           5\n",
            "4  29.90  19.95       1           5\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import requests\n",
        "from io import StringIO\n",
        "import time\n",
        "# بارگذاری داده‌ها\n",
        "link = [\"http://cs.joensuu.fi/sipu/datasets/Compound.txt\"]\n",
        "numbers = []\n",
        "read = requests.get(link[0])\n",
        "content = read.text\n",
        "data = StringIO(content)\n",
        "df = pd.read_csv(data, sep=\"\\s+\", header=None, names=[\"x1\", \"x2\", \"labels\"])\n",
        "numbers.append(df)\n",
        "dataset = pd.concat(numbers, ignore_index=True)\n",
        "# تعریف تابع k_median\n",
        "def k_median(data, k, max_iterations=200):\n",
        "    centers = data.sample(n=k, random_state=42).to_numpy()\n",
        "    for _ in range(max_iterations):\n",
        "        distances = np.linalg.norm(data.to_numpy()[:, np.newaxis] - centers, axis=2)\n",
        "        labels = np.argmin(distances, axis=1)\n",
        "        for i in range(0, k, 2):\n",
        "            if i < k and np.any(labels == i):\n",
        "                centers[i] = data.iloc[labels == i].median(axis=0).to_numpy()\n",
        "            if i + 1 < k and np.any(labels == (i + 1)):\n",
        "                centers[i + 1] = data.iloc[labels == (i + 1)].median(axis=0).to_numpy()\n",
        "        if np.allclose(centers, centers.mean(axis=0)):\n",
        "            break\n",
        "    return centers, labels\n",
        "k =6\n",
        "# زمان شروع\n",
        "start_time = time.time()\n",
        "centers, labels = k_median(dataset[[\"x1\", \"x2\"]], k)\n",
        "labels += 1\n",
        "dataset[\"new_labels\"] = labels\n",
        "# تعریف purity\n",
        "def purity_score(dataset):\n",
        "    total = 0\n",
        "    for i in range(k):\n",
        "        cluster_labels = dataset[dataset[\"new_labels\"] == (i + 1)][\"labels\"]\n",
        "        if len(cluster_labels) > 0:\n",
        "            most_common = Counter(cluster_labels).most_common(1)[0][1]\n",
        "            total += most_common\n",
        "    return total / len(dataset)\n",
        "purity = purity_score(dataset)\n",
        "# تعریف f_measure\n",
        "def f_measure(dataset):\n",
        "    precision_list = []\n",
        "    recall_list = []\n",
        "    for i in range(k):\n",
        "        true_labels = dataset[\"labels\"].to_numpy()\n",
        "        predicted_labels = (dataset[\"new_labels\"] == (i + 1)).to_numpy()\n",
        "        tp = np.sum((true_labels[predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fp = np.sum((true_labels[predicted_labels] != dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fn = np.sum((true_labels[~predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        precision_list.append(precision)\n",
        "        recall_list.append(recall)\n",
        "    precision = np.mean(precision_list)\n",
        "    recall = np.mean(recall_list)\n",
        "    f_measure_value = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    return f_measure_value\n",
        "f_measure_value = f_measure(dataset)\n",
        "# زمان پایان\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(\"Purity:\", purity)\n",
        "print(\"F-measure:\", f_measure_value)\n",
        "print(\"Execution time:\", execution_time)\n",
        "print(\"Dataset with new labels:\")\n",
        "print(dataset[[\"x1\", \"x2\", \"labels\", \"new_labels\"]].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MK-n8zWgBpwr"
      },
      "outputs": [],
      "source": [
        "#################با کرنل دو جمله ای k_median محاسبه"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXLv6F_nB_Qs",
        "outputId": "53f3c078-184b-4627-b722-71b9d1d39e3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Purity: 0.47869674185463656\n",
            "F-measure: 0.04006410256410257\n",
            "Execution time: 1.589979648590088\n",
            "Dataset with new labels:\n",
            "      x1     x2  labels  new_labels\n",
            "0  26.75  22.15       1           1\n",
            "1  29.80  22.15       1           1\n",
            "2  31.55  21.10       1           1\n",
            "3  27.70  20.85       1           1\n",
            "4  29.90  19.95       1           1\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import requests\n",
        "from io import StringIO\n",
        "import time\n",
        "from sklearn.metrics.pairwise import polynomial_kernel\n",
        "\n",
        "# بارگذاری داده‌ها\n",
        "link = [\"http://cs.joensuu.fi/sipu/datasets/Compound.txt\"]\n",
        "numbers = []\n",
        "read = requests.get(link[0])\n",
        "content = read.text\n",
        "data = StringIO(content)\n",
        "df = pd.read_csv(data, sep=\"\\s+\", header=None, names=[\"x1\", \"x2\", \"labels\"])\n",
        "numbers.append(df)\n",
        "dataset = pd.concat(numbers, ignore_index=True)\n",
        "# تعریف تابع k_median_polynomial\n",
        "def k_median_polynomial(data, k, max_iterations=200):\n",
        "    centers = data.sample(n=k, random_state=42).to_numpy()\n",
        "    for _ in range(max_iterations):\n",
        "        similarity_matrix = polynomial_kernel(data, centers)\n",
        "        labels = np.argmax(similarity_matrix, axis=1)\n",
        "        new_centers = []\n",
        "        for i in range(k):\n",
        "            cluster_points = data.iloc[np.where(labels == i)]\n",
        "            if len(cluster_points) > 0:\n",
        "                new_centers.append(cluster_points.median(axis=0).to_numpy())\n",
        "            else:\n",
        "                new_centers.append(data.sample(n=1, random_state=42).to_numpy().flatten())\n",
        "        new_centers = np.array(new_centers)\n",
        "        if np.allclose(centers, new_centers, atol=1e-4):\n",
        "            break\n",
        "        centers = new_centers\n",
        "    return centers, labels\n",
        "\n",
        "k = 6\n",
        "# زمان شروع\n",
        "start_time = time.time()\n",
        "centers, labels = k_median_polynomial(dataset[[\"x1\", \"x2\"]], k)\n",
        "labels += 1\n",
        "dataset[\"new_labels\"] = labels\n",
        "# تعریف purity\n",
        "def purity_score(dataset):\n",
        "    total = 0\n",
        "    for i in range(k):\n",
        "        cluster_labels = dataset[dataset[\"new_labels\"] == (i + 1)][\"labels\"]\n",
        "        if len(cluster_labels) > 0:\n",
        "            most_common = Counter(cluster_labels).most_common(1)[0][1]\n",
        "            total += most_common\n",
        "    return total / len(dataset)\n",
        "\n",
        "purity = purity_score(dataset)\n",
        "\n",
        "# تعریف f_measure\n",
        "def f_measure(dataset):\n",
        "    precision_list = []\n",
        "    recall_list = []\n",
        "    for i in range(k):\n",
        "        true_labels = dataset[\"labels\"].to_numpy()\n",
        "        predicted_labels = (dataset[\"new_labels\"] == (i + 1)).to_numpy()\n",
        "        tp = np.sum((true_labels[predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fp = np.sum((true_labels[predicted_labels] != dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fn = np.sum((true_labels[~predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        precision_list.append(precision)\n",
        "        recall_list.append(recall)\n",
        "\n",
        "    precision = np.mean(precision_list)\n",
        "    recall = np.mean(recall_list)\n",
        "    f_measure_value = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    return f_measure_value\n",
        "\n",
        "f_measure_value = f_measure(dataset)\n",
        "\n",
        "# زمان پایان\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "\n",
        "print(\"Purity:\", purity)\n",
        "print(\"F-measure:\", f_measure_value)\n",
        "print(\"Execution time:\", execution_time)\n",
        "print(\"Dataset with new labels:\")\n",
        "print(dataset[[\"x1\", \"x2\", \"labels\", \"new_labels\"]].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SD7jyDirCTeK"
      },
      "outputs": [],
      "source": [
        "############## با کرنل گوسی k_median محاسبه"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s95JTHqMCNMb",
        "outputId": "b3de9e7b-efe8-4f80-c249-d5f1d0592ede"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Purity: 0.87468671679198\n",
            "F-measure: 0.1647940074906367\n",
            "Execution time: 0.04909372329711914\n",
            "Dataset with new labels:\n",
            "      x1     x2  labels  new_labels\n",
            "0  26.75  22.15       1           5\n",
            "1  29.80  22.15       1           5\n",
            "2  31.55  21.10       1           5\n",
            "3  27.70  20.85       1           5\n",
            "4  29.90  19.95       1           5\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import requests\n",
        "from io import StringIO\n",
        "import time\n",
        "from sklearn.metrics.pairwise import rbf_kernel\n",
        "# بارگذاری داده‌ها\n",
        "link = [\"http://cs.joensuu.fi/sipu/datasets/Compound.txt\"]\n",
        "numbers = []\n",
        "read = requests.get(link[0])\n",
        "content = read.text\n",
        "data = StringIO(content)\n",
        "df = pd.read_csv(data, sep=\"\\s+\", header=None, names=[\"x1\", \"x2\", \"labels\"])\n",
        "numbers.append(df)\n",
        "dataset = pd.concat(numbers, ignore_index=True)\n",
        "# تعریف تابع k_median\n",
        "def k_median_rbf(data, k, max_iterations=100, gamma=0.5):\n",
        "    centers = data.sample(n=k, random_state=42).to_numpy()\n",
        "    for _ in range(max_iterations):\n",
        "        similarity_matrix = rbf_kernel(data, centers, gamma=gamma)\n",
        "        labels = np.argmax(similarity_matrix, axis=1)\n",
        "        new_centers = np.array([data[labels == i].median(axis=0) for i in range(k)])\n",
        "        if np.allclose(centers, new_centers):\n",
        "            break\n",
        "        centers = new_centers\n",
        "    return centers, labels\n",
        "k =6\n",
        "# زمان شروع\n",
        "start_time = time.time()\n",
        "centers, labels = k_median(dataset[[\"x1\", \"x2\"]], k)\n",
        "labels += 1\n",
        "dataset[\"new_labels\"] = labels\n",
        "# تعریف purity\n",
        "def purity_score(dataset):\n",
        "    total = 0\n",
        "    for i in range(k):\n",
        "        cluster_labels = dataset[dataset[\"new_labels\"] == (i + 1)][\"labels\"]\n",
        "        if len(cluster_labels) > 0:\n",
        "            most_common = Counter(cluster_labels).most_common(1)[0][1]\n",
        "            total += most_common\n",
        "    return total / len(dataset)\n",
        "purity = purity_score(dataset)\n",
        "# تعریف f_measure\n",
        "def f_measure(dataset):\n",
        "    precision_list = []\n",
        "    recall_list = []\n",
        "    for i in range(k):\n",
        "        true_labels = dataset[\"labels\"].to_numpy()\n",
        "        predicted_labels = (dataset[\"new_labels\"] == (i + 1)).to_numpy()\n",
        "        tp = np.sum((true_labels[predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fp = np.sum((true_labels[predicted_labels] != dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fn = np.sum((true_labels[~predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        precision_list.append(precision)\n",
        "        recall_list.append(recall)\n",
        "        precision = np.mean(precision_list)\n",
        "    recall = np.mean(recall_list)\n",
        "    f_measure_value = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    return f_measure_value\n",
        "f_measure_value = f_measure(dataset)\n",
        "# زمان پایان\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(\"Purity:\", purity)\n",
        "print(\"F-measure:\", f_measure_value)\n",
        "print(\"Execution time:\", execution_time)\n",
        "print(\"Dataset with new labels:\")\n",
        "print(dataset[[\"x1\", \"x2\", \"labels\", \"new_labels\"]].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6ntGaq5DFYt"
      },
      "outputs": [],
      "source": [
        "#################         الگوریتم خوشه بندی طیفی"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdiPT0cmDW4y",
        "outputId": "87d5d759-aa52-434b-b96e-59e52c30417d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Purity: 0.8571428571428571\n",
            "F-measure: 0.7442548363975008\n",
            "Execution time: 0.07467508316040039\n",
            "Dataset with new labels:\n",
            "      x1     x2  labels  new_labels\n",
            "0  26.75  22.15       1           1\n",
            "1  29.80  22.15       1           1\n",
            "2  31.55  21.10       1           1\n",
            "3  27.70  20.85       1           1\n",
            "4  29.90  19.95       1           1\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import requests\n",
        "from io import StringIO\n",
        "import time\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "from sklearn.cluster import KMeans\n",
        "from scipy.sparse.linalg import eigsh\n",
        "# بارگذاری داده‌ها\n",
        "link = [\"http://cs.joensuu.fi/sipu/datasets/Compound.txt\"]\n",
        "numbers = []\n",
        "read = requests.get(link[0])\n",
        "content = read.text\n",
        "data = StringIO(content)\n",
        "df = pd.read_csv(data, sep=\"\\s+\", header=None, names=[\"x1\", \"x2\", \"labels\"])\n",
        "numbers.append(df)\n",
        "dataset = pd.concat(numbers, ignore_index=True)\n",
        "# تابع خوشه‌بندی طیفی\n",
        "def spectral_clustering(data, k):\n",
        "    adjacency_matrix = kneighbors_graph(data, n_neighbors=l, mode='connectivity', include_self=False).toarray()\n",
        "    weight_matrix = adjacency_matrix * adjacency_matrix.T\n",
        "    degree_matrix = np.diag(weight_matrix.sum(axis=1))\n",
        "    laplacian_matrix = degree_matrix - weight_matrix\n",
        "    eigvals, eigvecs = eigsh(laplacian_matrix, k=l, which='SM')\n",
        "    kmeans = KMeans(n_clusters=k)\n",
        "    labels = kmeans.fit_predict(eigvecs)\n",
        "    return labels\n",
        "l=9\n",
        "k =6\n",
        "# زمان شروع\n",
        "start_time = time.time()\n",
        "labels = spectral_clustering(dataset[[\"x1\", \"x2\"]], k)\n",
        "labels += 1\n",
        "dataset[\"new_labels\"] = labels\n",
        "# تعریف purity\n",
        "def purity_score(dataset):\n",
        "    total = 0\n",
        "    for i in range(k):\n",
        "        cluster_labels = dataset[dataset[\"new_labels\"] == (i + 1)][\"labels\"]\n",
        "        if len(cluster_labels) > 0:\n",
        "            most_common = Counter(cluster_labels).most_common(1)[0][1]\n",
        "            total += most_common\n",
        "    return total / len(dataset)\n",
        "purity = purity_score(dataset)\n",
        "# تعریف f_measure\n",
        "def f_measure(dataset):\n",
        "    precision_list = []\n",
        "    recall_list = []\n",
        "    for i in range(k):\n",
        "        true_labels = dataset[\"labels\"].to_numpy()\n",
        "        predicted_labels = (dataset[\"new_labels\"] == (i + 1)).to_numpy()\n",
        "        tp = np.sum((true_labels[predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fp = np.sum((true_labels[predicted_labels] != dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fn = np.sum((true_labels[~predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        precision_list.append(precision)\n",
        "        recall_list.append(recall)\n",
        "    precision = np.mean(precision_list)\n",
        "    recall = np.mean(recall_list)\n",
        "    f_measure_value = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    return f_measure_value\n",
        "f_measure_value = f_measure(dataset)\n",
        "# زمان پایان\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(\"Purity:\", purity)\n",
        "print(\"F-measure:\", f_measure_value)\n",
        "print(\"Execution time:\", execution_time)\n",
        "print(\"Dataset with new labels:\")\n",
        "print(dataset[[\"x1\", \"x2\", \"labels\", \"new_labels\"]].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HWmCT1HH_PDo"
      },
      "outputs": [],
      "source": [
        "###############مقایسه الگوریتم ها"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcxfsJ2k_Jnn",
        "outputId": "26b1399b-e019-4c0d-bcf4-28cd2a7bd2fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "مقایسه نتایج الگوریتم‌ها:\n",
            "             Algorithm    Purity  F-measure  Execution Time\n",
            "0             k_median  0.874687   0.164794        0.022899\n",
            "1            k_median2  0.874687   0.164794        0.714261\n",
            "2  spectral_clustering  0.904762   0.424102        0.324050\n",
            "3  k_median_polynomial  0.478697   0.040064        2.392724\n",
            "4         k_median_rbf  0.874687   0.164794        0.041273\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import requests\n",
        "from io import StringIO\n",
        "import time\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics.pairwise import polynomial_kernel, rbf_kernel\n",
        "from scipy.sparse.linalg import eigsh\n",
        "\n",
        "# بارگذاری داده‌ها\n",
        "link = [\"http://cs.joensuu.fi/sipu/datasets/Compound.txt\"]\n",
        "numbers = []\n",
        "read = requests.get(link[0])\n",
        "content = read.text\n",
        "data = StringIO(content)\n",
        "df = pd.read_csv(data, sep=\"\\s+\", header=None, names=[\"x1\", \"x2\", \"labels\"])\n",
        "numbers.append(df)\n",
        "dataset = pd.concat(numbers, ignore_index=True)\n",
        "k=6\n",
        "l=9\n",
        "\n",
        "# تعریف تابع k_median\n",
        "def k_median(data, k, max_iterations=200):\n",
        "    centers = data.sample(n=k, random_state=42).to_numpy()\n",
        "    for _ in range(max_iterations):\n",
        "        distances = np.linalg.norm(data.to_numpy()[:, np.newaxis] - centers, axis=2)\n",
        "        labels = np.argmin(distances, axis=1)\n",
        "        new_centers = np.array([np.median(data[labels == i].to_numpy(), axis=0) for i in range(k)])\n",
        "        if np.all(centers == new_centers):\n",
        "            break\n",
        "        centers = new_centers\n",
        "    return centers, labels\n",
        "\n",
        "# نسخه دوم k_median (با فواصل مشابه نسخه اول شما)\n",
        "def k_median2(data, k, max_iterations=200):\n",
        "    centers = data.sample(n=k, random_state=42).to_numpy()\n",
        "    for _ in range(max_iterations):\n",
        "        distances = np.linalg.norm(data.to_numpy()[:, np.newaxis] - centers, axis=2)\n",
        "        labels = np.argmin(distances, axis=1)\n",
        "        for i in range(0, k, 2):\n",
        "            if i < k and np.any(labels == i):\n",
        "                centers[i] = data.iloc[labels == i].median(axis=0).to_numpy()\n",
        "            if i + 1 < k and np.any(labels == (i + 1)):\n",
        "                centers[i + 1] = data.iloc[labels == (i + 1)].median(axis=0).to_numpy()\n",
        "        if np.allclose(centers, centers.mean(axis=0)):\n",
        "            break\n",
        "    return centers, labels\n",
        "\n",
        "# K-Median با کرنل چندجمله‌ای\n",
        "def k_median_polynomial(data, k, max_iterations=200):\n",
        "    centers = data.sample(n=k, random_state=42).to_numpy()\n",
        "    for _ in range(max_iterations):\n",
        "        similarity_matrix = polynomial_kernel(data, centers)\n",
        "        labels = np.argmax(similarity_matrix, axis=1)\n",
        "        new_centers = []\n",
        "        for i in range(k):\n",
        "            cluster_points = data.iloc[np.where(labels == i)]\n",
        "            if len(cluster_points) > 0:\n",
        "                new_centers.append(cluster_points.median(axis=0).to_numpy())\n",
        "            else:\n",
        "                new_centers.append(data.sample(n=1, random_state=42).to_numpy().flatten())\n",
        "        new_centers = np.array(new_centers)\n",
        "        if np.allclose(centers, new_centers, atol=1e-4):\n",
        "            break\n",
        "        centers = new_centers\n",
        "    return centers, labels\n",
        "\n",
        "# K-Median با کرنل گوسی\n",
        "def k_median_rbf(data, k, max_iterations=100, gamma=0.5):\n",
        "    centers = data.sample(n=k, random_state=42).to_numpy()\n",
        "    for _ in range(max_iterations):\n",
        "        similarity_matrix = rbf_kernel(data, centers, gamma=gamma)\n",
        "        labels = np.argmax(similarity_matrix, axis=1)\n",
        "        new_centers = np.array([data[labels == i].median(axis=0) for i in range(k)])\n",
        "        if np.allclose(centers, new_centers):\n",
        "            break\n",
        "        centers = new_centers\n",
        "    return centers, labels\n",
        "\n",
        "# خوشه‌بندی طیفی\n",
        "def spectral_clustering(data, k):\n",
        "    adjacency_matrix = kneighbors_graph(data, n_neighbors=l, mode='connectivity', include_self=False).toarray()\n",
        "    weight_matrix = adjacency_matrix * adjacency_matrix.T\n",
        "    degree_matrix = np.diag(weight_matrix.sum(axis=1))\n",
        "    laplacian_matrix = degree_matrix - weight_matrix\n",
        "    eigvals, eigvecs = eigsh(laplacian_matrix, k=l, which='SM')\n",
        "    kmeans = KMeans(n_clusters=k)\n",
        "    labels = kmeans.fit_predict(eigvecs)\n",
        "    return labels\n",
        "\n",
        "# محاسبه Purity\n",
        "def purity_score(dataset):\n",
        "    total = 0\n",
        "    for i in range(k):\n",
        "        cluster_labels = dataset[dataset[\"new_labels\"] == (i + 1)][\"labels\"]\n",
        "        if len(cluster_labels) > 0:\n",
        "            most_common = Counter(cluster_labels).most_common(1)[0][1]\n",
        "            total += most_common\n",
        "    return total / len(dataset)\n",
        "\n",
        "# محاسبه F-measure\n",
        "def f_measure(dataset):\n",
        "    precision_list = []\n",
        "    recall_list = []\n",
        "    for i in range(k):\n",
        "        true_labels = dataset[\"labels\"].to_numpy()\n",
        "        predicted_labels = (dataset[\"new_labels\"] == (i + 1)).to_numpy()\n",
        "        tp = np.sum((true_labels[predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fp = np.sum((true_labels[predicted_labels] != dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fn = np.sum((true_labels[~predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        precision_list.append(precision)\n",
        "        recall_list.append(recall)\n",
        "    precision = np.mean(precision_list)\n",
        "    recall = np.mean(recall_list)\n",
        "    f_measure_value = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    return f_measure_value\n",
        "\n",
        "# اجرای الگوریتم‌ها\n",
        "def run_algorithm(algorithm, dataset, k):\n",
        "    start_time = time.time()\n",
        "    if algorithm == spectral_clustering:\n",
        "        labels = algorithm(dataset[[\"x1\", \"x2\"]], k)\n",
        "        centers = None\n",
        "    else:\n",
        "        centers, labels = algorithm(dataset[[\"x1\", \"x2\"]], k)\n",
        "    labels += 1\n",
        "    dataset[\"new_labels\"] = labels\n",
        "    purity = purity_score(dataset)\n",
        "    f_measure_value = f_measure(dataset)\n",
        "    end_time = time.time()\n",
        "    execution_time = end_time - start_time\n",
        "    return purity, f_measure_value, execution_time, dataset\n",
        "\n",
        "# نتایج\n",
        "results = []\n",
        "algorithms = [k_median, k_median2, spectral_clustering, k_median_polynomial, k_median_rbf]\n",
        "for algorithm in algorithms:\n",
        "    purity, f_measure_value, execution_time, dataset_with_labels = run_algorithm(algorithm, dataset.copy(), k)\n",
        "    results.append({\n",
        "        \"Algorithm\": algorithm.__name__,\n",
        "        \"Purity\": purity,\n",
        "        \"F-measure\": f_measure_value,\n",
        "        \"Execution Time\": execution_time\n",
        "    })\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "# مقایسه نتایج\n",
        "print(\"مقایسه نتایج الگوریتم‌ها:\")\n",
        "print(results_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j1VK-VWEEI6i"
      },
      "outputs": [],
      "source": [
        "########################## انجام الگوریتم ها در تکست سوم(pathbased.txt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o1k1mGDjEXaJ"
      },
      "outputs": [],
      "source": [
        "###################با جابه جایی یکی از مراکز با نقاط داده k_median محاسبه"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvzXmbJmEhxR",
        "outputId": "3f7ba6bd-3847-4b1d-9746-2fcc7a01e9ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Purity: 0.74\n",
            "F-measure: 0.09641873278236915\n",
            "Execution time: 0.04737448692321777\n",
            "Dataset with new labels:\n",
            "      x1    x2  labels  new_labels\n",
            "0  11.25  5.05       1           1\n",
            "1  10.95  4.70       1           1\n",
            "2   9.85  5.80       1           1\n",
            "3   9.80  5.75       1           1\n",
            "4   9.15  6.80       1           1\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import requests\n",
        "from io import StringIO\n",
        "import time\n",
        "# بارگذاری داده‌ها\n",
        "link= [\"http://cs.joensuu.fi/sipu/datasets/pathbased.txt\"]\n",
        "numbers = []\n",
        "read = requests.get(link[0])\n",
        "content = read.text\n",
        "data = StringIO(content)\n",
        "df = pd.read_csv(data, sep=\"\\s+\", header=None, names=[\"x1\", \"x2\", \"labels\"])\n",
        "numbers.append(df)\n",
        "dataset = pd.concat(numbers, ignore_index=True)\n",
        "# تعریف تابع k_media\n",
        "def k_median(data, k, max_iterations=200):\n",
        "    centers = data.sample(n=k, random_state=42).to_numpy()\n",
        "    for _ in range(max_iterations):\n",
        "        distances = np.linalg.norm(data.to_numpy()[:, np.newaxis] - centers, axis=2)\n",
        "        labels = np.argmin(distances, axis=1)\n",
        "        new_centers = np.array([np.median(data[labels == i].to_numpy(), axis=0) for i in range(k)])\n",
        "        if np.all(centers == new_centers):\n",
        "            break\n",
        "        centers = new_centers\n",
        "    return centers, labels\n",
        "k=3\n",
        "# زمان شروع\n",
        "start_time = time.time()\n",
        "centers, labels = k_median(dataset[[\"x1\", \"x2\"]], k)\n",
        "labels += 1\n",
        "dataset[\"new_labels\"] = labels\n",
        "# تعریف purity\n",
        "def purity_score(dataset):\n",
        "    total = 0\n",
        "    for i in range(k):\n",
        "        cluster_labels = dataset[dataset[\"new_labels\"] == (i + 1)][\"labels\"]\n",
        "        if len(cluster_labels) > 0:\n",
        "            most_common = Counter(cluster_labels).most_common(1)[0][1]\n",
        "            total += most_common\n",
        "    return total / len(dataset)\n",
        "purity = purity_score(dataset)\n",
        "# تعریف f_measure\n",
        "def f_measure(dataset):\n",
        "    precision_list = []\n",
        "    recall_list = []\n",
        "    for i in range(k):\n",
        "        true_labels = dataset[\"labels\"].to_numpy()\n",
        "        predicted_labels = (dataset[\"new_labels\"] == (i + 1)).to_numpy()\n",
        "        tp = np.sum((true_labels[predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fp = np.sum((true_labels[predicted_labels] != dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fn = np.sum((true_labels[~predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        precision_list.append(precision)\n",
        "        recall_list.append(recall)\n",
        "    precision = np.mean(precision_list)\n",
        "    recall = np.mean(recall_list)\n",
        "    f_measure_value = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    return f_measure_value\n",
        "f_measure_value = f_measure(dataset)\n",
        "#زمان پابان\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(\"Purity:\", purity)\n",
        "print(\"F-measure:\", f_measure_value)\n",
        "print(\"Execution time:\", execution_time)\n",
        "print(\"Dataset with new labels:\")\n",
        "print(dataset[[\"x1\", \"x2\", \"labels\", \"new_labels\"]].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "At_6HBhuEvHq"
      },
      "outputs": [],
      "source": [
        "###################### با جابه جایی دو تا از مراکز با نقاط داده k_median محاسبه"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQf71IOHFC4h",
        "outputId": "47f15e26-be5e-4cfa-d7a3-bcb96445e23e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Purity: 0.74\n",
            "F-measure: 0.09641873278236915\n",
            "Execution time: 0.4539005756378174\n",
            "Dataset with new labels:\n",
            "      x1    x2  labels  new_labels\n",
            "0  11.25  5.05       1           1\n",
            "1  10.95  4.70       1           1\n",
            "2   9.85  5.80       1           1\n",
            "3   9.80  5.75       1           1\n",
            "4   9.15  6.80       1           1\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import requests\n",
        "from io import StringIO\n",
        "import time\n",
        "# بارگذاری داده‌ها\n",
        "link = [\"http://cs.joensuu.fi/sipu/datasets/pathbased.txt\"]\n",
        "numbers = []\n",
        "read = requests.get(link[0])\n",
        "content = read.text\n",
        "data = StringIO(content)\n",
        "df = pd.read_csv(data, sep=\"\\s+\", header=None, names=[\"x1\", \"x2\", \"labels\"])\n",
        "numbers.append(df)\n",
        "dataset = pd.concat(numbers, ignore_index=True)\n",
        "# تعریف تابع k_median\n",
        "def k_median(data, k, max_iterations=200):\n",
        "    centers = data.sample(n=k, random_state=42).to_numpy()\n",
        "    for _ in range(max_iterations):\n",
        "        distances = np.linalg.norm(data.to_numpy()[:, np.newaxis] - centers, axis=2)\n",
        "        labels = np.argmin(distances, axis=1)\n",
        "        for i in range(0, k, 2):\n",
        "            if i < k and np.any(labels == i):\n",
        "                centers[i] = data.iloc[labels == i].median(axis=0).to_numpy()\n",
        "            if i + 1 < k and np.any(labels == (i + 1)):\n",
        "                centers[i + 1] = data.iloc[labels == (i + 1)].median(axis=0).to_numpy()\n",
        "        if np.allclose(centers, centers.mean(axis=0)):\n",
        "            break\n",
        "    return centers, labels\n",
        "k =3\n",
        "# زمان شروع\n",
        "start_time = time.time()\n",
        "centers, labels = k_median(dataset[[\"x1\", \"x2\"]], k)\n",
        "labels += 1\n",
        "dataset[\"new_labels\"] = labels\n",
        "# تعریف purity\n",
        "def purity_score(dataset):\n",
        "    total = 0\n",
        "    for i in range(k):\n",
        "        cluster_labels = dataset[dataset[\"new_labels\"] == (i + 1)][\"labels\"]\n",
        "        if len(cluster_labels) > 0:\n",
        "            most_common = Counter(cluster_labels).most_common(1)[0][1]\n",
        "            total += most_common\n",
        "    return total / len(dataset)\n",
        "purity = purity_score(dataset)\n",
        "# تعریف f_measure\n",
        "def f_measure(dataset):\n",
        "    precision_list = []\n",
        "    recall_list = []\n",
        "    for i in range(k):\n",
        "        true_labels = dataset[\"labels\"].to_numpy()\n",
        "        predicted_labels = (dataset[\"new_labels\"] == (i + 1)).to_numpy()\n",
        "        tp = np.sum((true_labels[predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fp = np.sum((true_labels[predicted_labels] != dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fn = np.sum((true_labels[~predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        precision_list.append(precision)\n",
        "        recall_list.append(recall)\n",
        "    precision = np.mean(precision_list)\n",
        "    recall = np.mean(recall_list)\n",
        "    f_measure_value = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    return f_measure_value\n",
        "f_measure_value = f_measure(dataset)\n",
        "# زمان پایان\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(\"Purity:\", purity)\n",
        "print(\"F-measure:\", f_measure_value)\n",
        "print(\"Execution time:\", execution_time)\n",
        "print(\"Dataset with new labels:\")\n",
        "print(dataset[[\"x1\", \"x2\", \"labels\", \"new_labels\"]].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "waslMu-rFhRD"
      },
      "outputs": [],
      "source": [
        "#################با کرنل دو جمله ای k_median محاسبه"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7sG3CRqFUVC",
        "outputId": "b6f05997-b8b6-4e6e-b1c6-723db9b69052"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Purity: 0.36666666666666664\n",
            "F-measure: 0.1628883291351805\n",
            "Execution time: 0.03727149963378906\n",
            "Dataset with new labels:\n",
            "      x1    x2  labels  new_labels\n",
            "0  11.25  5.05       1           3\n",
            "1  10.95  4.70       1           3\n",
            "2   9.85  5.80       1           3\n",
            "3   9.80  5.75       1           3\n",
            "4   9.15  6.80       1           3\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import requests\n",
        "from io import StringIO\n",
        "import time\n",
        "from sklearn.metrics.pairwise import polynomial_kernel\n",
        "\n",
        "# بارگذاری داده‌ها\n",
        "link = [\"http://cs.joensuu.fi/sipu/datasets/pathbased.txt\"]\n",
        "numbers = []\n",
        "read = requests.get(link[0])\n",
        "content = read.text\n",
        "data = StringIO(content)\n",
        "df = pd.read_csv(data, sep=\"\\s+\", header=None, names=[\"x1\", \"x2\", \"labels\"])\n",
        "numbers.append(df)\n",
        "dataset = pd.concat(numbers, ignore_index=True)\n",
        "# تعریف تابع k_median_polynomial\n",
        "def k_median_polynomial(data, k, max_iterations=200):\n",
        "    centers = data.sample(n=k, random_state=42).to_numpy()\n",
        "    for _ in range(max_iterations):\n",
        "        similarity_matrix = polynomial_kernel(data, centers)\n",
        "        labels = np.argmax(similarity_matrix, axis=1)\n",
        "        new_centers = []\n",
        "        for i in range(k):\n",
        "            cluster_points = data.iloc[np.where(labels == i)]\n",
        "            if len(cluster_points) > 0:\n",
        "                new_centers.append(cluster_points.median(axis=0).to_numpy())\n",
        "            else:\n",
        "                new_centers.append(data.sample(n=1, random_state=42).to_numpy().flatten())\n",
        "        new_centers = np.array(new_centers)\n",
        "        if np.allclose(centers, new_centers, atol=1e-4):\n",
        "            break\n",
        "        centers = new_centers\n",
        "    return centers, labels\n",
        "\n",
        "k = 3\n",
        "# زمان شروع\n",
        "start_time = time.time()\n",
        "centers, labels = k_median_polynomial(dataset[[\"x1\", \"x2\"]], k)\n",
        "labels += 1\n",
        "dataset[\"new_labels\"] = labels\n",
        "# تعریف purity\n",
        "def purity_score(dataset):\n",
        "    total = 0\n",
        "    for i in range(k):\n",
        "        cluster_labels = dataset[dataset[\"new_labels\"] == (i + 1)][\"labels\"]\n",
        "        if len(cluster_labels) > 0:\n",
        "            most_common = Counter(cluster_labels).most_common(1)[0][1]\n",
        "            total += most_common\n",
        "    return total / len(dataset)\n",
        "\n",
        "purity = purity_score(dataset)\n",
        "\n",
        "# تعریف f_measure\n",
        "def f_measure(dataset):\n",
        "    precision_list = []\n",
        "    recall_list = []\n",
        "    for i in range(k):\n",
        "        true_labels = dataset[\"labels\"].to_numpy()\n",
        "        predicted_labels = (dataset[\"new_labels\"] == (i + 1)).to_numpy()\n",
        "        tp = np.sum((true_labels[predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fp = np.sum((true_labels[predicted_labels] != dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fn = np.sum((true_labels[~predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        precision_list.append(precision)\n",
        "        recall_list.append(recall)\n",
        "\n",
        "    precision = np.mean(precision_list)\n",
        "    recall = np.mean(recall_list)\n",
        "    f_measure_value = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    return f_measure_value\n",
        "\n",
        "f_measure_value = f_measure(dataset)\n",
        "\n",
        "# زمان پایان\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "\n",
        "print(\"Purity:\", purity)\n",
        "print(\"F-measure:\", f_measure_value)\n",
        "print(\"Execution time:\", execution_time)\n",
        "print(\"Dataset with new labels:\")\n",
        "print(dataset[[\"x1\", \"x2\", \"labels\", \"new_labels\"]].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Gex6GBLGEdM"
      },
      "outputs": [],
      "source": [
        "#################با کرنل  گوسی k_median محاسبه"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKBJqunqFrT_",
        "outputId": "740921d0-67c7-4599-e6b4-27c21a488717"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Purity: 0.74\n",
            "F-measure: 0.09641873278236915\n",
            "Execution time: 0.02574944496154785\n",
            "Dataset with new labels:\n",
            "      x1    x2  labels  new_labels\n",
            "0  11.25  5.05       1           1\n",
            "1  10.95  4.70       1           1\n",
            "2   9.85  5.80       1           1\n",
            "3   9.80  5.75       1           1\n",
            "4   9.15  6.80       1           1\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import requests\n",
        "from io import StringIO\n",
        "import time\n",
        "from sklearn.metrics.pairwise import rbf_kernel\n",
        "# بارگذاری داده‌ها\n",
        "link = [\"http://cs.joensuu.fi/sipu/datasets/pathbased.txt\"]\n",
        "numbers = []\n",
        "read = requests.get(link[0])\n",
        "content = read.text\n",
        "data = StringIO(content)\n",
        "df = pd.read_csv(data, sep=\"\\s+\", header=None, names=[\"x1\", \"x2\", \"labels\"])\n",
        "numbers.append(df)\n",
        "dataset = pd.concat(numbers, ignore_index=True)\n",
        "# تعریف تابع k_median\n",
        "def k_median_rbf(data, k, max_iterations=100, gamma=0.5):\n",
        "    centers = data.sample(n=k, random_state=42).to_numpy()\n",
        "    for _ in range(max_iterations):\n",
        "        similarity_matrix = rbf_kernel(data, centers, gamma=gamma)\n",
        "        labels = np.argmax(similarity_matrix, axis=1)\n",
        "        new_centers = np.array([data[labels == i].median(axis=0) for i in range(k)])\n",
        "        if np.allclose(centers, new_centers):\n",
        "            break\n",
        "        centers = new_centers\n",
        "    return centers, labels\n",
        "k =3\n",
        "# زمان شروع\n",
        "start_time = time.time()\n",
        "centers, labels = k_median(dataset[[\"x1\", \"x2\"]], k)\n",
        "labels += 1\n",
        "dataset[\"new_labels\"] = labels\n",
        "# تعریف purity\n",
        "def purity_score(dataset):\n",
        "    total = 0\n",
        "    for i in range(k):\n",
        "        cluster_labels = dataset[dataset[\"new_labels\"] == (i + 1)][\"labels\"]\n",
        "        if len(cluster_labels) > 0:\n",
        "            most_common = Counter(cluster_labels).most_common(1)[0][1]\n",
        "            total += most_common\n",
        "    return total / len(dataset)\n",
        "purity = purity_score(dataset)\n",
        "# تعریف f_measure\n",
        "def f_measure(dataset):\n",
        "    precision_list = []\n",
        "    recall_list = []\n",
        "    for i in range(k):\n",
        "        true_labels = dataset[\"labels\"].to_numpy()\n",
        "        predicted_labels = (dataset[\"new_labels\"] == (i + 1)).to_numpy()\n",
        "        tp = np.sum((true_labels[predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fp = np.sum((true_labels[predicted_labels] != dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fn = np.sum((true_labels[~predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        precision_list.append(precision)\n",
        "        recall_list.append(recall)\n",
        "        precision = np.mean(precision_list)\n",
        "    recall = np.mean(recall_list)\n",
        "    f_measure_value = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    return f_measure_value\n",
        "f_measure_value = f_measure(dataset)\n",
        "# زمان پایان\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(\"Purity:\", purity)\n",
        "print(\"F-measure:\", f_measure_value)\n",
        "print(\"Execution time:\", execution_time)\n",
        "print(\"Dataset with new labels:\")\n",
        "print(dataset[[\"x1\", \"x2\", \"labels\", \"new_labels\"]].head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NGEhv_3bGPPL"
      },
      "outputs": [],
      "source": [
        "#################         الگوریتم خوشه بندی طیفی"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5ICczMIGZJj",
        "outputId": "e13aa6db-c0e5-49a8-fcc4-43b0edc3ac51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Purity: 0.59\n",
            "F-measure: 0.49045527842808384\n",
            "Execution time: 0.05619072914123535\n",
            "Dataset with new labels:\n",
            "      x1    x2  labels  new_labels\n",
            "0  11.25  5.05       1           1\n",
            "1  10.95  4.70       1           1\n",
            "2   9.85  5.80       1           1\n",
            "3   9.80  5.75       1           1\n",
            "4   9.15  6.80       1           1\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import requests\n",
        "from io import StringIO\n",
        "import time\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "from sklearn.cluster import KMeans\n",
        "from scipy.sparse.linalg import eigsh\n",
        "# بارگذاری داده‌ها\n",
        "link = [\"http://cs.joensuu.fi/sipu/datasets/pathbased.txt\"]\n",
        "numbers = []\n",
        "read = requests.get(link[0])\n",
        "content = read.text\n",
        "data = StringIO(content)\n",
        "df = pd.read_csv(data, sep=\"\\s+\", header=None, names=[\"x1\", \"x2\", \"labels\"])\n",
        "numbers.append(df)\n",
        "dataset = pd.concat(numbers, ignore_index=True)\n",
        "# تابع خوشه‌بندی طیفی\n",
        "def spectral_clustering(data, k):\n",
        "    adjacency_matrix = kneighbors_graph(data, n_neighbors=l, mode='connectivity', include_self=False).toarray()\n",
        "    weight_matrix = adjacency_matrix * adjacency_matrix.T\n",
        "    degree_matrix = np.diag(weight_matrix.sum(axis=1))\n",
        "    laplacian_matrix = degree_matrix - weight_matrix\n",
        "    eigvals, eigvecs = eigsh(laplacian_matrix, k=l, which='SM')\n",
        "    kmeans = KMeans(n_clusters=k)\n",
        "    labels = kmeans.fit_predict(eigvecs)\n",
        "    return labels\n",
        "l=9\n",
        "k =3\n",
        "# زمان شروع\n",
        "start_time = time.time()\n",
        "labels = spectral_clustering(dataset[[\"x1\", \"x2\"]], k)\n",
        "labels += 1\n",
        "dataset[\"new_labels\"] = labels\n",
        "# تعریف purity\n",
        "def purity_score(dataset):\n",
        "    total = 0\n",
        "    for i in range(k):\n",
        "        cluster_labels = dataset[dataset[\"new_labels\"] == (i + 1)][\"labels\"]\n",
        "        if len(cluster_labels) > 0:\n",
        "            most_common = Counter(cluster_labels).most_common(1)[0][1]\n",
        "            total += most_common\n",
        "    return total / len(dataset)\n",
        "purity = purity_score(dataset)\n",
        "# تعریف f_measure\n",
        "def f_measure(dataset):\n",
        "    precision_list = []\n",
        "    recall_list = []\n",
        "    for i in range(k):\n",
        "        true_labels = dataset[\"labels\"].to_numpy()\n",
        "        predicted_labels = (dataset[\"new_labels\"] == (i + 1)).to_numpy()\n",
        "        tp = np.sum((true_labels[predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fp = np.sum((true_labels[predicted_labels] != dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fn = np.sum((true_labels[~predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        precision_list.append(precision)\n",
        "        recall_list.append(recall)\n",
        "    precision = np.mean(precision_list)\n",
        "    recall = np.mean(recall_list)\n",
        "    f_measure_value = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    return f_measure_value\n",
        "f_measure_value = f_measure(dataset)\n",
        "# زمان پایان\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(\"Purity:\", purity)\n",
        "print(\"F-measure:\", f_measure_value)\n",
        "print(\"Execution time:\", execution_time)\n",
        "print(\"Dataset with new labels:\")\n",
        "print(dataset[[\"x1\", \"x2\", \"labels\", \"new_labels\"]].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J85Kn7k7A2C9"
      },
      "outputs": [],
      "source": [
        "###############مقایسه الگوریتم ها"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BAt68vBATOA",
        "outputId": "d433ed7b-6a2b-406d-ffef-5861b9547765"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "مقایسه نتایج الگوریتم‌ها:\n",
            "             Algorithm    Purity  F-measure  Execution Time\n",
            "0             k_median  0.740000   0.096419        0.012383\n",
            "1            k_median2  0.740000   0.096419        0.218505\n",
            "2  spectral_clustering  0.586667   0.436108        0.028841\n",
            "3  k_median_polynomial  0.366667   0.162888        0.011394\n",
            "4         k_median_rbf  0.740000   0.096419        0.041589\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import requests\n",
        "from io import StringIO\n",
        "import time\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics.pairwise import polynomial_kernel, rbf_kernel\n",
        "from scipy.sparse.linalg import eigsh\n",
        "\n",
        "# بارگذاری داده‌ها\n",
        "link = [\"http://cs.joensuu.fi/sipu/datasets/pathbased.txt\"]\n",
        "numbers = []\n",
        "read = requests.get(link[0])\n",
        "content = read.text\n",
        "data = StringIO(content)\n",
        "df = pd.read_csv(data, sep=\"\\s+\", header=None, names=[\"x1\", \"x2\", \"labels\"])\n",
        "numbers.append(df)\n",
        "dataset = pd.concat(numbers, ignore_index=True)\n",
        "k=3\n",
        "l=9\n",
        "\n",
        "# تعریف تابع k_median\n",
        "def k_median(data, k, max_iterations=200):\n",
        "    centers = data.sample(n=k, random_state=42).to_numpy()\n",
        "    for _ in range(max_iterations):\n",
        "        distances = np.linalg.norm(data.to_numpy()[:, np.newaxis] - centers, axis=2)\n",
        "        labels = np.argmin(distances, axis=1)\n",
        "        new_centers = np.array([np.median(data[labels == i].to_numpy(), axis=0) for i in range(k)])\n",
        "        if np.all(centers == new_centers):\n",
        "            break\n",
        "        centers = new_centers\n",
        "    return centers, labels\n",
        "\n",
        "# نسخه دوم k_median (با فواصل مشابه نسخه اول شما)\n",
        "def k_median2(data, k, max_iterations=200):\n",
        "    centers = data.sample(n=k, random_state=42).to_numpy()\n",
        "    for _ in range(max_iterations):\n",
        "        distances = np.linalg.norm(data.to_numpy()[:, np.newaxis] - centers, axis=2)\n",
        "        labels = np.argmin(distances, axis=1)\n",
        "        for i in range(0, k, 2):\n",
        "            if i < k and np.any(labels == i):\n",
        "                centers[i] = data.iloc[labels == i].median(axis=0).to_numpy()\n",
        "            if i + 1 < k and np.any(labels == (i + 1)):\n",
        "                centers[i + 1] = data.iloc[labels == (i + 1)].median(axis=0).to_numpy()\n",
        "        if np.allclose(centers, centers.mean(axis=0)):\n",
        "            break\n",
        "    return centers, labels\n",
        "\n",
        "# K-Median با کرنل چندجمله‌ای\n",
        "def k_median_polynomial(data, k, max_iterations=200):\n",
        "    centers = data.sample(n=k, random_state=42).to_numpy()\n",
        "    for _ in range(max_iterations):\n",
        "        similarity_matrix = polynomial_kernel(data, centers)\n",
        "        labels = np.argmax(similarity_matrix, axis=1)\n",
        "        new_centers = []\n",
        "        for i in range(k):\n",
        "            cluster_points = data.iloc[np.where(labels == i)]\n",
        "            if len(cluster_points) > 0:\n",
        "                new_centers.append(cluster_points.median(axis=0).to_numpy())\n",
        "            else:\n",
        "                new_centers.append(data.sample(n=1, random_state=42).to_numpy().flatten())\n",
        "        new_centers = np.array(new_centers)\n",
        "        if np.allclose(centers, new_centers, atol=1e-4):\n",
        "            break\n",
        "        centers = new_centers\n",
        "    return centers, labels\n",
        "\n",
        "# K-Median با کرنل گوسی\n",
        "def k_median_rbf(data, k, max_iterations=100, gamma=0.5):\n",
        "    centers = data.sample(n=k, random_state=42).to_numpy()\n",
        "    for _ in range(max_iterations):\n",
        "        similarity_matrix = rbf_kernel(data, centers, gamma=gamma)\n",
        "        labels = np.argmax(similarity_matrix, axis=1)\n",
        "        new_centers = np.array([data[labels == i].median(axis=0) for i in range(k)])\n",
        "        if np.allclose(centers, new_centers):\n",
        "            break\n",
        "        centers = new_centers\n",
        "    return centers, labels\n",
        "\n",
        "# خوشه‌بندی طیفی\n",
        "def spectral_clustering(data, k):\n",
        "    adjacency_matrix = kneighbors_graph(data, n_neighbors=l, mode='connectivity', include_self=False).toarray()\n",
        "    weight_matrix = adjacency_matrix * adjacency_matrix.T\n",
        "    degree_matrix = np.diag(weight_matrix.sum(axis=1))\n",
        "    laplacian_matrix = degree_matrix - weight_matrix\n",
        "    eigvals, eigvecs = eigsh(laplacian_matrix, k=l, which='SM')\n",
        "    kmeans = KMeans(n_clusters=k)\n",
        "    labels = kmeans.fit_predict(eigvecs)\n",
        "    return labels\n",
        "\n",
        "# محاسبه Purity\n",
        "def purity_score(dataset):\n",
        "    total = 0\n",
        "    for i in range(k):\n",
        "        cluster_labels = dataset[dataset[\"new_labels\"] == (i + 1)][\"labels\"]\n",
        "        if len(cluster_labels) > 0:\n",
        "            most_common = Counter(cluster_labels).most_common(1)[0][1]\n",
        "            total += most_common\n",
        "    return total / len(dataset)\n",
        "\n",
        "# محاسبه F-measure\n",
        "def f_measure(dataset):\n",
        "    precision_list = []\n",
        "    recall_list = []\n",
        "    for i in range(k):\n",
        "        true_labels = dataset[\"labels\"].to_numpy()\n",
        "        predicted_labels = (dataset[\"new_labels\"] == (i + 1)).to_numpy()\n",
        "        tp = np.sum((true_labels[predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fp = np.sum((true_labels[predicted_labels] != dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fn = np.sum((true_labels[~predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        precision_list.append(precision)\n",
        "        recall_list.append(recall)\n",
        "    precision = np.mean(precision_list)\n",
        "    recall = np.mean(recall_list)\n",
        "    f_measure_value = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    return f_measure_value\n",
        "\n",
        "# اجرای الگوریتم‌ها\n",
        "def run_algorithm(algorithm, dataset, k):\n",
        "    start_time = time.time()\n",
        "    if algorithm == spectral_clustering:\n",
        "        labels = algorithm(dataset[[\"x1\", \"x2\"]], k)\n",
        "        centers = None\n",
        "    else:\n",
        "        centers, labels = algorithm(dataset[[\"x1\", \"x2\"]], k)\n",
        "    labels += 1\n",
        "    dataset[\"new_labels\"] = labels\n",
        "    purity = purity_score(dataset)\n",
        "    f_measure_value = f_measure(dataset)\n",
        "    end_time = time.time()\n",
        "    execution_time = end_time - start_time\n",
        "    return purity, f_measure_value, execution_time, dataset\n",
        "\n",
        "# نتایج\n",
        "results = []\n",
        "algorithms = [k_median, k_median2, spectral_clustering, k_median_polynomial, k_median_rbf]\n",
        "for algorithm in algorithms:\n",
        "    purity, f_measure_value, execution_time, dataset_with_labels = run_algorithm(algorithm, dataset.copy(), k)\n",
        "    results.append({\n",
        "        \"Algorithm\": algorithm.__name__,\n",
        "        \"Purity\": purity,\n",
        "        \"F-measure\": f_measure_value,\n",
        "        \"Execution Time\": execution_time\n",
        "    })\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "# مقایسه نتایج\n",
        "print(\"مقایسه نتایج الگوریتم‌ها:\")\n",
        "print(results_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wi-u0mL6HDBz"
      },
      "outputs": [],
      "source": [
        "########################## انجام الگوریتم ها در تکست چهارم(spiral.txt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uuiHQzaDK16N"
      },
      "outputs": [],
      "source": [
        "###################با جابه جایی یکی از مراکز با نقاط داده k_median"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Jsk18XUK54I",
        "outputId": "44117ca1-9c06-4ad6-9696-a4e347946568"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Purity: 0.3557692307692308\n",
            "F-measure: 0.3275272872589949\n",
            "Execution time: 0.010505914688110352\n",
            "Dataset with new labels:\n",
            "      x1    x2  labels  new_labels\n",
            "0  31.95  7.95       3           2\n",
            "1  31.15  7.30       3           2\n",
            "2  30.45  6.65       3           2\n",
            "3  29.70  6.00       3           2\n",
            "4  28.90  5.55       3           2\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import requests\n",
        "from io import StringIO\n",
        "import time\n",
        "# بارگذاری داده‌ها\n",
        "link= [\"http://cs.joensuu.fi/sipu/datasets/spiral.txt\"]\n",
        "numbers = []\n",
        "read = requests.get(link[0])\n",
        "content = read.text\n",
        "data = StringIO(content)\n",
        "df = pd.read_csv(data, sep=\"\\s+\", header=None, names=[\"x1\", \"x2\", \"labels\"])\n",
        "numbers.append(df)\n",
        "dataset = pd.concat(numbers, ignore_index=True)\n",
        "# تعریف تابع k_media\n",
        "def k_median(data, k, max_iterations=200):\n",
        "    centers = data.sample(n=k, random_state=42).to_numpy()\n",
        "    for _ in range(max_iterations):\n",
        "        distances = np.linalg.norm(data.to_numpy()[:, np.newaxis] - centers, axis=2)\n",
        "        labels = np.argmin(distances, axis=1)\n",
        "        new_centers = np.array([np.median(data[labels == i].to_numpy(), axis=0) for i in range(k)])\n",
        "        if np.all(centers == new_centers):\n",
        "            break\n",
        "        centers = new_centers\n",
        "    return centers, labels\n",
        "k=3\n",
        "# زمان شروع\n",
        "start_time = time.time()\n",
        "centers, labels = k_median(dataset[[\"x1\", \"x2\"]], k)\n",
        "labels += 1\n",
        "dataset[\"new_labels\"] = labels\n",
        "# تعریف purity\n",
        "def purity_score(dataset):\n",
        "    total = 0\n",
        "    for i in range(k):\n",
        "        cluster_labels = dataset[dataset[\"new_labels\"] == (i + 1)][\"labels\"]\n",
        "        if len(cluster_labels) > 0:\n",
        "            most_common = Counter(cluster_labels).most_common(1)[0][1]\n",
        "            total += most_common\n",
        "    return total / len(dataset)\n",
        "purity = purity_score(dataset)\n",
        "# تعریف f_measure\n",
        "def f_measure(dataset):\n",
        "    precision_list = []\n",
        "    recall_list = []\n",
        "    for i in range(k):\n",
        "        true_labels = dataset[\"labels\"].to_numpy()\n",
        "        predicted_labels = (dataset[\"new_labels\"] == (i + 1)).to_numpy()\n",
        "        tp = np.sum((true_labels[predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fp = np.sum((true_labels[predicted_labels] != dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fn = np.sum((true_labels[~predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        precision_list.append(precision)\n",
        "        recall_list.append(recall)\n",
        "    precision = np.mean(precision_list)\n",
        "    recall = np.mean(recall_list)\n",
        "    f_measure_value = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    return f_measure_value\n",
        "f_measure_value = f_measure(dataset)\n",
        "#زمان پابان\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(\"Purity:\", purity)\n",
        "print(\"F-measure:\", f_measure_value)\n",
        "print(\"Execution time:\", execution_time)\n",
        "print(\"Dataset with new labels:\")\n",
        "print(dataset[[\"x1\", \"x2\", \"labels\", \"new_labels\"]].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tGV_aGc5LIir"
      },
      "outputs": [],
      "source": [
        "###################### با جابه جایی دو تا از مراکز با نقاط داده k_median محاسبه"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rb57LpdpLNST",
        "outputId": "6fd3b0c9-33d4-4392-df7e-3af22f5ae988"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Purity: 0.3557692307692308\n",
            "F-measure: 0.3275272872589949\n",
            "Execution time: 0.7037723064422607\n",
            "Dataset with new labels:\n",
            "      x1    x2  labels  new_labels\n",
            "0  31.95  7.95       3           2\n",
            "1  31.15  7.30       3           2\n",
            "2  30.45  6.65       3           2\n",
            "3  29.70  6.00       3           2\n",
            "4  28.90  5.55       3           2\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import requests\n",
        "from io import StringIO\n",
        "import time\n",
        "# بارگذاری داده‌ها\n",
        "link = [\"http://cs.joensuu.fi/sipu/datasets/spiral.txt\"]\n",
        "numbers = []\n",
        "read = requests.get(link[0])\n",
        "content = read.text\n",
        "data = StringIO(content)\n",
        "df = pd.read_csv(data, sep=\"\\s+\", header=None, names=[\"x1\", \"x2\", \"labels\"])\n",
        "numbers.append(df)\n",
        "dataset = pd.concat(numbers, ignore_index=True)\n",
        "# تعریف تابع k_median\n",
        "def k_median(data, k, max_iterations=200):\n",
        "    centers = data.sample(n=k, random_state=42).to_numpy()\n",
        "    for _ in range(max_iterations):\n",
        "        distances = np.linalg.norm(data.to_numpy()[:, np.newaxis] - centers, axis=2)\n",
        "        labels = np.argmin(distances, axis=1)\n",
        "        for i in range(0, k, 2):\n",
        "            if i < k and np.any(labels == i):\n",
        "                centers[i] = data.iloc[labels == i].median(axis=0).to_numpy()\n",
        "            if i + 1 < k and np.any(labels == (i + 1)):\n",
        "                centers[i + 1] = data.iloc[labels == (i + 1)].median(axis=0).to_numpy()\n",
        "        if np.allclose(centers, centers.mean(axis=0)):\n",
        "            break\n",
        "    return centers, labels\n",
        "k =3\n",
        "# زمان شروع\n",
        "start_time = time.time()\n",
        "centers, labels = k_median(dataset[[\"x1\", \"x2\"]], k)\n",
        "labels += 1\n",
        "dataset[\"new_labels\"] = labels\n",
        "# تعریف purity\n",
        "def purity_score(dataset):\n",
        "    total = 0\n",
        "    for i in range(k):\n",
        "        cluster_labels = dataset[dataset[\"new_labels\"] == (i + 1)][\"labels\"]\n",
        "        if len(cluster_labels) > 0:\n",
        "            most_common = Counter(cluster_labels).most_common(1)[0][1]\n",
        "            total += most_common\n",
        "    return total / len(dataset)\n",
        "purity = purity_score(dataset)\n",
        "# تعریف f_measure\n",
        "def f_measure(dataset):\n",
        "    precision_list = []\n",
        "    recall_list = []\n",
        "    for i in range(k):\n",
        "        true_labels = dataset[\"labels\"].to_numpy()\n",
        "        predicted_labels = (dataset[\"new_labels\"] == (i + 1)).to_numpy()\n",
        "        tp = np.sum((true_labels[predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fp = np.sum((true_labels[predicted_labels] != dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fn = np.sum((true_labels[~predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        precision_list.append(precision)\n",
        "        recall_list.append(recall)\n",
        "    precision = np.mean(precision_list)\n",
        "    recall = np.mean(recall_list)\n",
        "    f_measure_value = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    return f_measure_value\n",
        "f_measure_value = f_measure(dataset)\n",
        "# زمان پایان\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(\"Purity:\", purity)\n",
        "print(\"F-measure:\", f_measure_value)\n",
        "print(\"Execution time:\", execution_time)\n",
        "print(\"Dataset with new labels:\")\n",
        "print(dataset[[\"x1\", \"x2\", \"labels\", \"new_labels\"]].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RHAek1lXLcbu"
      },
      "outputs": [],
      "source": [
        "#################با کرنل دو جمله ای k_median محاسبه"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtxyHoTgLf2k",
        "outputId": "7ecf9df6-84c2-40ed-eb3f-e77f0db6a3d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Purity: 0.34615384615384615\n",
            "F-measure: 0.2775933272126493\n",
            "Execution time: 0.6780035495758057\n",
            "Dataset with new labels:\n",
            "      x1    x2  labels  new_labels\n",
            "0  31.95  7.95       3           3\n",
            "1  31.15  7.30       3           3\n",
            "2  30.45  6.65       3           3\n",
            "3  29.70  6.00       3           3\n",
            "4  28.90  5.55       3           3\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import requests\n",
        "from io import StringIO\n",
        "import time\n",
        "from sklearn.metrics.pairwise import polynomial_kernel\n",
        "\n",
        "# بارگذاری داده‌ها\n",
        "link = [\"http://cs.joensuu.fi/sipu/datasets/spiral.txt\"]\n",
        "numbers = []\n",
        "read = requests.get(link[0])\n",
        "content = read.text\n",
        "data = StringIO(content)\n",
        "df = pd.read_csv(data, sep=\"\\s+\", header=None, names=[\"x1\", \"x2\", \"labels\"])\n",
        "numbers.append(df)\n",
        "dataset = pd.concat(numbers, ignore_index=True)\n",
        "# تعریف تابع k_median_polynomial\n",
        "def k_median_polynomial(data, k, max_iterations=200):\n",
        "    centers = data.sample(n=k, random_state=42).to_numpy()\n",
        "    for _ in range(max_iterations):\n",
        "        similarity_matrix = polynomial_kernel(data, centers)\n",
        "        labels = np.argmax(similarity_matrix, axis=1)\n",
        "        new_centers = []\n",
        "        for i in range(k):\n",
        "            cluster_points = data.iloc[np.where(labels == i)]\n",
        "            if len(cluster_points) > 0:\n",
        "                new_centers.append(cluster_points.median(axis=0).to_numpy())\n",
        "            else:\n",
        "                new_centers.append(data.sample(n=1, random_state=42).to_numpy().flatten())\n",
        "        new_centers = np.array(new_centers)\n",
        "        if np.allclose(centers, new_centers, atol=1e-4):\n",
        "            break\n",
        "        centers = new_centers\n",
        "    return centers, labels\n",
        "\n",
        "k = 3\n",
        "# زمان شروع\n",
        "start_time = time.time()\n",
        "centers, labels = k_median_polynomial(dataset[[\"x1\", \"x2\"]], k)\n",
        "labels += 1\n",
        "dataset[\"new_labels\"] = labels\n",
        "# تعریف purity\n",
        "def purity_score(dataset):\n",
        "    total = 0\n",
        "    for i in range(k):\n",
        "        cluster_labels = dataset[dataset[\"new_labels\"] == (i + 1)][\"labels\"]\n",
        "        if len(cluster_labels) > 0:\n",
        "            most_common = Counter(cluster_labels).most_common(1)[0][1]\n",
        "            total += most_common\n",
        "    return total / len(dataset)\n",
        "\n",
        "purity = purity_score(dataset)\n",
        "\n",
        "# تعریف f_measure\n",
        "def f_measure(dataset):\n",
        "    precision_list = []\n",
        "    recall_list = []\n",
        "    for i in range(k):\n",
        "        true_labels = dataset[\"labels\"].to_numpy()\n",
        "        predicted_labels = (dataset[\"new_labels\"] == (i + 1)).to_numpy()\n",
        "        tp = np.sum((true_labels[predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fp = np.sum((true_labels[predicted_labels] != dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fn = np.sum((true_labels[~predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        precision_list.append(precision)\n",
        "        recall_list.append(recall)\n",
        "\n",
        "    precision = np.mean(precision_list)\n",
        "    recall = np.mean(recall_list)\n",
        "    f_measure_value = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    return f_measure_value\n",
        "\n",
        "f_measure_value = f_measure(dataset)\n",
        "\n",
        "# زمان پایان\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "\n",
        "print(\"Purity:\", purity)\n",
        "print(\"F-measure:\", f_measure_value)\n",
        "print(\"Execution time:\", execution_time)\n",
        "print(\"Dataset with new labels:\")\n",
        "print(dataset[[\"x1\", \"x2\", \"labels\", \"new_labels\"]].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zse-4XlPLsk0"
      },
      "outputs": [],
      "source": [
        "#################با کرنل  گوسی k_median محاسبه"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IwVDJYoMM7U",
        "outputId": "8324b963-8433-405e-9115-ed14d5887a80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Purity: 0.3557692307692308\n",
            "F-measure: 0.3275272872589949\n",
            "Execution time: 0.043892621994018555\n",
            "Dataset with new labels:\n",
            "      x1    x2  labels  new_labels\n",
            "0  31.95  7.95       3           2\n",
            "1  31.15  7.30       3           2\n",
            "2  30.45  6.65       3           2\n",
            "3  29.70  6.00       3           2\n",
            "4  28.90  5.55       3           2\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import requests\n",
        "from io import StringIO\n",
        "import time\n",
        "from sklearn.metrics.pairwise import rbf_kernel\n",
        "# بارگذاری داده‌ها\n",
        "link = [\"http://cs.joensuu.fi/sipu/datasets/spiral.txt\"]\n",
        "numbers = []\n",
        "read = requests.get(link[0])\n",
        "content = read.text\n",
        "data = StringIO(content)\n",
        "df = pd.read_csv(data, sep=\"\\s+\", header=None, names=[\"x1\", \"x2\", \"labels\"])\n",
        "numbers.append(df)\n",
        "dataset = pd.concat(numbers, ignore_index=True)\n",
        "# تعریف تابع k_median\n",
        "def k_median_rbf(data, k, max_iterations=100, gamma=0.5):\n",
        "    centers = data.sample(n=k, random_state=42).to_numpy()\n",
        "    for _ in range(max_iterations):\n",
        "        similarity_matrix = rbf_kernel(data, centers, gamma=gamma)\n",
        "        labels = np.argmax(similarity_matrix, axis=1)\n",
        "        new_centers = np.array([data[labels == i].median(axis=0) for i in range(k)])\n",
        "        if np.allclose(centers, new_centers):\n",
        "            break\n",
        "        centers = new_centers\n",
        "    return centers, labels\n",
        "k =3\n",
        "# زمان شروع\n",
        "start_time = time.time()\n",
        "centers, labels = k_median(dataset[[\"x1\", \"x2\"]], k)\n",
        "labels += 1\n",
        "dataset[\"new_labels\"] = labels\n",
        "# تعریف purity\n",
        "def purity_score(dataset):\n",
        "    total = 0\n",
        "    for i in range(k):\n",
        "        cluster_labels = dataset[dataset[\"new_labels\"] == (i + 1)][\"labels\"]\n",
        "        if len(cluster_labels) > 0:\n",
        "            most_common = Counter(cluster_labels).most_common(1)[0][1]\n",
        "            total += most_common\n",
        "    return total / len(dataset)\n",
        "purity = purity_score(dataset)\n",
        "# تعریف f_measure\n",
        "def f_measure(dataset):\n",
        "    precision_list = []\n",
        "    recall_list = []\n",
        "    for i in range(k):\n",
        "        true_labels = dataset[\"labels\"].to_numpy()\n",
        "        predicted_labels = (dataset[\"new_labels\"] == (i + 1)).to_numpy()\n",
        "        tp = np.sum((true_labels[predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fp = np.sum((true_labels[predicted_labels] != dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fn = np.sum((true_labels[~predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        precision_list.append(precision)\n",
        "        recall_list.append(recall)\n",
        "        precision = np.mean(precision_list)\n",
        "    recall = np.mean(recall_list)\n",
        "    f_measure_value = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    return f_measure_value\n",
        "f_measure_value = f_measure(dataset)\n",
        "# زمان پایان\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(\"Purity:\", purity)\n",
        "print(\"F-measure:\", f_measure_value)\n",
        "print(\"Execution time:\", execution_time)\n",
        "print(\"Dataset with new labels:\")\n",
        "print(dataset[[\"x1\", \"x2\", \"labels\", \"new_labels\"]].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8bYnIVJft9KM"
      },
      "outputs": [],
      "source": [
        "#################         الگوریتم خوشه بندی طیفی"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tFeQVfbMQh_",
        "outputId": "bf695a4a-7285-498f-f047-d968b26a4093"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Purity: 0.6121794871794872\n",
            "F-measure: 0.19995040176152726\n",
            "Execution time: 0.3169400691986084\n",
            "Dataset with new labels:\n",
            "      x1    x2  labels  new_labels\n",
            "0  31.95  7.95       3           2\n",
            "1  31.15  7.30       3           2\n",
            "2  30.45  6.65       3           2\n",
            "3  29.70  6.00       3           2\n",
            "4  28.90  5.55       3           2\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import requests\n",
        "from io import StringIO\n",
        "import time\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "from sklearn.cluster import KMeans\n",
        "from scipy.sparse.linalg import eigsh\n",
        "# بارگذاری داده‌ها\n",
        "link = [\"http://cs.joensuu.fi/sipu/datasets/spiral.txt\"]\n",
        "numbers = []\n",
        "read = requests.get(link[0])\n",
        "content = read.text\n",
        "data = StringIO(content)\n",
        "df = pd.read_csv(data, sep=\"\\s+\", header=None, names=[\"x1\", \"x2\", \"labels\"])\n",
        "numbers.append(df)\n",
        "dataset = pd.concat(numbers, ignore_index=True)\n",
        "# تابع خوشه‌بندی طیفی\n",
        "def spectral_clustering(data, k):\n",
        "    adjacency_matrix = kneighbors_graph(data, n_neighbors=l, mode='connectivity', include_self=False).toarray()\n",
        "    weight_matrix = adjacency_matrix * adjacency_matrix.T\n",
        "    degree_matrix = np.diag(weight_matrix.sum(axis=1))\n",
        "    laplacian_matrix = degree_matrix - weight_matrix\n",
        "    eigvals, eigvecs = eigsh(laplacian_matrix, k=l, which='SM')\n",
        "    kmeans = KMeans(n_clusters=k)\n",
        "    labels = kmeans.fit_predict(eigvecs)\n",
        "    return labels\n",
        "l=9\n",
        "k =3\n",
        "# زمان شروع\n",
        "start_time = time.time()\n",
        "labels = spectral_clustering(dataset[[\"x1\", \"x2\"]], k)\n",
        "labels += 1\n",
        "dataset[\"new_labels\"] = labels\n",
        "# تعریف purity\n",
        "def purity_score(dataset):\n",
        "    total = 0\n",
        "    for i in range(k):\n",
        "        cluster_labels = dataset[dataset[\"new_labels\"] == (i + 1)][\"labels\"]\n",
        "        if len(cluster_labels) > 0:\n",
        "            most_common = Counter(cluster_labels).most_common(1)[0][1]\n",
        "            total += most_common\n",
        "    return total / len(dataset)\n",
        "purity = purity_score(dataset)\n",
        "# تعریف f_measure\n",
        "def f_measure(dataset):\n",
        "    precision_list = []\n",
        "    recall_list = []\n",
        "    for i in range(k):\n",
        "        true_labels = dataset[\"labels\"].to_numpy()\n",
        "        predicted_labels = (dataset[\"new_labels\"] == (i + 1)).to_numpy()\n",
        "        tp = np.sum((true_labels[predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fp = np.sum((true_labels[predicted_labels] != dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fn = np.sum((true_labels[~predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        precision_list.append(precision)\n",
        "        recall_list.append(recall)\n",
        "    precision = np.mean(precision_list)\n",
        "    recall = np.mean(recall_list)\n",
        "    f_measure_value = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    return f_measure_value\n",
        "f_measure_value = f_measure(dataset)\n",
        "# زمان پایان\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(\"Purity:\", purity)\n",
        "print(\"F-measure:\", f_measure_value)\n",
        "print(\"Execution time:\", execution_time)\n",
        "print(\"Dataset with new labels:\")\n",
        "print(dataset[[\"x1\", \"x2\", \"labels\", \"new_labels\"]].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ve_Ge9sFBHwP",
        "outputId": "fe59c67f-cfa1-421c-9cb5-a7f6e7441a2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "مقایسه نتایج الگوریتم‌ها:\n",
            "             Algorithm    Purity  F-measure  Execution Time\n",
            "0             k_median  0.355769   0.327527        0.030015\n",
            "1            k_median2  0.355769   0.327527        0.399443\n",
            "2  spectral_clustering  0.657051   0.079365        0.081156\n",
            "3  k_median_polynomial  0.346154   0.277593        0.799428\n",
            "4         k_median_rbf  0.355769   0.327527        0.030217\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import requests\n",
        "from io import StringIO\n",
        "import time\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics.pairwise import polynomial_kernel, rbf_kernel\n",
        "from scipy.sparse.linalg import eigsh\n",
        "\n",
        "# بارگذاری داده‌ها\n",
        "link = [\"http://cs.joensuu.fi/sipu/datasets/spiral.txt\"]\n",
        "numbers = []\n",
        "read = requests.get(link[0])\n",
        "content = read.text\n",
        "data = StringIO(content)\n",
        "df = pd.read_csv(data, sep=\"\\s+\", header=None, names=[\"x1\", \"x2\", \"labels\"])\n",
        "numbers.append(df)\n",
        "dataset = pd.concat(numbers, ignore_index=True)\n",
        "k=3\n",
        "l=9\n",
        "\n",
        "# تعریف تابع k_median\n",
        "def k_median(data, k, max_iterations=200):\n",
        "    centers = data.sample(n=k, random_state=42).to_numpy()\n",
        "    for _ in range(max_iterations):\n",
        "        distances = np.linalg.norm(data.to_numpy()[:, np.newaxis] - centers, axis=2)\n",
        "        labels = np.argmin(distances, axis=1)\n",
        "        new_centers = np.array([np.median(data[labels == i].to_numpy(), axis=0) for i in range(k)])\n",
        "        if np.all(centers == new_centers):\n",
        "            break\n",
        "        centers = new_centers\n",
        "    return centers, labels\n",
        "\n",
        "# نسخه دوم k_median (با فواصل مشابه نسخه اول شما)\n",
        "def k_median2(data, k, max_iterations=200):\n",
        "    centers = data.sample(n=k, random_state=42).to_numpy()\n",
        "    for _ in range(max_iterations):\n",
        "        distances = np.linalg.norm(data.to_numpy()[:, np.newaxis] - centers, axis=2)\n",
        "        labels = np.argmin(distances, axis=1)\n",
        "        for i in range(0, k, 2):\n",
        "            if i < k and np.any(labels == i):\n",
        "                centers[i] = data.iloc[labels == i].median(axis=0).to_numpy()\n",
        "            if i + 1 < k and np.any(labels == (i + 1)):\n",
        "                centers[i + 1] = data.iloc[labels == (i + 1)].median(axis=0).to_numpy()\n",
        "        if np.allclose(centers, centers.mean(axis=0)):\n",
        "            break\n",
        "    return centers, labels\n",
        "\n",
        "# K-Median با کرنل چندجمله‌ای\n",
        "def k_median_polynomial(data, k, max_iterations=200):\n",
        "    centers = data.sample(n=k, random_state=42).to_numpy()\n",
        "    for _ in range(max_iterations):\n",
        "        similarity_matrix = polynomial_kernel(data, centers)\n",
        "        labels = np.argmax(similarity_matrix, axis=1)\n",
        "        new_centers = []\n",
        "        for i in range(k):\n",
        "            cluster_points = data.iloc[np.where(labels == i)]\n",
        "            if len(cluster_points) > 0:\n",
        "                new_centers.append(cluster_points.median(axis=0).to_numpy())\n",
        "            else:\n",
        "                new_centers.append(data.sample(n=1, random_state=42).to_numpy().flatten())\n",
        "        new_centers = np.array(new_centers)\n",
        "        if np.allclose(centers, new_centers, atol=1e-4):\n",
        "            break\n",
        "        centers = new_centers\n",
        "    return centers, labels\n",
        "\n",
        "# K-Median با کرنل گوسی\n",
        "def k_median_rbf(data, k, max_iterations=100, gamma=0.5):\n",
        "    centers = data.sample(n=k, random_state=42).to_numpy()\n",
        "    for _ in range(max_iterations):\n",
        "        similarity_matrix = rbf_kernel(data, centers, gamma=gamma)\n",
        "        labels = np.argmax(similarity_matrix, axis=1)\n",
        "        new_centers = np.array([data[labels == i].median(axis=0) for i in range(k)])\n",
        "        if np.allclose(centers, new_centers):\n",
        "            break\n",
        "        centers = new_centers\n",
        "    return centers, labels\n",
        "\n",
        "# خوشه‌بندی طیفی\n",
        "def spectral_clustering(data, k):\n",
        "    adjacency_matrix = kneighbors_graph(data, n_neighbors=l, mode='connectivity', include_self=False).toarray()\n",
        "    weight_matrix = adjacency_matrix * adjacency_matrix.T\n",
        "    degree_matrix = np.diag(weight_matrix.sum(axis=1))\n",
        "    laplacian_matrix = degree_matrix - weight_matrix\n",
        "    eigvals, eigvecs = eigsh(laplacian_matrix, k=l, which='SM')\n",
        "    kmeans = KMeans(n_clusters=k)\n",
        "    labels = kmeans.fit_predict(eigvecs)\n",
        "    return labels\n",
        "\n",
        "# محاسبه Purity\n",
        "def purity_score(dataset):\n",
        "    total = 0\n",
        "    for i in range(k):\n",
        "        cluster_labels = dataset[dataset[\"new_labels\"] == (i + 1)][\"labels\"]\n",
        "        if len(cluster_labels) > 0:\n",
        "            most_common = Counter(cluster_labels).most_common(1)[0][1]\n",
        "            total += most_common\n",
        "    return total / len(dataset)\n",
        "\n",
        "# محاسبه F-measure\n",
        "def f_measure(dataset):\n",
        "    precision_list = []\n",
        "    recall_list = []\n",
        "    for i in range(k):\n",
        "        true_labels = dataset[\"labels\"].to_numpy()\n",
        "        predicted_labels = (dataset[\"new_labels\"] == (i + 1)).to_numpy()\n",
        "        tp = np.sum((true_labels[predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fp = np.sum((true_labels[predicted_labels] != dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fn = np.sum((true_labels[~predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        precision_list.append(precision)\n",
        "        recall_list.append(recall)\n",
        "    precision = np.mean(precision_list)\n",
        "    recall = np.mean(recall_list)\n",
        "    f_measure_value = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    return f_measure_value\n",
        "\n",
        "# اجرای الگوریتم‌ها\n",
        "def run_algorithm(algorithm, dataset, k):\n",
        "    start_time = time.time()\n",
        "    if algorithm == spectral_clustering:\n",
        "        labels = algorithm(dataset[[\"x1\", \"x2\"]], k)\n",
        "        centers = None\n",
        "    else:\n",
        "        centers, labels = algorithm(dataset[[\"x1\", \"x2\"]], k)\n",
        "    labels += 1\n",
        "    dataset[\"new_labels\"] = labels\n",
        "    purity = purity_score(dataset)\n",
        "    f_measure_value = f_measure(dataset)\n",
        "    end_time = time.time()\n",
        "    execution_time = end_time - start_time\n",
        "    return purity, f_measure_value, execution_time, dataset\n",
        "\n",
        "# نتایج\n",
        "results = []\n",
        "algorithms = [k_median, k_median2, spectral_clustering, k_median_polynomial, k_median_rbf]\n",
        "for algorithm in algorithms:\n",
        "    purity, f_measure_value, execution_time, dataset_with_labels = run_algorithm(algorithm, dataset.copy(), k)\n",
        "    results.append({\n",
        "        \"Algorithm\": algorithm.__name__,\n",
        "        \"Purity\": purity,\n",
        "        \"F-measure\": f_measure_value,\n",
        "        \"Execution Time\": execution_time\n",
        "    })\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "# مقایسه نتایج\n",
        "print(\"مقایسه نتایج الگوریتم‌ها:\")\n",
        "print(results_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mpg4ZjFNMdlU"
      },
      "outputs": [],
      "source": [
        "########################انجام الگوریتم ها در تکست پنجم(D31.txt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lcUfg0IiMoz-"
      },
      "outputs": [],
      "source": [
        "###################با جابه جایی یکی از مراکز با نقاط داده k_median"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNe5QbWUMs7d",
        "outputId": "e9f264dc-c07d-44e5-f7b0-a522178e18c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Purity: 0.7893548387096774\n",
            "F-measure: 0.0008378718056137411\n",
            "Execution time: 0.30080747604370117\n",
            "Dataset with new labels:\n",
            "        x1      x2  labels  new_labels\n",
            "0  25.0514  5.7475       1          14\n",
            "1  26.6614  7.3414       1          30\n",
            "2  25.2653  6.2466       1          14\n",
            "3  25.2285  4.7447       1          14\n",
            "4  25.7529  5.1564       1          14\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import requests\n",
        "from io import StringIO\n",
        "import time\n",
        "# بارگذاری داده‌ها\n",
        "link= [\"http://cs.joensuu.fi/sipu/datasets/D31.txt\"]\n",
        "numbers = []\n",
        "read = requests.get(link[0])\n",
        "content = read.text\n",
        "data = StringIO(content)\n",
        "df = pd.read_csv(data, sep=\"\\s+\", header=None, names=[\"x1\", \"x2\", \"labels\"])\n",
        "numbers.append(df)\n",
        "dataset = pd.concat(numbers, ignore_index=True)\n",
        "# تعریف تابع k_media\n",
        "def k_median(data, k, max_iterations=200):\n",
        "    centers = data.sample(n=k, random_state=42).to_numpy()\n",
        "    for _ in range(max_iterations):\n",
        "        distances = np.linalg.norm(data.to_numpy()[:, np.newaxis] - centers, axis=2)\n",
        "        labels = np.argmin(distances, axis=1)\n",
        "        new_centers = np.array([np.median(data[labels == i].to_numpy(), axis=0) for i in range(k)])\n",
        "        if np.all(centers == new_centers):\n",
        "            break\n",
        "        centers = new_centers\n",
        "    return centers, labels\n",
        "k=31\n",
        "# زمان شروع\n",
        "start_time = time.time()\n",
        "centers, labels = k_median(dataset[[\"x1\", \"x2\"]], k)\n",
        "labels += 1\n",
        "dataset[\"new_labels\"] = labels\n",
        "# تعریف purity\n",
        "def purity_score(dataset):\n",
        "    total = 0\n",
        "    for i in range(k):\n",
        "        cluster_labels = dataset[dataset[\"new_labels\"] == (i + 1)][\"labels\"]\n",
        "        if len(cluster_labels) > 0:\n",
        "            most_common = Counter(cluster_labels).most_common(1)[0][1]\n",
        "            total += most_common\n",
        "    return total / len(dataset)\n",
        "purity = purity_score(dataset)\n",
        "# تعریف f_measure\n",
        "def f_measure(dataset):\n",
        "    precision_list = []\n",
        "    recall_list = []\n",
        "    for i in range(k):\n",
        "        true_labels = dataset[\"labels\"].to_numpy()\n",
        "        predicted_labels = (dataset[\"new_labels\"] == (i + 1)).to_numpy()\n",
        "        tp = np.sum((true_labels[predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fp = np.sum((true_labels[predicted_labels] != dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fn = np.sum((true_labels[~predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        precision_list.append(precision)\n",
        "        recall_list.append(recall)\n",
        "    precision = np.mean(precision_list)\n",
        "    recall = np.mean(recall_list)\n",
        "    f_measure_value = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    return f_measure_value\n",
        "f_measure_value = f_measure(dataset)\n",
        "#زمان پابان\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(\"Purity:\", purity)\n",
        "print(\"F-measure:\", f_measure_value)\n",
        "print(\"Execution time:\", execution_time)\n",
        "print(\"Dataset with new labels:\")\n",
        "print(dataset[[\"x1\", \"x2\", \"labels\", \"new_labels\"]].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2x5wqXsXNFcN"
      },
      "outputs": [],
      "source": [
        "###################### با جابه جایی دو تا از مراکز با نقاط داده k_median محاسبه"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MuZS8R4NKQY",
        "outputId": "439c0f83-9bea-49d8-c540-ccc8988aa4f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Purity: 0.7893548387096774\n",
            "F-measure: 0.0008378718056137411\n",
            "Execution time: 6.320572137832642\n",
            "Dataset with new labels:\n",
            "        x1      x2  labels  new_labels\n",
            "0  25.0514  5.7475       1          14\n",
            "1  26.6614  7.3414       1          30\n",
            "2  25.2653  6.2466       1          14\n",
            "3  25.2285  4.7447       1          14\n",
            "4  25.7529  5.1564       1          14\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import requests\n",
        "from io import StringIO\n",
        "import time\n",
        "# بارگذاری داده‌ها\n",
        "link = [\"http://cs.joensuu.fi/sipu/datasets/D31.txt\"]\n",
        "numbers = []\n",
        "read = requests.get(link[0])\n",
        "content = read.text\n",
        "data = StringIO(content)\n",
        "df = pd.read_csv(data, sep=\"\\s+\", header=None, names=[\"x1\", \"x2\", \"labels\"])\n",
        "numbers.append(df)\n",
        "dataset = pd.concat(numbers, ignore_index=True)\n",
        "# تعریف تابع k_median\n",
        "def k_median(data, k, max_iterations=200):\n",
        "    centers = data.sample(n=k, random_state=42).to_numpy()\n",
        "    for _ in range(max_iterations):\n",
        "        distances = np.linalg.norm(data.to_numpy()[:, np.newaxis] - centers, axis=2)\n",
        "        labels = np.argmin(distances, axis=1)\n",
        "        for i in range(0, k, 2):\n",
        "            if i < k and np.any(labels == i):\n",
        "                centers[i] = data.iloc[labels == i].median(axis=0).to_numpy()\n",
        "            if i + 1 < k and np.any(labels == (i + 1)):\n",
        "                centers[i + 1] = data.iloc[labels == (i + 1)].median(axis=0).to_numpy()\n",
        "        if np.allclose(centers, centers.mean(axis=0)):\n",
        "            break\n",
        "    return centers, labels\n",
        "k =31\n",
        "# زمان شروع\n",
        "start_time = time.time()\n",
        "centers, labels = k_median(dataset[[\"x1\", \"x2\"]], k)\n",
        "labels += 1\n",
        "dataset[\"new_labels\"] = labels\n",
        "# تعریف purity\n",
        "def purity_score(dataset):\n",
        "    total = 0\n",
        "    for i in range(k):\n",
        "        cluster_labels = dataset[dataset[\"new_labels\"] == (i + 1)][\"labels\"]\n",
        "        if len(cluster_labels) > 0:\n",
        "            most_common = Counter(cluster_labels).most_common(1)[0][1]\n",
        "            total += most_common\n",
        "    return total / len(dataset)\n",
        "purity = purity_score(dataset)\n",
        "# تعریف f_measure\n",
        "def f_measure(dataset):\n",
        "    precision_list = []\n",
        "    recall_list = []\n",
        "    for i in range(k):\n",
        "        true_labels = dataset[\"labels\"].to_numpy()\n",
        "        predicted_labels = (dataset[\"new_labels\"] == (i + 1)).to_numpy()\n",
        "        tp = np.sum((true_labels[predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fp = np.sum((true_labels[predicted_labels] != dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fn = np.sum((true_labels[~predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        precision_list.append(precision)\n",
        "        recall_list.append(recall)\n",
        "    precision = np.mean(precision_list)\n",
        "    recall = np.mean(recall_list)\n",
        "    f_measure_value = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    return f_measure_value\n",
        "f_measure_value = f_measure(dataset)\n",
        "# زمان پایان\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(\"Purity:\", purity)\n",
        "print(\"F-measure:\", f_measure_value)\n",
        "print(\"Execution time:\", execution_time)\n",
        "print(\"Dataset with new labels:\")\n",
        "print(dataset[[\"x1\", \"x2\", \"labels\", \"new_labels\"]].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MftQ6Y3kNdkt"
      },
      "outputs": [],
      "source": [
        "#################با کرنل دو جمله ای k_median محاسبه"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWk8HkVMNhZ9",
        "outputId": "b84602fa-81bf-4504-c5bc-263d8b1ed61a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Purity: 0.06451612903225806\n",
            "F-measure: 0.00019424210891432535\n",
            "Execution time: 5.582829236984253\n",
            "Dataset with new labels:\n",
            "        x1      x2  labels  new_labels\n",
            "0  25.0514  5.7475       1          10\n",
            "1  26.6614  7.3414       1          10\n",
            "2  25.2653  6.2466       1          10\n",
            "3  25.2285  4.7447       1          10\n",
            "4  25.7529  5.1564       1          10\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import requests\n",
        "from io import StringIO\n",
        "import time\n",
        "from sklearn.metrics.pairwise import polynomial_kernel\n",
        "\n",
        "# بارگذاری داده‌ها\n",
        "link = [\"http://cs.joensuu.fi/sipu/datasets/D31.txt\"]\n",
        "numbers = []\n",
        "read = requests.get(link[0])\n",
        "content = read.text\n",
        "data = StringIO(content)\n",
        "df = pd.read_csv(data, sep=\"\\s+\", header=None, names=[\"x1\", \"x2\", \"labels\"])\n",
        "numbers.append(df)\n",
        "dataset = pd.concat(numbers, ignore_index=True)\n",
        "# تعریف تابع k_median_polynomial\n",
        "def k_median_polynomial(data, k, max_iterations=200):\n",
        "    centers = data.sample(n=k, random_state=42).to_numpy()\n",
        "    for _ in range(max_iterations):\n",
        "        similarity_matrix = polynomial_kernel(data, centers)\n",
        "        labels = np.argmax(similarity_matrix, axis=1)\n",
        "        new_centers = []\n",
        "        for i in range(k):\n",
        "            cluster_points = data.iloc[np.where(labels == i)]\n",
        "            if len(cluster_points) > 0:\n",
        "                new_centers.append(cluster_points.median(axis=0).to_numpy())\n",
        "            else:\n",
        "                new_centers.append(data.sample(n=1, random_state=42).to_numpy().flatten())\n",
        "        new_centers = np.array(new_centers)\n",
        "        if np.allclose(centers, new_centers, atol=1e-4):\n",
        "            break\n",
        "        centers = new_centers\n",
        "    return centers, labels\n",
        "\n",
        "k = 31\n",
        "# زمان شروع\n",
        "start_time = time.time()\n",
        "centers, labels = k_median_polynomial(dataset[[\"x1\", \"x2\"]], k)\n",
        "labels += 1\n",
        "dataset[\"new_labels\"] = labels\n",
        "# تعریف purity\n",
        "def purity_score(dataset):\n",
        "    total = 0\n",
        "    for i in range(k):\n",
        "        cluster_labels = dataset[dataset[\"new_labels\"] == (i + 1)][\"labels\"]\n",
        "        if len(cluster_labels) > 0:\n",
        "            most_common = Counter(cluster_labels).most_common(1)[0][1]\n",
        "            total += most_common\n",
        "    return total / len(dataset)\n",
        "\n",
        "purity = purity_score(dataset)\n",
        "\n",
        "# تعریف f_measure\n",
        "def f_measure(dataset):\n",
        "    precision_list = []\n",
        "    recall_list = []\n",
        "    for i in range(k):\n",
        "        true_labels = dataset[\"labels\"].to_numpy()\n",
        "        predicted_labels = (dataset[\"new_labels\"] == (i + 1)).to_numpy()\n",
        "        tp = np.sum((true_labels[predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fp = np.sum((true_labels[predicted_labels] != dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fn = np.sum((true_labels[~predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        precision_list.append(precision)\n",
        "        recall_list.append(recall)\n",
        "\n",
        "    precision = np.mean(precision_list)\n",
        "    recall = np.mean(recall_list)\n",
        "    f_measure_value = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    return f_measure_value\n",
        "\n",
        "f_measure_value = f_measure(dataset)\n",
        "\n",
        "# زمان پایان\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "\n",
        "print(\"Purity:\", purity)\n",
        "print(\"F-measure:\", f_measure_value)\n",
        "print(\"Execution time:\", execution_time)\n",
        "print(\"Dataset with new labels:\")\n",
        "print(dataset[[\"x1\", \"x2\", \"labels\", \"new_labels\"]].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ir7ytLYLgxHq"
      },
      "outputs": [],
      "source": [
        "#################با کرنل  گوسی k_median محاسبه"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gxl3p5cNg27J",
        "outputId": "274f6781-b886-43a4-acf4-ad9e2a43801d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Purity: 0.7893548387096774\n",
            "F-measure: 0.0008378718056137411\n",
            "Execution time: 0.46477818489074707\n",
            "Dataset with new labels:\n",
            "        x1      x2  labels  new_labels\n",
            "0  25.0514  5.7475       1          14\n",
            "1  26.6614  7.3414       1          30\n",
            "2  25.2653  6.2466       1          14\n",
            "3  25.2285  4.7447       1          14\n",
            "4  25.7529  5.1564       1          14\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import requests\n",
        "from io import StringIO\n",
        "import time\n",
        "from sklearn.metrics.pairwise import rbf_kernel\n",
        "\n",
        "# بارگذاری داده‌ها\n",
        "link = [\"http://cs.joensuu.fi/sipu/datasets/D31.txt\"]\n",
        "numbers = []\n",
        "read = requests.get(link[0])\n",
        "content = read.text\n",
        "data = StringIO(content)\n",
        "df = pd.read_csv(data, sep=\"\\s+\", header=None, names=[\"x1\", \"x2\", \"labels\"])\n",
        "numbers.append(df)\n",
        "dataset = pd.concat(numbers, ignore_index=True)\n",
        "\n",
        "# تعریف تابع k_median\n",
        "def k_median_rbf(data, k, max_iterations=100, gamma=0.5):\n",
        "    centers = data.sample(n=k, random_state=42).to_numpy()\n",
        "    for _ in range(max_iterations):\n",
        "        similarity_matrix = rbf_kernel(data.to_numpy(), centers, gamma=gamma)\n",
        "        labels = np.argmax(similarity_matrix, axis=1)\n",
        "        new_centers = []\n",
        "        for i in range(k):\n",
        "            cluster_points = data.iloc[np.where(labels == i)]\n",
        "            if len(cluster_points) > 0:\n",
        "                new_centers.append(cluster_points.median(axis=0).to_numpy())\n",
        "            else:\n",
        "                new_centers.append(data.sample(n=1, random_state=42).to_numpy().flatten())\n",
        "        new_centers = np.array(new_centers)\n",
        "        if np.allclose(centers, new_centers, atol=1e-4):\n",
        "            break\n",
        "        centers = new_centers\n",
        "    return centers, labels\n",
        "\n",
        "k = 31\n",
        "\n",
        "# زمان شروع\n",
        "start_time = time.time()\n",
        "centers, labels = k_median_rbf(dataset[[\"x1\", \"x2\"]], k)\n",
        "labels += 1\n",
        "dataset[\"new_labels\"] = labels\n",
        "\n",
        "# تعریف purity\n",
        "def purity_score(dataset):\n",
        "    total = 0\n",
        "    for i in range(k):\n",
        "        cluster_labels = dataset[dataset[\"new_labels\"] == (i + 1)][\"labels\"]\n",
        "        if len(cluster_labels) > 0:\n",
        "            most_common = Counter(cluster_labels).most_common(1)[0][1]\n",
        "            total += most_common\n",
        "    return total / len(dataset)\n",
        "\n",
        "purity = purity_score(dataset)\n",
        "\n",
        "# تعریف f_measure\n",
        "def f_measure(dataset):\n",
        "    precision_list = []\n",
        "    recall_list = []\n",
        "    for i in range(k):\n",
        "        true_labels = dataset[\"labels\"].to_numpy()\n",
        "        predicted_labels = dataset[\"new_labels\"].to_numpy()\n",
        "        tp = np.sum((true_labels == i + 1) & (predicted_labels == i + 1))\n",
        "        fp = np.sum((true_labels != i + 1) & (predicted_labels == i + 1))\n",
        "        fn = np.sum((true_labels == i + 1) & (predicted_labels != i + 1))\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        precision_list.append(precision)\n",
        "        recall_list.append(recall)\n",
        "    precision = np.mean(precision_list)\n",
        "    recall = np.mean(recall_list)\n",
        "    f_measure_value = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    return f_measure_value\n",
        "\n",
        "f_measure_value = f_measure(dataset)\n",
        "\n",
        "# زمان پایان\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "\n",
        "print(\"Purity:\", purity)\n",
        "print(\"F-measure:\", f_measure_value)\n",
        "print(\"Execution time:\", execution_time)\n",
        "print(\"Dataset with new labels:\")\n",
        "print(dataset[[\"x1\", \"x2\", \"labels\", \"new_labels\"]].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oW0_HhprilAd"
      },
      "outputs": [],
      "source": [
        "#################         الگوریتم خوشه بندی طیفی"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fD1PuHfxipAn",
        "outputId": "962d6095-779b-463e-bd6d-e8bb533b6a6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Purity: 0.6083870967741936\n",
            "F-measure: 0.06665165055605297\n",
            "Execution time: 90.07427644729614\n",
            "Dataset with new labels:\n",
            "        x1      x2  labels  new_labels\n",
            "0  25.0514  5.7475       1           2\n",
            "1  26.6614  7.3414       1           2\n",
            "2  25.2653  6.2466       1           2\n",
            "3  25.2285  4.7447       1           2\n",
            "4  25.7529  5.1564       1           2\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import requests\n",
        "from io import StringIO\n",
        "import time\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "from sklearn.cluster import KMeans\n",
        "from scipy.sparse.linalg import eigsh\n",
        "# بارگذاری داده‌ها\n",
        "link = [\"http://cs.joensuu.fi/sipu/datasets/D31.txt\"]\n",
        "numbers = []\n",
        "read = requests.get(link[0])\n",
        "content = read.text\n",
        "data = StringIO(content)\n",
        "df = pd.read_csv(data, sep=\"\\s+\", header=None, names=[\"x1\", \"x2\", \"labels\"])\n",
        "numbers.append(df)\n",
        "dataset = pd.concat(numbers, ignore_index=True)\n",
        "# تابع خوشه‌بندی طیفی\n",
        "def spectral_clustering(data, k):\n",
        "    adjacency_matrix = kneighbors_graph(data, n_neighbors=l, mode='connectivity', include_self=False).toarray()\n",
        "    weight_matrix = adjacency_matrix * adjacency_matrix.T\n",
        "    degree_matrix = np.diag(weight_matrix.sum(axis=1))\n",
        "    laplacian_matrix = degree_matrix - weight_matrix\n",
        "    eigvals, eigvecs = eigsh(laplacian_matrix, k=l, which='SM')\n",
        "    kmeans = KMeans(n_clusters=k)\n",
        "    labels = kmeans.fit_predict(eigvecs)\n",
        "    return labels\n",
        "l=9\n",
        "k =31\n",
        "# زمان شروع\n",
        "start_time = time.time()\n",
        "labels = spectral_clustering(dataset[[\"x1\", \"x2\"]], k)\n",
        "labels += 1\n",
        "dataset[\"new_labels\"] = labels\n",
        "# تعریف purity\n",
        "def purity_score(dataset):\n",
        "    total = 0\n",
        "    for i in range(k):\n",
        "        cluster_labels = dataset[dataset[\"new_labels\"] == (i + 1)][\"labels\"]\n",
        "        if len(cluster_labels) > 0:\n",
        "            most_common = Counter(cluster_labels).most_common(1)[0][1]\n",
        "            total += most_common\n",
        "    return total / len(dataset)\n",
        "purity = purity_score(dataset)\n",
        "# تعریف f_measure\n",
        "def f_measure(dataset):\n",
        "    precision_list = []\n",
        "    recall_list = []\n",
        "    for i in range(k):\n",
        "        true_labels = dataset[\"labels\"].to_numpy()\n",
        "        predicted_labels = (dataset[\"new_labels\"] == (i + 1)).to_numpy()\n",
        "        tp = np.sum((true_labels[predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fp = np.sum((true_labels[predicted_labels] != dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fn = np.sum((true_labels[~predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        precision_list.append(precision)\n",
        "        recall_list.append(recall)\n",
        "    precision = np.mean(precision_list)\n",
        "    recall = np.mean(recall_list)\n",
        "    f_measure_value = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    return f_measure_value\n",
        "f_measure_value = f_measure(dataset)\n",
        "# زمان پایان\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(\"Purity:\", purity)\n",
        "print(\"F-measure:\", f_measure_value)\n",
        "print(\"Execution time:\", execution_time)\n",
        "print(\"Dataset with new labels:\")\n",
        "print(dataset[[\"x1\", \"x2\", \"labels\", \"new_labels\"]].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npZ7HcPQFv-5",
        "outputId": "a85c6265-1056-4993-ad6c-8785d6062d88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "مقایسه نتایج الگوریتم‌ها:\n",
            "             Algorithm    Purity  F-measure  Execution Time\n",
            "0             k_median  0.789355   0.000838        0.171317\n",
            "1            k_median2  0.789355   0.000838        3.196847\n",
            "2  spectral_clustering  0.577097   0.089400       71.564161\n",
            "3  k_median_polynomial  0.064516   0.000194        5.688468\n",
            "4         k_median_rbf  0.789355   0.000838        0.165985\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import requests\n",
        "from io import StringIO\n",
        "import time\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics.pairwise import polynomial_kernel, rbf_kernel\n",
        "from scipy.sparse.linalg import eigsh\n",
        "\n",
        "# بارگذاری داده‌ها\n",
        "link = [\"http://cs.joensuu.fi/sipu/datasets/D31.txt\"]\n",
        "numbers = []\n",
        "read = requests.get(link[0])\n",
        "content = read.text\n",
        "data = StringIO(content)\n",
        "df = pd.read_csv(data, sep=\"\\s+\", header=None, names=[\"x1\", \"x2\", \"labels\"])\n",
        "numbers.append(df)\n",
        "dataset = pd.concat(numbers, ignore_index=True)\n",
        "k=31\n",
        "l=9\n",
        "\n",
        "# تعریف تابع k_median\n",
        "def k_median(data, k, max_iterations=200):\n",
        "    centers = data.sample(n=k, random_state=42).to_numpy()\n",
        "    for _ in range(max_iterations):\n",
        "        distances = np.linalg.norm(data.to_numpy()[:, np.newaxis] - centers, axis=2)\n",
        "        labels = np.argmin(distances, axis=1)\n",
        "        new_centers = np.array([np.median(data[labels == i].to_numpy(), axis=0) for i in range(k)])\n",
        "        if np.all(centers == new_centers):\n",
        "            break\n",
        "        centers = new_centers\n",
        "    return centers, labels\n",
        "\n",
        "# نسخه دوم k_median (با فواصل مشابه نسخه اول شما)\n",
        "def k_median2(data, k, max_iterations=200):\n",
        "    centers = data.sample(n=k, random_state=42).to_numpy()\n",
        "    for _ in range(max_iterations):\n",
        "        distances = np.linalg.norm(data.to_numpy()[:, np.newaxis] - centers, axis=2)\n",
        "        labels = np.argmin(distances, axis=1)\n",
        "        for i in range(0, k, 2):\n",
        "            if i < k and np.any(labels == i):\n",
        "                centers[i] = data.iloc[labels == i].median(axis=0).to_numpy()\n",
        "            if i + 1 < k and np.any(labels == (i + 1)):\n",
        "                centers[i + 1] = data.iloc[labels == (i + 1)].median(axis=0).to_numpy()\n",
        "        if np.allclose(centers, centers.mean(axis=0)):\n",
        "            break\n",
        "    return centers, labels\n",
        "\n",
        "# K-Median با کرنل چندجمله‌ای\n",
        "def k_median_polynomial(data, k, max_iterations=200):\n",
        "    centers = data.sample(n=k, random_state=42).to_numpy()\n",
        "    for _ in range(max_iterations):\n",
        "        similarity_matrix = polynomial_kernel(data, centers)\n",
        "        labels = np.argmax(similarity_matrix, axis=1)\n",
        "        new_centers = []\n",
        "        for i in range(k):\n",
        "            cluster_points = data.iloc[np.where(labels == i)]\n",
        "            if len(cluster_points) > 0:\n",
        "                new_centers.append(cluster_points.median(axis=0).to_numpy())\n",
        "            else:\n",
        "                new_centers.append(data.sample(n=1, random_state=42).to_numpy().flatten())\n",
        "        new_centers = np.array(new_centers)\n",
        "        if np.allclose(centers, new_centers, atol=1e-4):\n",
        "            break\n",
        "        centers = new_centers\n",
        "    return centers, labels\n",
        "\n",
        "# K-Median با کرنل گوسی\n",
        "def k_median_rbf(data, k, max_iterations=100, gamma=0.5):\n",
        "    centers = data.sample(n=k, random_state=42).to_numpy()\n",
        "    for _ in range(max_iterations):\n",
        "        similarity_matrix = rbf_kernel(data, centers, gamma=gamma)\n",
        "        labels = np.argmax(similarity_matrix, axis=1)\n",
        "        new_centers = np.array([data[labels == i].median(axis=0) for i in range(k)])\n",
        "        if np.allclose(centers, new_centers):\n",
        "            break\n",
        "        centers = new_centers\n",
        "    return centers, labels\n",
        "\n",
        "# خوشه‌بندی طیفی\n",
        "def spectral_clustering(data, k):\n",
        "    adjacency_matrix = kneighbors_graph(data, n_neighbors=l, mode='connectivity', include_self=False).toarray()\n",
        "    weight_matrix = adjacency_matrix * adjacency_matrix.T\n",
        "    degree_matrix = np.diag(weight_matrix.sum(axis=1))\n",
        "    laplacian_matrix = degree_matrix - weight_matrix\n",
        "    eigvals, eigvecs = eigsh(laplacian_matrix, k=l, which='SM')\n",
        "    kmeans = KMeans(n_clusters=k)\n",
        "    labels = kmeans.fit_predict(eigvecs)\n",
        "    return labels\n",
        "\n",
        "# محاسبه Purity\n",
        "def purity_score(dataset):\n",
        "    total = 0\n",
        "    for i in range(k):\n",
        "        cluster_labels = dataset[dataset[\"new_labels\"] == (i + 1)][\"labels\"]\n",
        "        if len(cluster_labels) > 0:\n",
        "            most_common = Counter(cluster_labels).most_common(1)[0][1]\n",
        "            total += most_common\n",
        "    return total / len(dataset)\n",
        "\n",
        "# محاسبه F-measure\n",
        "def f_measure(dataset):\n",
        "    precision_list = []\n",
        "    recall_list = []\n",
        "    for i in range(k):\n",
        "        true_labels = dataset[\"labels\"].to_numpy()\n",
        "        predicted_labels = (dataset[\"new_labels\"] == (i + 1)).to_numpy()\n",
        "        tp = np.sum((true_labels[predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fp = np.sum((true_labels[predicted_labels] != dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fn = np.sum((true_labels[~predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        precision_list.append(precision)\n",
        "        recall_list.append(recall)\n",
        "    precision = np.mean(precision_list)\n",
        "    recall = np.mean(recall_list)\n",
        "    f_measure_value = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    return f_measure_value\n",
        "\n",
        "# اجرای الگوریتم‌ها\n",
        "def run_algorithm(algorithm, dataset, k):\n",
        "    start_time = time.time()\n",
        "    if algorithm == spectral_clustering:\n",
        "        labels = algorithm(dataset[[\"x1\", \"x2\"]], k)\n",
        "        centers = None\n",
        "    else:\n",
        "        centers, labels = algorithm(dataset[[\"x1\", \"x2\"]], k)\n",
        "    labels += 1\n",
        "    dataset[\"new_labels\"] = labels\n",
        "    purity = purity_score(dataset)\n",
        "    f_measure_value = f_measure(dataset)\n",
        "    end_time = time.time()\n",
        "    execution_time = end_time - start_time\n",
        "    return purity, f_measure_value, execution_time, dataset\n",
        "\n",
        "# نتایج\n",
        "results = []\n",
        "algorithms = [k_median, k_median2, spectral_clustering, k_median_polynomial, k_median_rbf]\n",
        "for algorithm in algorithms:\n",
        "    purity, f_measure_value, execution_time, dataset_with_labels = run_algorithm(algorithm, dataset.copy(), k)\n",
        "    results.append({\n",
        "        \"Algorithm\": algorithm.__name__,\n",
        "        \"Purity\": purity,\n",
        "        \"F-measure\": f_measure_value,\n",
        "        \"Execution Time\": execution_time\n",
        "    })\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "# مقایسه نتایج\n",
        "print(\"مقایسه نتایج الگوریتم‌ها:\")\n",
        "print(results_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hdDuiQUHjWDG"
      },
      "outputs": [],
      "source": [
        "########################انجام الگوریتم ها در تکست ششم(R15.txt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2BUaRHaVjtcX"
      },
      "outputs": [],
      "source": [
        "###################با جابه جایی یکی از مراکز با نقاط داده k_median"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B399xZZfjsTs"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bYJVJecjq53",
        "outputId": "91cf762f-6339-4b85-fba8-e547690deb44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Purity: 0.8616666666666667\n",
            "F-measure: 0.24399105163921148\n",
            "Execution time: 0.08253240585327148\n",
            "Dataset with new labels:\n",
            "       x1      x2  labels  new_labels\n",
            "0   9.802  10.132       1           1\n",
            "1  10.350   9.768       1           1\n",
            "2  10.098   9.988       1           1\n",
            "3   9.730   9.910       1           1\n",
            "4   9.754  10.430       1           1\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import requests\n",
        "from io import StringIO\n",
        "import time\n",
        "# بارگذاری داده‌ها\n",
        "link= [\"http://cs.joensuu.fi/sipu/datasets/R15.txt\"]\n",
        "numbers = []\n",
        "read = requests.get(link[0])\n",
        "content = read.text\n",
        "data = StringIO(content)\n",
        "df = pd.read_csv(data, sep=\"\\s+\", header=None, names=[\"x1\", \"x2\", \"labels\"])\n",
        "numbers.append(df)\n",
        "dataset = pd.concat(numbers, ignore_index=True)\n",
        "# تعریف تابع k_media\n",
        "def k_median(data, k, max_iterations=200):\n",
        "    centers = data.sample(n=k, random_state=42).to_numpy()\n",
        "    for _ in range(max_iterations):\n",
        "        distances = np.linalg.norm(data.to_numpy()[:, np.newaxis] - centers, axis=2)\n",
        "        labels = np.argmin(distances, axis=1)\n",
        "        new_centers = np.array([np.median(data[labels == i].to_numpy(), axis=0) for i in range(k)])\n",
        "        if np.all(centers == new_centers):\n",
        "            break\n",
        "        centers = new_centers\n",
        "    return centers, labels\n",
        "k=15\n",
        "# زمان شروع\n",
        "start_time = time.time()\n",
        "centers, labels = k_median(dataset[[\"x1\", \"x2\"]], k)\n",
        "labels += 1\n",
        "dataset[\"new_labels\"] = labels\n",
        "# تعریف purity\n",
        "def purity_score(dataset):\n",
        "    total = 0\n",
        "    for i in range(k):\n",
        "        cluster_labels = dataset[dataset[\"new_labels\"] == (i + 1)][\"labels\"]\n",
        "        if len(cluster_labels) > 0:\n",
        "            most_common = Counter(cluster_labels).most_common(1)[0][1]\n",
        "            total += most_common\n",
        "    return total / len(dataset)\n",
        "purity = purity_score(dataset)\n",
        "# تعریف f_measure\n",
        "def f_measure(dataset):\n",
        "    precision_list = []\n",
        "    recall_list = []\n",
        "    for i in range(k):\n",
        "        true_labels = dataset[\"labels\"].to_numpy()\n",
        "        predicted_labels = (dataset[\"new_labels\"] == (i + 1)).to_numpy()\n",
        "        tp = np.sum((true_labels[predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fp = np.sum((true_labels[predicted_labels] != dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fn = np.sum((true_labels[~predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        precision_list.append(precision)\n",
        "        recall_list.append(recall)\n",
        "    precision = np.mean(precision_list)\n",
        "    recall = np.mean(recall_list)\n",
        "    f_measure_value = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    return f_measure_value\n",
        "f_measure_value = f_measure(dataset)\n",
        "#زمان پابان\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(\"Purity:\", purity)\n",
        "print(\"F-measure:\", f_measure_value)\n",
        "print(\"Execution time:\", execution_time)\n",
        "print(\"Dataset with new labels:\")\n",
        "print(dataset[[\"x1\", \"x2\", \"labels\", \"new_labels\"]].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zsl6N53Ujxwa"
      },
      "outputs": [],
      "source": [
        "###################### با جابه جایی دو تا از مراکز با نقاط داده k_median محاسبه"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5vqLf1Nj6Lz",
        "outputId": "36b6d773-08c8-45c0-c3b9-4001611c379c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Purity: 0.8616666666666667\n",
            "F-measure: 0.24399105163921148\n",
            "Execution time: 2.2917191982269287\n",
            "Dataset with new labels:\n",
            "       x1      x2  labels  new_labels\n",
            "0   9.802  10.132       1           1\n",
            "1  10.350   9.768       1           1\n",
            "2  10.098   9.988       1           1\n",
            "3   9.730   9.910       1           1\n",
            "4   9.754  10.430       1           1\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import requests\n",
        "from io import StringIO\n",
        "import time\n",
        "# بارگذاری داده‌ها\n",
        "link = [\"http://cs.joensuu.fi/sipu/datasets/R15.txt\"]\n",
        "numbers = []\n",
        "read = requests.get(link[0])\n",
        "content = read.text\n",
        "data = StringIO(content)\n",
        "df = pd.read_csv(data, sep=\"\\s+\", header=None, names=[\"x1\", \"x2\", \"labels\"])\n",
        "numbers.append(df)\n",
        "dataset = pd.concat(numbers, ignore_index=True)\n",
        "# تعریف تابع k_median\n",
        "def k_median(data, k, max_iterations=200):\n",
        "    centers = data.sample(n=k, random_state=42).to_numpy()\n",
        "    for _ in range(max_iterations):\n",
        "        distances = np.linalg.norm(data.to_numpy()[:, np.newaxis] - centers, axis=2)\n",
        "        labels = np.argmin(distances, axis=1)\n",
        "        for i in range(0, k, 2):\n",
        "            if i < k and np.any(labels == i):\n",
        "                centers[i] = data.iloc[labels == i].median(axis=0).to_numpy()\n",
        "            if i + 1 < k and np.any(labels == (i + 1)):\n",
        "                centers[i + 1] = data.iloc[labels == (i + 1)].median(axis=0).to_numpy()\n",
        "        if np.allclose(centers, centers.mean(axis=0)):\n",
        "            break\n",
        "    return centers, labels\n",
        "k =15\n",
        "# زمان شروع\n",
        "start_time = time.time()\n",
        "centers, labels = k_median(dataset[[\"x1\", \"x2\"]], k)\n",
        "labels += 1\n",
        "dataset[\"new_labels\"] = labels\n",
        "# تعریف purity\n",
        "def purity_score(dataset):\n",
        "    total = 0\n",
        "    for i in range(k):\n",
        "        cluster_labels = dataset[dataset[\"new_labels\"] == (i + 1)][\"labels\"]\n",
        "        if len(cluster_labels) > 0:\n",
        "            most_common = Counter(cluster_labels).most_common(1)[0][1]\n",
        "            total += most_common\n",
        "    return total / len(dataset)\n",
        "purity = purity_score(dataset)\n",
        "# تعریف f_measure\n",
        "def f_measure(dataset):\n",
        "    precision_list = []\n",
        "    recall_list = []\n",
        "    for i in range(k):\n",
        "        true_labels = dataset[\"labels\"].to_numpy()\n",
        "        predicted_labels = (dataset[\"new_labels\"] == (i + 1)).to_numpy()\n",
        "        tp = np.sum((true_labels[predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fp = np.sum((true_labels[predicted_labels] != dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fn = np.sum((true_labels[~predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        precision_list.append(precision)\n",
        "        recall_list.append(recall)\n",
        "    precision = np.mean(precision_list)\n",
        "    recall = np.mean(recall_list)\n",
        "    f_measure_value = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    return f_measure_value\n",
        "f_measure_value = f_measure(dataset)\n",
        "# زمان پایان\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(\"Purity:\", purity)\n",
        "print(\"F-measure:\", f_measure_value)\n",
        "print(\"Execution time:\", execution_time)\n",
        "print(\"Dataset with new labels:\")\n",
        "print(dataset[[\"x1\", \"x2\", \"labels\", \"new_labels\"]].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5H-FqWapkLax"
      },
      "outputs": [],
      "source": [
        "#################با کرنل دو جمله ای k_median محاسبه"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBTAIcXnkOGi",
        "outputId": "2bed5a3a-879b-46fc-d220-9b56f97a56f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Purity: 0.09166666666666666\n",
            "F-measure: 0.008533333333333334\n",
            "Execution time: 3.134512424468994\n",
            "Dataset with new labels:\n",
            "       x1      x2  labels  new_labels\n",
            "0   9.802  10.132       1           1\n",
            "1  10.350   9.768       1           1\n",
            "2  10.098   9.988       1           1\n",
            "3   9.730   9.910       1           1\n",
            "4   9.754  10.430       1           1\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import requests\n",
        "from io import StringIO\n",
        "import time\n",
        "from sklearn.metrics.pairwise import polynomial_kernel\n",
        "\n",
        "# بارگذاری داده‌ها\n",
        "link = [\"http://cs.joensuu.fi/sipu/datasets/R15.txt\"]\n",
        "numbers = []\n",
        "read = requests.get(link[0])\n",
        "content = read.text\n",
        "data = StringIO(content)\n",
        "df = pd.read_csv(data, sep=\"\\s+\", header=None, names=[\"x1\", \"x2\", \"labels\"])\n",
        "numbers.append(df)\n",
        "dataset = pd.concat(numbers, ignore_index=True)\n",
        "# تعریف تابع k_median_polynomial\n",
        "def k_median_polynomial(data, k, max_iterations=200):\n",
        "    centers = data.sample(n=k, random_state=42).to_numpy()\n",
        "    for _ in range(max_iterations):\n",
        "        similarity_matrix = polynomial_kernel(data, centers)\n",
        "        labels = np.argmax(similarity_matrix, axis=1)\n",
        "        new_centers = []\n",
        "        for i in range(k):\n",
        "            cluster_points = data.iloc[np.where(labels == i)]\n",
        "            if len(cluster_points) > 0:\n",
        "                new_centers.append(cluster_points.median(axis=0).to_numpy())\n",
        "            else:\n",
        "                new_centers.append(data.sample(n=1, random_state=42).to_numpy().flatten())\n",
        "        new_centers = np.array(new_centers)\n",
        "        if np.allclose(centers, new_centers, atol=1e-4):\n",
        "            break\n",
        "        centers = new_centers\n",
        "    return centers, labels\n",
        "\n",
        "k = 15\n",
        "# زمان شروع\n",
        "start_time = time.time()\n",
        "centers, labels = k_median_polynomial(dataset[[\"x1\", \"x2\"]], k)\n",
        "labels += 1\n",
        "dataset[\"new_labels\"] = labels\n",
        "# تعریف purity\n",
        "def purity_score(dataset):\n",
        "    total = 0\n",
        "    for i in range(k):\n",
        "        cluster_labels = dataset[dataset[\"new_labels\"] == (i + 1)][\"labels\"]\n",
        "        if len(cluster_labels) > 0:\n",
        "            most_common = Counter(cluster_labels).most_common(1)[0][1]\n",
        "            total += most_common\n",
        "    return total / len(dataset)\n",
        "\n",
        "purity = purity_score(dataset)\n",
        "\n",
        "# تعریف f_measure\n",
        "def f_measure(dataset):\n",
        "    precision_list = []\n",
        "    recall_list = []\n",
        "    for i in range(k):\n",
        "        true_labels = dataset[\"labels\"].to_numpy()\n",
        "        predicted_labels = (dataset[\"new_labels\"] == (i + 1)).to_numpy()\n",
        "        tp = np.sum((true_labels[predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fp = np.sum((true_labels[predicted_labels] != dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fn = np.sum((true_labels[~predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        precision_list.append(precision)\n",
        "        recall_list.append(recall)\n",
        "\n",
        "    precision = np.mean(precision_list)\n",
        "    recall = np.mean(recall_list)\n",
        "    f_measure_value = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    return f_measure_value\n",
        "\n",
        "f_measure_value = f_measure(dataset)\n",
        "\n",
        "# زمان پایان\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "\n",
        "print(\"Purity:\", purity)\n",
        "print(\"F-measure:\", f_measure_value)\n",
        "print(\"Execution time:\", execution_time)\n",
        "print(\"Dataset with new labels:\")\n",
        "print(dataset[[\"x1\", \"x2\", \"labels\", \"new_labels\"]].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tfsh0YxgksIG"
      },
      "outputs": [],
      "source": [
        "#################با کرنل  گوسی k_median محاسبه"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4SBWK1QkvNE",
        "outputId": "29ba8d16-e998-441d-8616-d3ff7d20522e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Purity: 0.8616666666666667\n",
            "F-measure: 0.24399105163921148\n",
            "Execution time: 0.19124841690063477\n",
            "Dataset with new labels:\n",
            "       x1      x2  labels  new_labels\n",
            "0   9.802  10.132       1           1\n",
            "1  10.350   9.768       1           1\n",
            "2  10.098   9.988       1           1\n",
            "3   9.730   9.910       1           1\n",
            "4   9.754  10.430       1           1\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import requests\n",
        "from io import StringIO\n",
        "import time\n",
        "from sklearn.metrics.pairwise import rbf_kernel\n",
        "\n",
        "# بارگذاری داده‌ها\n",
        "link = [\"http://cs.joensuu.fi/sipu/datasets/R15.txt\"]\n",
        "numbers = []\n",
        "read = requests.get(link[0])\n",
        "content = read.text\n",
        "data = StringIO(content)\n",
        "df = pd.read_csv(data, sep=\"\\s+\", header=None, names=[\"x1\", \"x2\", \"labels\"])\n",
        "numbers.append(df)\n",
        "dataset = pd.concat(numbers, ignore_index=True)\n",
        "\n",
        "# تعریف تابع k_median\n",
        "def k_median_rbf(data, k, max_iterations=100, gamma=0.5):\n",
        "    centers = data.sample(n=k, random_state=42).to_numpy()\n",
        "    for _ in range(max_iterations):\n",
        "        similarity_matrix = rbf_kernel(data.to_numpy(), centers, gamma=gamma)\n",
        "        labels = np.argmax(similarity_matrix, axis=1)\n",
        "        new_centers = []\n",
        "        for i in range(k):\n",
        "            cluster_points = data.iloc[np.where(labels == i)]\n",
        "            if len(cluster_points) > 0:\n",
        "                new_centers.append(cluster_points.median(axis=0).to_numpy())\n",
        "            else:\n",
        "                new_centers.append(data.sample(n=1, random_state=42).to_numpy().flatten())\n",
        "        new_centers = np.array(new_centers)\n",
        "        if np.allclose(centers, new_centers, atol=1e-4):\n",
        "            break\n",
        "        centers = new_centers\n",
        "    return centers, labels\n",
        "\n",
        "k = 15\n",
        "\n",
        "# زمان شروع\n",
        "start_time = time.time()\n",
        "centers, labels = k_median_rbf(dataset[[\"x1\", \"x2\"]], k)\n",
        "labels += 1\n",
        "dataset[\"new_labels\"] = labels\n",
        "\n",
        "# تعریف purity\n",
        "def purity_score(dataset):\n",
        "    total = 0\n",
        "    for i in range(k):\n",
        "        cluster_labels = dataset[dataset[\"new_labels\"] == (i + 1)][\"labels\"]\n",
        "        if len(cluster_labels) > 0:\n",
        "            most_common = Counter(cluster_labels).most_common(1)[0][1]\n",
        "            total += most_common\n",
        "    return total / len(dataset)\n",
        "\n",
        "purity = purity_score(dataset)\n",
        "\n",
        "# تعریف f_measure\n",
        "def f_measure(dataset):\n",
        "    precision_list = []\n",
        "    recall_list = []\n",
        "    for i in range(k):\n",
        "        true_labels = dataset[\"labels\"].to_numpy()\n",
        "        predicted_labels = dataset[\"new_labels\"].to_numpy()\n",
        "        tp = np.sum((true_labels == i + 1) & (predicted_labels == i + 1))\n",
        "        fp = np.sum((true_labels != i + 1) & (predicted_labels == i + 1))\n",
        "        fn = np.sum((true_labels == i + 1) & (predicted_labels != i + 1))\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        precision_list.append(precision)\n",
        "        recall_list.append(recall)\n",
        "    precision = np.mean(precision_list)\n",
        "    recall = np.mean(recall_list)\n",
        "    f_measure_value = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    return f_measure_value\n",
        "\n",
        "f_measure_value = f_measure(dataset)\n",
        "\n",
        "# زمان پایان\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "\n",
        "print(\"Purity:\", purity)\n",
        "print(\"F-measure:\", f_measure_value)\n",
        "print(\"Execution time:\", execution_time)\n",
        "print(\"Dataset with new labels:\")\n",
        "print(dataset[[\"x1\", \"x2\", \"labels\", \"new_labels\"]].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "83_sA_m9lXdU"
      },
      "outputs": [],
      "source": [
        "#################         الگوریتم خوشه بندی طیفی"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixx4qdlblCCj",
        "outputId": "9d1bb76e-ea1c-4af0-e284-6dd16be6a217"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Purity: 0.7316666666666667\n",
            "F-measure: 0.022408963585434174\n",
            "Execution time: 1.6195805072784424\n",
            "Dataset with new labels:\n",
            "       x1      x2  labels  new_labels\n",
            "0   9.802  10.132       1          14\n",
            "1  10.350   9.768       1          14\n",
            "2  10.098   9.988       1          14\n",
            "3   9.730   9.910       1          14\n",
            "4   9.754  10.430       1          14\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import requests\n",
        "from io import StringIO\n",
        "import time\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "from sklearn.cluster import KMeans\n",
        "from scipy.sparse.linalg import eigsh\n",
        "# بارگذاری داده‌ها\n",
        "link = [\"http://cs.joensuu.fi/sipu/datasets/R15.txt\"]\n",
        "numbers = []\n",
        "read = requests.get(link[0])\n",
        "content = read.text\n",
        "data = StringIO(content)\n",
        "df = pd.read_csv(data, sep=\"\\s+\", header=None, names=[\"x1\", \"x2\", \"labels\"])\n",
        "numbers.append(df)\n",
        "dataset = pd.concat(numbers, ignore_index=True)\n",
        "# تابع خوشه‌بندی طیفی\n",
        "def spectral_clustering(data, k):\n",
        "    adjacency_matrix = kneighbors_graph(data, n_neighbors=l, mode='connectivity', include_self=False).toarray()\n",
        "    weight_matrix = adjacency_matrix * adjacency_matrix.T\n",
        "    degree_matrix = np.diag(weight_matrix.sum(axis=1))\n",
        "    laplacian_matrix = degree_matrix - weight_matrix\n",
        "    eigvals, eigvecs = eigsh(laplacian_matrix, k=l, which='SM')\n",
        "    kmeans = KMeans(n_clusters=k)\n",
        "    labels = kmeans.fit_predict(eigvecs)\n",
        "    return labels\n",
        "l=9\n",
        "k =15\n",
        "# زمان شروع\n",
        "start_time = time.time()\n",
        "labels = spectral_clustering(dataset[[\"x1\", \"x2\"]], k)\n",
        "labels += 1\n",
        "dataset[\"new_labels\"] = labels\n",
        "# تعریف purity\n",
        "def purity_score(dataset):\n",
        "    total = 0\n",
        "    for i in range(k):\n",
        "        cluster_labels = dataset[dataset[\"new_labels\"] == (i + 1)][\"labels\"]\n",
        "        if len(cluster_labels) > 0:\n",
        "            most_common = Counter(cluster_labels).most_common(1)[0][1]\n",
        "            total += most_common\n",
        "    return total / len(dataset)\n",
        "purity = purity_score(dataset)\n",
        "# تعریف f_measure\n",
        "def f_measure(dataset):\n",
        "    precision_list = []\n",
        "    recall_list = []\n",
        "    for i in range(k):\n",
        "        true_labels = dataset[\"labels\"].to_numpy()\n",
        "        predicted_labels = (dataset[\"new_labels\"] == (i + 1)).to_numpy()\n",
        "        tp = np.sum((true_labels[predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fp = np.sum((true_labels[predicted_labels] != dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fn = np.sum((true_labels[~predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        precision_list.append(precision)\n",
        "        recall_list.append(recall)\n",
        "    precision = np.mean(precision_list)\n",
        "    recall = np.mean(recall_list)\n",
        "    f_measure_value = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    return f_measure_value\n",
        "f_measure_value = f_measure(dataset)\n",
        "# زمان پایان\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(\"Purity:\", purity)\n",
        "print(\"F-measure:\", f_measure_value)\n",
        "print(\"Execution time:\", execution_time)\n",
        "print(\"Dataset with new labels:\")\n",
        "print(dataset[[\"x1\", \"x2\", \"labels\", \"new_labels\"]].head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###مقایسه الگوریتم ها"
      ],
      "metadata": {
        "id": "g3BStGSRNG2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import requests\n",
        "from io import StringIO\n",
        "import time\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics.pairwise import polynomial_kernel, rbf_kernel\n",
        "from scipy.sparse.linalg import eigsh\n",
        "\n",
        "# بارگذاری داده‌ها\n",
        "link = [\"http://cs.joensuu.fi/sipu/datasets/R15.txt\"]\n",
        "numbers = []\n",
        "read = requests.get(link[0])\n",
        "content = read.text\n",
        "data = StringIO(content)\n",
        "df = pd.read_csv(data, sep=\"\\s+\", header=None, names=[\"x1\", \"x2\", \"labels\"])\n",
        "numbers.append(df)\n",
        "dataset = pd.concat(numbers, ignore_index=True)\n",
        "k=15\n",
        "l=9\n",
        "\n",
        "# تعریف تابع k_median\n",
        "def k_median(data, k, max_iterations=200):\n",
        "    centers = data.sample(n=k, random_state=42).to_numpy()\n",
        "    for _ in range(max_iterations):\n",
        "        distances = np.linalg.norm(data.to_numpy()[:, np.newaxis] - centers, axis=2)\n",
        "        labels = np.argmin(distances, axis=1)\n",
        "        new_centers = np.array([np.median(data[labels == i].to_numpy(), axis=0) for i in range(k)])\n",
        "        if np.all(centers == new_centers):\n",
        "            break\n",
        "        centers = new_centers\n",
        "    return centers, labels\n",
        "\n",
        "# نسخه دوم k_median (با فواصل مشابه نسخه اول شما)\n",
        "def k_median2(data, k, max_iterations=200):\n",
        "    centers = data.sample(n=k, random_state=42).to_numpy()\n",
        "    for _ in range(max_iterations):\n",
        "        distances = np.linalg.norm(data.to_numpy()[:, np.newaxis] - centers, axis=2)\n",
        "        labels = np.argmin(distances, axis=1)\n",
        "        for i in range(0, k, 2):\n",
        "            if i < k and np.any(labels == i):\n",
        "                centers[i] = data.iloc[labels == i].median(axis=0).to_numpy()\n",
        "            if i + 1 < k and np.any(labels == (i + 1)):\n",
        "                centers[i + 1] = data.iloc[labels == (i + 1)].median(axis=0).to_numpy()\n",
        "        if np.allclose(centers, centers.mean(axis=0)):\n",
        "            break\n",
        "    return centers, labels\n",
        "\n",
        "# K-Median با کرنل چندجمله‌ای\n",
        "def k_median_polynomial(data, k, max_iterations=200):\n",
        "    centers = data.sample(n=k, random_state=42).to_numpy()\n",
        "    for _ in range(max_iterations):\n",
        "        similarity_matrix = polynomial_kernel(data, centers)\n",
        "        labels = np.argmax(similarity_matrix, axis=1)\n",
        "        new_centers = []\n",
        "        for i in range(k):\n",
        "            cluster_points = data.iloc[np.where(labels == i)]\n",
        "            if len(cluster_points) > 0:\n",
        "                new_centers.append(cluster_points.median(axis=0).to_numpy())\n",
        "            else:\n",
        "                new_centers.append(data.sample(n=1, random_state=42).to_numpy().flatten())\n",
        "        new_centers = np.array(new_centers)\n",
        "        if np.allclose(centers, new_centers, atol=1e-4):\n",
        "            break\n",
        "        centers = new_centers\n",
        "    return centers, labels\n",
        "\n",
        "# K-Median با کرنل گوسی\n",
        "def k_median_rbf(data, k, max_iterations=100, gamma=0.5):\n",
        "    centers = data.sample(n=k, random_state=42).to_numpy()\n",
        "    for _ in range(max_iterations):\n",
        "        similarity_matrix = rbf_kernel(data, centers, gamma=gamma)\n",
        "        labels = np.argmax(similarity_matrix, axis=1)\n",
        "        new_centers = np.array([data[labels == i].median(axis=0) for i in range(k)])\n",
        "        if np.allclose(centers, new_centers):\n",
        "            break\n",
        "        centers = new_centers\n",
        "    return centers, labels\n",
        "\n",
        "# خوشه‌بندی طیفی\n",
        "def spectral_clustering(data, k):\n",
        "    adjacency_matrix = kneighbors_graph(data, n_neighbors=l, mode='connectivity', include_self=False).toarray()\n",
        "    weight_matrix = adjacency_matrix * adjacency_matrix.T\n",
        "    degree_matrix = np.diag(weight_matrix.sum(axis=1))\n",
        "    laplacian_matrix = degree_matrix - weight_matrix\n",
        "    eigvals, eigvecs = eigsh(laplacian_matrix, k=l, which='SM')\n",
        "    kmeans = KMeans(n_clusters=k)\n",
        "    labels = kmeans.fit_predict(eigvecs)\n",
        "    return labels\n",
        "\n",
        "# محاسبه Purity\n",
        "def purity_score(dataset):\n",
        "    total = 0\n",
        "    for i in range(k):\n",
        "        cluster_labels = dataset[dataset[\"new_labels\"] == (i + 1)][\"labels\"]\n",
        "        if len(cluster_labels) > 0:\n",
        "            most_common = Counter(cluster_labels).most_common(1)[0][1]\n",
        "            total += most_common\n",
        "    return total / len(dataset)\n",
        "\n",
        "# محاسبه F-measure\n",
        "def f_measure(dataset):\n",
        "    precision_list = []\n",
        "    recall_list = []\n",
        "    for i in range(k):\n",
        "        true_labels = dataset[\"labels\"].to_numpy()\n",
        "        predicted_labels = (dataset[\"new_labels\"] == (i + 1)).to_numpy()\n",
        "        tp = np.sum((true_labels[predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fp = np.sum((true_labels[predicted_labels] != dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fn = np.sum((true_labels[~predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        precision_list.append(precision)\n",
        "        recall_list.append(recall)\n",
        "    precision = np.mean(precision_list)\n",
        "    recall = np.mean(recall_list)\n",
        "    f_measure_value = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    return f_measure_value\n",
        "\n",
        "# اجرای الگوریتم‌ها\n",
        "def run_algorithm(algorithm, dataset, k):\n",
        "    start_time = time.time()\n",
        "    if algorithm == spectral_clustering:\n",
        "        labels = algorithm(dataset[[\"x1\", \"x2\"]], k)\n",
        "        centers = None\n",
        "    else:\n",
        "        centers, labels = algorithm(dataset[[\"x1\", \"x2\"]], k)\n",
        "    labels += 1\n",
        "    dataset[\"new_labels\"] = labels\n",
        "    purity = purity_score(dataset)\n",
        "    f_measure_value = f_measure(dataset)\n",
        "    end_time = time.time()\n",
        "    execution_time = end_time - start_time\n",
        "    return purity, f_measure_value, execution_time, dataset\n",
        "\n",
        "# نتایج\n",
        "results = []\n",
        "algorithms = [k_median, k_median2, spectral_clustering, k_median_polynomial, k_median_rbf]\n",
        "for algorithm in algorithms:\n",
        "    purity, f_measure_value, execution_time, dataset_with_labels = run_algorithm(algorithm, dataset.copy(), k)\n",
        "    results.append({\n",
        "        \"Algorithm\": algorithm.__name__,\n",
        "        \"Purity\": purity,\n",
        "        \"F-measure\": f_measure_value,\n",
        "        \"Execution Time\": execution_time\n",
        "    })\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "# مقایسه نتایج\n",
        "print(\"مقایسه نتایج الگوریتم‌ها:\")\n",
        "print(results_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9sMz3lyMRzB",
        "outputId": "4c44f828-5d16-41c8-8943-f2fd43ba0684"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "مقایسه نتایج الگوریتم‌ها:\n",
            "             Algorithm    Purity  F-measure  Execution Time\n",
            "0             k_median  0.861667   0.243991        0.071751\n",
            "1            k_median2  0.861667   0.243991        1.559398\n",
            "2  spectral_clustering  0.918333   0.065823        0.366690\n",
            "3  k_median_polynomial  0.091667   0.008533        1.814952\n",
            "4         k_median_rbf  0.861667   0.243991        0.086007\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qDilgarZMHNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qBzcx4WtlQ_J"
      },
      "outputs": [],
      "source": [
        "########################## انجام الگوریتم ها در تکست هفتم(jain.txt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3AXvDfCVlTse"
      },
      "outputs": [],
      "source": [
        "###################با جابه جایی یکی از مراکز با نقاط داده k_median"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2C6Yk6ols2p",
        "outputId": "3253a4d6-6bae-4b6d-967d-079465b9262b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Purity: 0.7533512064343163\n",
            "F-measure: 0.19784946236559142\n",
            "Execution time: 0.024845600128173828\n",
            "Dataset with new labels:\n",
            "     x1     x2  labels  new_labels\n",
            "0  0.85  17.45       2           2\n",
            "1  0.75  15.60       2           2\n",
            "2  3.30  15.45       2           2\n",
            "3  5.25  14.20       2           2\n",
            "4  4.90  15.65       2           2\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import requests\n",
        "from io import StringIO\n",
        "import time\n",
        "# بارگذاری داده‌ها\n",
        "link= [\"http://cs.joensuu.fi/sipu/datasets/jain.txt\"]\n",
        "numbers = []\n",
        "read = requests.get(link[0])\n",
        "content = read.text\n",
        "data = StringIO(content)\n",
        "df = pd.read_csv(data, sep=\"\\s+\", header=None, names=[\"x1\", \"x2\", \"labels\"])\n",
        "numbers.append(df)\n",
        "dataset = pd.concat(numbers, ignore_index=True)\n",
        "# تعریف تابع k_media\n",
        "def k_median(data, k, max_iterations=200):\n",
        "    centers = data.sample(n=k, random_state=42).to_numpy()\n",
        "    for _ in range(max_iterations):\n",
        "        distances = np.linalg.norm(data.to_numpy()[:, np.newaxis] - centers, axis=2)\n",
        "        labels = np.argmin(distances, axis=1)\n",
        "        new_centers = np.array([np.median(data[labels == i].to_numpy(), axis=0) for i in range(k)])\n",
        "        if np.all(centers == new_centers):\n",
        "            break\n",
        "        centers = new_centers\n",
        "    return centers, labels\n",
        "k=2\n",
        "# زمان شروع\n",
        "start_time = time.time()\n",
        "centers, labels = k_median(dataset[[\"x1\", \"x2\"]], k)\n",
        "labels += 1\n",
        "dataset[\"new_labels\"] = labels\n",
        "# تعریف purity\n",
        "def purity_score(dataset):\n",
        "    total = 0\n",
        "    for i in range(k):\n",
        "        cluster_labels = dataset[dataset[\"new_labels\"] == (i + 1)][\"labels\"]\n",
        "        if len(cluster_labels) > 0:\n",
        "            most_common = Counter(cluster_labels).most_common(1)[0][1]\n",
        "            total += most_common\n",
        "    return total / len(dataset)\n",
        "purity = purity_score(dataset)\n",
        "# تعریف f_measure\n",
        "def f_measure(dataset):\n",
        "    precision_list = []\n",
        "    recall_list = []\n",
        "    for i in range(k):\n",
        "        true_labels = dataset[\"labels\"].to_numpy()\n",
        "        predicted_labels = (dataset[\"new_labels\"] == (i + 1)).to_numpy()\n",
        "        tp = np.sum((true_labels[predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fp = np.sum((true_labels[predicted_labels] != dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fn = np.sum((true_labels[~predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        precision_list.append(precision)\n",
        "        recall_list.append(recall)\n",
        "    precision = np.mean(precision_list)\n",
        "    recall = np.mean(recall_list)\n",
        "    f_measure_value = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    return f_measure_value\n",
        "f_measure_value = f_measure(dataset)\n",
        "#زمان پابان\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(\"Purity:\", purity)\n",
        "print(\"F-measure:\", f_measure_value)\n",
        "print(\"Execution time:\", execution_time)\n",
        "print(\"Dataset with new labels:\")\n",
        "print(dataset[[\"x1\", \"x2\", \"labels\", \"new_labels\"]].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_YOalWukl1Wi"
      },
      "outputs": [],
      "source": [
        "###################### با جابه جایی دو تا از مراکز با نقاط داده k_median محاسبه"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGcV-4TOl4Kk",
        "outputId": "81bdff2b-252f-4d04-cef0-b35759fa740a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Purity: 0.7533512064343163\n",
            "F-measure: 0.19784946236559142\n",
            "Execution time: 0.4446718692779541\n",
            "Dataset with new labels:\n",
            "     x1     x2  labels  new_labels\n",
            "0  0.85  17.45       2           2\n",
            "1  0.75  15.60       2           2\n",
            "2  3.30  15.45       2           2\n",
            "3  5.25  14.20       2           2\n",
            "4  4.90  15.65       2           2\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import requests\n",
        "from io import StringIO\n",
        "import time\n",
        "# بارگذاری داده‌ها\n",
        "link = [\"http://cs.joensuu.fi/sipu/datasets/jain.txt\"]\n",
        "numbers = []\n",
        "read = requests.get(link[0])\n",
        "content = read.text\n",
        "data = StringIO(content)\n",
        "df = pd.read_csv(data, sep=\"\\s+\", header=None, names=[\"x1\", \"x2\", \"labels\"])\n",
        "numbers.append(df)\n",
        "dataset = pd.concat(numbers, ignore_index=True)\n",
        "# تعریف تابع k_median\n",
        "def k_median(data, k, max_iterations=200):\n",
        "    centers = data.sample(n=k, random_state=42).to_numpy()\n",
        "    for _ in range(max_iterations):\n",
        "        distances = np.linalg.norm(data.to_numpy()[:, np.newaxis] - centers, axis=2)\n",
        "        labels = np.argmin(distances, axis=1)\n",
        "        for i in range(0, k, 2):\n",
        "            if i < k and np.any(labels == i):\n",
        "                centers[i] = data.iloc[labels == i].median(axis=0).to_numpy()\n",
        "            if i + 1 < k and np.any(labels == (i + 1)):\n",
        "                centers[i + 1] = data.iloc[labels == (i + 1)].median(axis=0).to_numpy()\n",
        "        if np.allclose(centers, centers.mean(axis=0)):\n",
        "            break\n",
        "    return centers, labels\n",
        "k =2\n",
        "# زمان شروع\n",
        "start_time = time.time()\n",
        "centers, labels = k_median(dataset[[\"x1\", \"x2\"]], k)\n",
        "labels += 1\n",
        "dataset[\"new_labels\"] = labels\n",
        "# تعریف purity\n",
        "def purity_score(dataset):\n",
        "    total = 0\n",
        "    for i in range(k):\n",
        "        cluster_labels = dataset[dataset[\"new_labels\"] == (i + 1)][\"labels\"]\n",
        "        if len(cluster_labels) > 0:\n",
        "            most_common = Counter(cluster_labels).most_common(1)[0][1]\n",
        "            total += most_common\n",
        "    return total / len(dataset)\n",
        "purity = purity_score(dataset)\n",
        "# تعریف f_measure\n",
        "def f_measure(dataset):\n",
        "    precision_list = []\n",
        "    recall_list = []\n",
        "    for i in range(k):\n",
        "        true_labels = dataset[\"labels\"].to_numpy()\n",
        "        predicted_labels = (dataset[\"new_labels\"] == (i + 1)).to_numpy()\n",
        "        tp = np.sum((true_labels[predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fp = np.sum((true_labels[predicted_labels] != dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fn = np.sum((true_labels[~predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        precision_list.append(precision)\n",
        "        recall_list.append(recall)\n",
        "    precision = np.mean(precision_list)\n",
        "    recall = np.mean(recall_list)\n",
        "    f_measure_value = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    return f_measure_value\n",
        "f_measure_value = f_measure(dataset)\n",
        "# زمان پایان\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(\"Purity:\", purity)\n",
        "print(\"F-measure:\", f_measure_value)\n",
        "print(\"Execution time:\", execution_time)\n",
        "print(\"Dataset with new labels:\")\n",
        "print(dataset[[\"x1\", \"x2\", \"labels\", \"new_labels\"]].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bhxnRVkpmF12"
      },
      "outputs": [],
      "source": [
        "#################با کرنل دو جمله ای k_median محاسبه"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NaXSop6VmIzU",
        "outputId": "5c0edd5d-9092-41ed-b6a8-6b69c9f24c81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Purity: 0.9168900804289544\n",
            "F-measure: 0.10828034816547491\n",
            "Execution time: 0.024169445037841797\n",
            "Dataset with new labels:\n",
            "     x1     x2  labels  new_labels\n",
            "0  0.85  17.45       2           2\n",
            "1  0.75  15.60       2           2\n",
            "2  3.30  15.45       2           2\n",
            "3  5.25  14.20       2           2\n",
            "4  4.90  15.65       2           2\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import requests\n",
        "from io import StringIO\n",
        "import time\n",
        "from sklearn.metrics.pairwise import polynomial_kernel\n",
        "\n",
        "# بارگذاری داده‌ها\n",
        "link = [\"http://cs.joensuu.fi/sipu/datasets/jain.txt\"]\n",
        "numbers = []\n",
        "read = requests.get(link[0])\n",
        "content = read.text\n",
        "data = StringIO(content)\n",
        "df = pd.read_csv(data, sep=\"\\s+\", header=None, names=[\"x1\", \"x2\", \"labels\"])\n",
        "numbers.append(df)\n",
        "dataset = pd.concat(numbers, ignore_index=True)\n",
        "# تعریف تابع k_median_polynomial\n",
        "def k_median_polynomial(data, k, max_iterations=200):\n",
        "    centers = data.sample(n=k, random_state=42).to_numpy()\n",
        "    for _ in range(max_iterations):\n",
        "        similarity_matrix = polynomial_kernel(data, centers)\n",
        "        labels = np.argmax(similarity_matrix, axis=1)\n",
        "        new_centers = []\n",
        "        for i in range(k):\n",
        "            cluster_points = data.iloc[np.where(labels == i)]\n",
        "            if len(cluster_points) > 0:\n",
        "                new_centers.append(cluster_points.median(axis=0).to_numpy())\n",
        "            else:\n",
        "                new_centers.append(data.sample(n=1, random_state=42).to_numpy().flatten())\n",
        "        new_centers = np.array(new_centers)\n",
        "        if np.allclose(centers, new_centers, atol=1e-4):\n",
        "            break\n",
        "        centers = new_centers\n",
        "    return centers, labels\n",
        "\n",
        "k = 2\n",
        "# زمان شروع\n",
        "start_time = time.time()\n",
        "centers, labels = k_median_polynomial(dataset[[\"x1\", \"x2\"]], k)\n",
        "labels += 1\n",
        "dataset[\"new_labels\"] = labels\n",
        "# تعریف purity\n",
        "def purity_score(dataset):\n",
        "    total = 0\n",
        "    for i in range(k):\n",
        "        cluster_labels = dataset[dataset[\"new_labels\"] == (i + 1)][\"labels\"]\n",
        "        if len(cluster_labels) > 0:\n",
        "            most_common = Counter(cluster_labels).most_common(1)[0][1]\n",
        "            total += most_common\n",
        "    return total / len(dataset)\n",
        "\n",
        "purity = purity_score(dataset)\n",
        "\n",
        "# تعریف f_measure\n",
        "def f_measure(dataset):\n",
        "    precision_list = []\n",
        "    recall_list = []\n",
        "    for i in range(k):\n",
        "        true_labels = dataset[\"labels\"].to_numpy()\n",
        "        predicted_labels = (dataset[\"new_labels\"] == (i + 1)).to_numpy()\n",
        "        tp = np.sum((true_labels[predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fp = np.sum((true_labels[predicted_labels] != dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fn = np.sum((true_labels[~predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        precision_list.append(precision)\n",
        "        recall_list.append(recall)\n",
        "\n",
        "    precision = np.mean(precision_list)\n",
        "    recall = np.mean(recall_list)\n",
        "    f_measure_value = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    return f_measure_value\n",
        "\n",
        "f_measure_value = f_measure(dataset)\n",
        "\n",
        "# زمان پایان\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "\n",
        "print(\"Purity:\", purity)\n",
        "print(\"F-measure:\", f_measure_value)\n",
        "print(\"Execution time:\", execution_time)\n",
        "print(\"Dataset with new labels:\")\n",
        "print(dataset[[\"x1\", \"x2\", \"labels\", \"new_labels\"]].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fs3jczWjmXa5"
      },
      "outputs": [],
      "source": [
        "#################با کرنل  گوسی k_median محاسبه"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UH3uACi-mavo",
        "outputId": "d36468f0-ccdd-46a1-a5bc-bbf921cbae99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Purity: 0.7533512064343163\n",
            "F-measure: 0.7931225734886301\n",
            "Execution time: 0.020768165588378906\n",
            "Dataset with new labels:\n",
            "     x1     x2  labels  new_labels\n",
            "0  0.85  17.45       2           2\n",
            "1  0.75  15.60       2           2\n",
            "2  3.30  15.45       2           2\n",
            "3  5.25  14.20       2           2\n",
            "4  4.90  15.65       2           2\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import requests\n",
        "from io import StringIO\n",
        "import time\n",
        "from sklearn.metrics.pairwise import rbf_kernel\n",
        "\n",
        "# بارگذاری داده‌ها\n",
        "link = [\"http://cs.joensuu.fi/sipu/datasets/jain.txt\"]\n",
        "numbers = []\n",
        "read = requests.get(link[0])\n",
        "content = read.text\n",
        "data = StringIO(content)\n",
        "df = pd.read_csv(data, sep=\"\\s+\", header=None, names=[\"x1\", \"x2\", \"labels\"])\n",
        "numbers.append(df)\n",
        "dataset = pd.concat(numbers, ignore_index=True)\n",
        "\n",
        "# تعریف تابع k_median\n",
        "def k_median_rbf(data, k, max_iterations=100, gamma=0.5):\n",
        "    centers = data.sample(n=k, random_state=42).to_numpy()\n",
        "    for _ in range(max_iterations):\n",
        "        similarity_matrix = rbf_kernel(data.to_numpy(), centers, gamma=gamma)\n",
        "        labels = np.argmax(similarity_matrix, axis=1)\n",
        "        new_centers = []\n",
        "        for i in range(k):\n",
        "            cluster_points = data.iloc[np.where(labels == i)]\n",
        "            if len(cluster_points) > 0:\n",
        "                new_centers.append(cluster_points.median(axis=0).to_numpy())\n",
        "            else:\n",
        "                new_centers.append(data.sample(n=1, random_state=42).to_numpy().flatten())\n",
        "        new_centers = np.array(new_centers)\n",
        "        if np.allclose(centers, new_centers, atol=1e-4):\n",
        "            break\n",
        "        centers = new_centers\n",
        "    return centers, labels\n",
        "\n",
        "k = 2\n",
        "\n",
        "# زمان شروع\n",
        "start_time = time.time()\n",
        "centers, labels = k_median_rbf(dataset[[\"x1\", \"x2\"]], k)\n",
        "labels += 1\n",
        "dataset[\"new_labels\"] = labels\n",
        "\n",
        "# تعریف purity\n",
        "def purity_score(dataset):\n",
        "    total = 0\n",
        "    for i in range(k):\n",
        "        cluster_labels = dataset[dataset[\"new_labels\"] == (i + 1)][\"labels\"]\n",
        "        if len(cluster_labels) > 0:\n",
        "            most_common = Counter(cluster_labels).most_common(1)[0][1]\n",
        "            total += most_common\n",
        "    return total / len(dataset)\n",
        "\n",
        "purity = purity_score(dataset)\n",
        "\n",
        "# تعریف f_measure\n",
        "def f_measure(dataset):\n",
        "    precision_list = []\n",
        "    recall_list = []\n",
        "    for i in range(k):\n",
        "        true_labels = dataset[\"labels\"].to_numpy()\n",
        "        predicted_labels = dataset[\"new_labels\"].to_numpy()\n",
        "        tp = np.sum((true_labels == i + 1) & (predicted_labels == i + 1))\n",
        "        fp = np.sum((true_labels != i + 1) & (predicted_labels == i + 1))\n",
        "        fn = np.sum((true_labels == i + 1) & (predicted_labels != i + 1))\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        precision_list.append(precision)\n",
        "        recall_list.append(recall)\n",
        "    precision = np.mean(precision_list)\n",
        "    recall = np.mean(recall_list)\n",
        "    f_measure_value = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    return f_measure_value\n",
        "\n",
        "f_measure_value = f_measure(dataset)\n",
        "\n",
        "# زمان پایان\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "\n",
        "print(\"Purity:\", purity)\n",
        "print(\"F-measure:\", f_measure_value)\n",
        "print(\"Execution time:\", execution_time)\n",
        "print(\"Dataset with new labels:\")\n",
        "print(dataset[[\"x1\", \"x2\", \"labels\", \"new_labels\"]].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hI7l3CW_m417"
      },
      "outputs": [],
      "source": [
        "#################         الگوریتم خوشه بندی طیفی"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-2fuwllmqRs",
        "outputId": "48fc2bde-bf6f-43cc-a13c-5c85e6edb9cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Purity: 0.739946380697051\n",
            "F-measure: 0.6843275797594913\n",
            "Execution time: 0.28987550735473633\n",
            "Dataset with new labels:\n",
            "     x1     x2  labels  new_labels\n",
            "0  0.85  17.45       2           1\n",
            "1  0.75  15.60       2           1\n",
            "2  3.30  15.45       2           1\n",
            "3  5.25  14.20       2           1\n",
            "4  4.90  15.65       2           1\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import requests\n",
        "from io import StringIO\n",
        "import time\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "from sklearn.cluster import KMeans\n",
        "from scipy.sparse.linalg import eigsh\n",
        "# بارگذاری داده‌ها\n",
        "link = [\"http://cs.joensuu.fi/sipu/datasets/jain.txt\"]\n",
        "numbers = []\n",
        "read = requests.get(link[0])\n",
        "content = read.text\n",
        "data = StringIO(content)\n",
        "df = pd.read_csv(data, sep=\"\\s+\", header=None, names=[\"x1\", \"x2\", \"labels\"])\n",
        "numbers.append(df)\n",
        "dataset = pd.concat(numbers, ignore_index=True)\n",
        "# تابع خوشه‌بندی طیفی\n",
        "def spectral_clustering(data, k):\n",
        "    adjacency_matrix = kneighbors_graph(data, n_neighbors=l, mode='connectivity', include_self=False).toarray()\n",
        "    weight_matrix = adjacency_matrix * adjacency_matrix.T\n",
        "    degree_matrix = np.diag(weight_matrix.sum(axis=1))\n",
        "    laplacian_matrix = degree_matrix - weight_matrix\n",
        "    eigvals, eigvecs = eigsh(laplacian_matrix, k=l, which='SM')\n",
        "    kmeans = KMeans(n_clusters=k)\n",
        "    labels = kmeans.fit_predict(eigvecs)\n",
        "    return labels\n",
        "l=9\n",
        "k =2\n",
        "# زمان شروع\n",
        "start_time = time.time()\n",
        "labels = spectral_clustering(dataset[[\"x1\", \"x2\"]], k)\n",
        "labels += 1\n",
        "dataset[\"new_labels\"] = labels\n",
        "# تعریف purity\n",
        "def purity_score(dataset):\n",
        "    total = 0\n",
        "    for i in range(k):\n",
        "        cluster_labels = dataset[dataset[\"new_labels\"] == (i + 1)][\"labels\"]\n",
        "        if len(cluster_labels) > 0:\n",
        "            most_common = Counter(cluster_labels).most_common(1)[0][1]\n",
        "            total += most_common\n",
        "    return total / len(dataset)\n",
        "purity = purity_score(dataset)\n",
        "# تعریف f_measure\n",
        "def f_measure(dataset):\n",
        "    precision_list = []\n",
        "    recall_list = []\n",
        "    for i in range(k):\n",
        "        true_labels = dataset[\"labels\"].to_numpy()\n",
        "        predicted_labels = (dataset[\"new_labels\"] == (i + 1)).to_numpy()\n",
        "        tp = np.sum((true_labels[predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fp = np.sum((true_labels[predicted_labels] != dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fn = np.sum((true_labels[~predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        precision_list.append(precision)\n",
        "        recall_list.append(recall)\n",
        "    precision = np.mean(precision_list)\n",
        "    recall = np.mean(recall_list)\n",
        "    f_measure_value = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    return f_measure_value\n",
        "f_measure_value = f_measure(dataset)\n",
        "# زمان پایان\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(\"Purity:\", purity)\n",
        "print(\"F-measure:\", f_measure_value)\n",
        "print(\"Execution time:\", execution_time)\n",
        "print(\"Dataset with new labels:\")\n",
        "print(dataset[[\"x1\", \"x2\", \"labels\", \"new_labels\"]].head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###مفایسه الگوریتم"
      ],
      "metadata": {
        "id": "thSprW7JN2fs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import requests\n",
        "from io import StringIO\n",
        "import time\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics.pairwise import polynomial_kernel, rbf_kernel\n",
        "from scipy.sparse.linalg import eigsh\n",
        "\n",
        "# بارگذاری داده‌ها\n",
        "link = [\"http://cs.joensuu.fi/sipu/datasets/jain.txt\"]\n",
        "numbers = []\n",
        "read = requests.get(link[0])\n",
        "content = read.text\n",
        "data = StringIO(content)\n",
        "df = pd.read_csv(data, sep=\"\\s+\", header=None, names=[\"x1\", \"x2\", \"labels\"])\n",
        "numbers.append(df)\n",
        "dataset = pd.concat(numbers, ignore_index=True)\n",
        "k=2\n",
        "l=9\n",
        "\n",
        "# تعریف تابع k_median\n",
        "def k_median(data, k, max_iterations=200):\n",
        "    centers = data.sample(n=k, random_state=42).to_numpy()\n",
        "    for _ in range(max_iterations):\n",
        "        distances = np.linalg.norm(data.to_numpy()[:, np.newaxis] - centers, axis=2)\n",
        "        labels = np.argmin(distances, axis=1)\n",
        "        new_centers = np.array([np.median(data[labels == i].to_numpy(), axis=0) for i in range(k)])\n",
        "        if np.all(centers == new_centers):\n",
        "            break\n",
        "        centers = new_centers\n",
        "    return centers, labels\n",
        "\n",
        "# نسخه دوم k_median (با فواصل مشابه نسخه اول شما)\n",
        "def k_median2(data, k, max_iterations=200):\n",
        "    centers = data.sample(n=k, random_state=42).to_numpy()\n",
        "    for _ in range(max_iterations):\n",
        "        distances = np.linalg.norm(data.to_numpy()[:, np.newaxis] - centers, axis=2)\n",
        "        labels = np.argmin(distances, axis=1)\n",
        "        for i in range(0, k, 2):\n",
        "            if i < k and np.any(labels == i):\n",
        "                centers[i] = data.iloc[labels == i].median(axis=0).to_numpy()\n",
        "            if i + 1 < k and np.any(labels == (i + 1)):\n",
        "                centers[i + 1] = data.iloc[labels == (i + 1)].median(axis=0).to_numpy()\n",
        "        if np.allclose(centers, centers.mean(axis=0)):\n",
        "            break\n",
        "    return centers, labels\n",
        "\n",
        "# K-Median با کرنل چندجمله‌ای\n",
        "def k_median_polynomial(data, k, max_iterations=200):\n",
        "    centers = data.sample(n=k, random_state=42).to_numpy()\n",
        "    for _ in range(max_iterations):\n",
        "        similarity_matrix = polynomial_kernel(data, centers)\n",
        "        labels = np.argmax(similarity_matrix, axis=1)\n",
        "        new_centers = []\n",
        "        for i in range(k):\n",
        "            cluster_points = data.iloc[np.where(labels == i)]\n",
        "            if len(cluster_points) > 0:\n",
        "                new_centers.append(cluster_points.median(axis=0).to_numpy())\n",
        "            else:\n",
        "                new_centers.append(data.sample(n=1, random_state=42).to_numpy().flatten())\n",
        "        new_centers = np.array(new_centers)\n",
        "        if np.allclose(centers, new_centers, atol=1e-4):\n",
        "            break\n",
        "        centers = new_centers\n",
        "    return centers, labels\n",
        "\n",
        "# K-Median با کرنل گوسی\n",
        "def k_median_rbf(data, k, max_iterations=100, gamma=0.5):\n",
        "    centers = data.sample(n=k, random_state=42).to_numpy()\n",
        "    for _ in range(max_iterations):\n",
        "        similarity_matrix = rbf_kernel(data, centers, gamma=gamma)\n",
        "        labels = np.argmax(similarity_matrix, axis=1)\n",
        "        new_centers = np.array([data[labels == i].median(axis=0) for i in range(k)])\n",
        "        if np.allclose(centers, new_centers):\n",
        "            break\n",
        "        centers = new_centers\n",
        "    return centers, labels\n",
        "\n",
        "# خوشه‌بندی طیفی\n",
        "def spectral_clustering(data, k):\n",
        "    adjacency_matrix = kneighbors_graph(data, n_neighbors=l, mode='connectivity', include_self=False).toarray()\n",
        "    weight_matrix = adjacency_matrix * adjacency_matrix.T\n",
        "    degree_matrix = np.diag(weight_matrix.sum(axis=1))\n",
        "    laplacian_matrix = degree_matrix - weight_matrix\n",
        "    eigvals, eigvecs = eigsh(laplacian_matrix, k=l, which='SM')\n",
        "    kmeans = KMeans(n_clusters=k)\n",
        "    labels = kmeans.fit_predict(eigvecs)\n",
        "    return labels\n",
        "\n",
        "# محاسبه Purity\n",
        "def purity_score(dataset):\n",
        "    total = 0\n",
        "    for i in range(k):\n",
        "        cluster_labels = dataset[dataset[\"new_labels\"] == (i + 1)][\"labels\"]\n",
        "        if len(cluster_labels) > 0:\n",
        "            most_common = Counter(cluster_labels).most_common(1)[0][1]\n",
        "            total += most_common\n",
        "    return total / len(dataset)\n",
        "\n",
        "# محاسبه F-measure\n",
        "def f_measure(dataset):\n",
        "    precision_list = []\n",
        "    recall_list = []\n",
        "    for i in range(k):\n",
        "        true_labels = dataset[\"labels\"].to_numpy()\n",
        "        predicted_labels = (dataset[\"new_labels\"] == (i + 1)).to_numpy()\n",
        "        tp = np.sum((true_labels[predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fp = np.sum((true_labels[predicted_labels] != dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fn = np.sum((true_labels[~predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        precision_list.append(precision)\n",
        "        recall_list.append(recall)\n",
        "    precision = np.mean(precision_list)\n",
        "    recall = np.mean(recall_list)\n",
        "    f_measure_value = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    return f_measure_value\n",
        "\n",
        "# اجرای الگوریتم‌ها\n",
        "def run_algorithm(algorithm, dataset, k):\n",
        "    start_time = time.time()\n",
        "    if algorithm == spectral_clustering:\n",
        "        labels = algorithm(dataset[[\"x1\", \"x2\"]], k)\n",
        "        centers = None\n",
        "    else:\n",
        "        centers, labels = algorithm(dataset[[\"x1\", \"x2\"]], k)\n",
        "    labels += 1\n",
        "    dataset[\"new_labels\"] = labels\n",
        "    purity = purity_score(dataset)\n",
        "    f_measure_value = f_measure(dataset)\n",
        "    end_time = time.time()\n",
        "    execution_time = end_time - start_time\n",
        "    return purity, f_measure_value, execution_time, dataset\n",
        "\n",
        "# نتایج\n",
        "results = []\n",
        "algorithms = [k_median, k_median2, spectral_clustering, k_median_polynomial, k_median_rbf]\n",
        "for algorithm in algorithms:\n",
        "    purity, f_measure_value, execution_time, dataset_with_labels = run_algorithm(algorithm, dataset.copy(), k)\n",
        "    results.append({\n",
        "        \"Algorithm\": algorithm.__name__,\n",
        "        \"Purity\": purity,\n",
        "        \"F-measure\": f_measure_value,\n",
        "        \"Execution Time\": execution_time\n",
        "    })\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "# مقایسه نتایج\n",
        "print(\"مقایسه نتایج الگوریتم‌ها:\")\n",
        "print(results_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjVPmqZANdjp",
        "outputId": "eef5bf3d-7fc1-4cf5-9672-93d354059377"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "مقایسه نتایج الگوریتم‌ها:\n",
            "             Algorithm    Purity  F-measure  Execution Time\n",
            "0             k_median  0.753351   0.197849        0.023755\n",
            "1            k_median2  0.753351   0.197849        0.608602\n",
            "2  spectral_clustering  0.739946   0.740905        0.194289\n",
            "3  k_median_polynomial  0.916890   0.108280        0.042042\n",
            "4         k_median_rbf  0.753351   0.197849        0.046003\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I4myjS5om7cW"
      },
      "outputs": [],
      "source": [
        "########################## انجام الگوریتم ها در تکست هشتم(flame.txt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qOEBxsaqnGUL"
      },
      "outputs": [],
      "source": [
        "\n",
        "###################با جابه جایی یکی از مراکز با نقاط داده k_median"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSJhItK3nKQe",
        "outputId": "f5aaaccf-26c7-4a0f-c6e4-42475b84ab01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Purity: 0.85\n",
            "F-measure: 0.1400029726977676\n",
            "Execution time: 0.030186891555786133\n",
            "Dataset with new labels:\n",
            "     x1     x2  labels  new_labels\n",
            "0  1.85  27.80       1           2\n",
            "1  1.35  26.65       1           2\n",
            "2  1.40  23.25       2           2\n",
            "3  0.85  23.05       2           2\n",
            "4  0.50  22.35       2           2\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import requests\n",
        "from io import StringIO\n",
        "import time\n",
        "# بارگذاری داده‌ها\n",
        "link= [\"http://cs.joensuu.fi/sipu/datasets/flame.txt\"]\n",
        "numbers = []\n",
        "read = requests.get(link[0])\n",
        "content = read.text\n",
        "data = StringIO(content)\n",
        "df = pd.read_csv(data, sep=\"\\s+\", header=None, names=[\"x1\", \"x2\", \"labels\"])\n",
        "numbers.append(df)\n",
        "dataset = pd.concat(numbers, ignore_index=True)\n",
        "# تعریف تابع k_media\n",
        "def k_median(data, k, max_iterations=200):\n",
        "    centers = data.sample(n=k, random_state=42).to_numpy()\n",
        "    for _ in range(max_iterations):\n",
        "        distances = np.linalg.norm(data.to_numpy()[:, np.newaxis] - centers, axis=2)\n",
        "        labels = np.argmin(distances, axis=1)\n",
        "        new_centers = np.array([np.median(data[labels == i].to_numpy(), axis=0) for i in range(k)])\n",
        "        if np.all(centers == new_centers):\n",
        "            break\n",
        "        centers = new_centers\n",
        "    return centers, labels\n",
        "k=2\n",
        "# زمان شروع\n",
        "start_time = time.time()\n",
        "centers, labels = k_median(dataset[[\"x1\", \"x2\"]], k)\n",
        "labels += 1\n",
        "dataset[\"new_labels\"] = labels\n",
        "# تعریف purity\n",
        "def purity_score(dataset):\n",
        "    total = 0\n",
        "    for i in range(k):\n",
        "        cluster_labels = dataset[dataset[\"new_labels\"] == (i + 1)][\"labels\"]\n",
        "        if len(cluster_labels) > 0:\n",
        "            most_common = Counter(cluster_labels).most_common(1)[0][1]\n",
        "            total += most_common\n",
        "    return total / len(dataset)\n",
        "purity = purity_score(dataset)\n",
        "# تعریف f_measure\n",
        "def f_measure(dataset):\n",
        "    precision_list = []\n",
        "    recall_list = []\n",
        "    for i in range(k):\n",
        "        true_labels = dataset[\"labels\"].to_numpy()\n",
        "        predicted_labels = (dataset[\"new_labels\"] == (i + 1)).to_numpy()\n",
        "        tp = np.sum((true_labels[predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fp = np.sum((true_labels[predicted_labels] != dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fn = np.sum((true_labels[~predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        precision_list.append(precision)\n",
        "        recall_list.append(recall)\n",
        "    precision = np.mean(precision_list)\n",
        "    recall = np.mean(recall_list)\n",
        "    f_measure_value = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    return f_measure_value\n",
        "f_measure_value = f_measure(dataset)\n",
        "#زمان پابان\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(\"Purity:\", purity)\n",
        "print(\"F-measure:\", f_measure_value)\n",
        "print(\"Execution time:\", execution_time)\n",
        "print(\"Dataset with new labels:\")\n",
        "print(dataset[[\"x1\", \"x2\", \"labels\", \"new_labels\"]].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z7Ty3ENXnXcZ"
      },
      "outputs": [],
      "source": [
        "###################### با جابه جایی دو تا از مراکز با نقاط داده k_median محاسبه"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5uVtXkfnZ1b",
        "outputId": "5092f9c0-3d94-4768-e0c4-48bda83416d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Purity: 0.85\n",
            "F-measure: 0.1400029726977676\n",
            "Execution time: 0.5584278106689453\n",
            "Dataset with new labels:\n",
            "     x1     x2  labels  new_labels\n",
            "0  1.85  27.80       1           2\n",
            "1  1.35  26.65       1           2\n",
            "2  1.40  23.25       2           2\n",
            "3  0.85  23.05       2           2\n",
            "4  0.50  22.35       2           2\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import requests\n",
        "from io import StringIO\n",
        "import time\n",
        "# بارگذاری داده‌ها\n",
        "link = [\"http://cs.joensuu.fi/sipu/datasets/flame.txt\"]\n",
        "numbers = []\n",
        "read = requests.get(link[0])\n",
        "content = read.text\n",
        "data = StringIO(content)\n",
        "df = pd.read_csv(data, sep=\"\\s+\", header=None, names=[\"x1\", \"x2\", \"labels\"])\n",
        "numbers.append(df)\n",
        "dataset = pd.concat(numbers, ignore_index=True)\n",
        "# تعریف تابع k_median\n",
        "def k_median(data, k, max_iterations=200):\n",
        "    centers = data.sample(n=k, random_state=42).to_numpy()\n",
        "    for _ in range(max_iterations):\n",
        "        distances = np.linalg.norm(data.to_numpy()[:, np.newaxis] - centers, axis=2)\n",
        "        labels = np.argmin(distances, axis=1)\n",
        "        for i in range(0, k, 2):\n",
        "            if i < k and np.any(labels == i):\n",
        "                centers[i] = data.iloc[labels == i].median(axis=0).to_numpy()\n",
        "            if i + 1 < k and np.any(labels == (i + 1)):\n",
        "                centers[i + 1] = data.iloc[labels == (i + 1)].median(axis=0).to_numpy()\n",
        "        if np.allclose(centers, centers.mean(axis=0)):\n",
        "            break\n",
        "    return centers, labels\n",
        "k =2\n",
        "# زمان شروع\n",
        "start_time = time.time()\n",
        "centers, labels = k_median(dataset[[\"x1\", \"x2\"]], k)\n",
        "labels += 1\n",
        "dataset[\"new_labels\"] = labels\n",
        "# تعریف purity\n",
        "def purity_score(dataset):\n",
        "    total = 0\n",
        "    for i in range(k):\n",
        "        cluster_labels = dataset[dataset[\"new_labels\"] == (i + 1)][\"labels\"]\n",
        "        if len(cluster_labels) > 0:\n",
        "            most_common = Counter(cluster_labels).most_common(1)[0][1]\n",
        "            total += most_common\n",
        "    return total / len(dataset)\n",
        "purity = purity_score(dataset)\n",
        "# تعریف f_measure\n",
        "def f_measure(dataset):\n",
        "    precision_list = []\n",
        "    recall_list = []\n",
        "    for i in range(k):\n",
        "        true_labels = dataset[\"labels\"].to_numpy()\n",
        "        predicted_labels = (dataset[\"new_labels\"] == (i + 1)).to_numpy()\n",
        "        tp = np.sum((true_labels[predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fp = np.sum((true_labels[predicted_labels] != dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fn = np.sum((true_labels[~predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        precision_list.append(precision)\n",
        "        recall_list.append(recall)\n",
        "    precision = np.mean(precision_list)\n",
        "    recall = np.mean(recall_list)\n",
        "    f_measure_value = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    return f_measure_value\n",
        "f_measure_value = f_measure(dataset)\n",
        "# زمان پایان\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(\"Purity:\", purity)\n",
        "print(\"F-measure:\", f_measure_value)\n",
        "print(\"Execution time:\", execution_time)\n",
        "print(\"Dataset with new labels:\")\n",
        "print(dataset[[\"x1\", \"x2\", \"labels\", \"new_labels\"]].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IxlrG7lWnlg4"
      },
      "outputs": [],
      "source": [
        "#################با کرنل دو جمله ای k_median محاسبه"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPEewxDWn1BD",
        "outputId": "301bbd9f-11f0-43b5-f851-1b66deb3d572"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Purity: 0.6375\n",
            "F-measure: 0.3893129770992366\n",
            "Execution time: 0.011703014373779297\n",
            "Dataset with new labels:\n",
            "     x1     x2  labels  new_labels\n",
            "0  1.85  27.80       1           2\n",
            "1  1.35  26.65       1           2\n",
            "2  1.40  23.25       2           2\n",
            "3  0.85  23.05       2           2\n",
            "4  0.50  22.35       2           2\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import requests\n",
        "from io import StringIO\n",
        "import time\n",
        "from sklearn.metrics.pairwise import polynomial_kernel\n",
        "\n",
        "# بارگذاری داده‌ها\n",
        "link = [\"http://cs.joensuu.fi/sipu/datasets/flame.txt\"]\n",
        "numbers = []\n",
        "read = requests.get(link[0])\n",
        "content = read.text\n",
        "data = StringIO(content)\n",
        "df = pd.read_csv(data, sep=\"\\s+\", header=None, names=[\"x1\", \"x2\", \"labels\"])\n",
        "numbers.append(df)\n",
        "dataset = pd.concat(numbers, ignore_index=True)\n",
        "# تعریف تابع k_median_polynomial\n",
        "def k_median_polynomial(data, k, max_iterations=200):\n",
        "    centers = data.sample(n=k, random_state=42).to_numpy()\n",
        "    for _ in range(max_iterations):\n",
        "        similarity_matrix = polynomial_kernel(data, centers)\n",
        "        labels = np.argmax(similarity_matrix, axis=1)\n",
        "        new_centers = []\n",
        "        for i in range(k):\n",
        "            cluster_points = data.iloc[np.where(labels == i)]\n",
        "            if len(cluster_points) > 0:\n",
        "                new_centers.append(cluster_points.median(axis=0).to_numpy())\n",
        "            else:\n",
        "                new_centers.append(data.sample(n=1, random_state=42).to_numpy().flatten())\n",
        "        new_centers = np.array(new_centers)\n",
        "        if np.allclose(centers, new_centers, atol=1e-4):\n",
        "            break\n",
        "        centers = new_centers\n",
        "    return centers, labels\n",
        "\n",
        "k = 2\n",
        "# زمان شروع\n",
        "start_time = time.time()\n",
        "centers, labels = k_median_polynomial(dataset[[\"x1\", \"x2\"]], k)\n",
        "labels += 1\n",
        "dataset[\"new_labels\"] = labels\n",
        "# تعریف purity\n",
        "def purity_score(dataset):\n",
        "    total = 0\n",
        "    for i in range(k):\n",
        "        cluster_labels = dataset[dataset[\"new_labels\"] == (i + 1)][\"labels\"]\n",
        "        if len(cluster_labels) > 0:\n",
        "            most_common = Counter(cluster_labels).most_common(1)[0][1]\n",
        "            total += most_common\n",
        "    return total / len(dataset)\n",
        "\n",
        "purity = purity_score(dataset)\n",
        "\n",
        "# تعریف f_measure\n",
        "def f_measure(dataset):\n",
        "    precision_list = []\n",
        "    recall_list = []\n",
        "    for i in range(k):\n",
        "        true_labels = dataset[\"labels\"].to_numpy()\n",
        "        predicted_labels = (dataset[\"new_labels\"] == (i + 1)).to_numpy()\n",
        "        tp = np.sum((true_labels[predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fp = np.sum((true_labels[predicted_labels] != dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fn = np.sum((true_labels[~predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        precision_list.append(precision)\n",
        "        recall_list.append(recall)\n",
        "\n",
        "    precision = np.mean(precision_list)\n",
        "    recall = np.mean(recall_list)\n",
        "    f_measure_value = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    return f_measure_value\n",
        "\n",
        "f_measure_value = f_measure(dataset)\n",
        "\n",
        "# زمان پایان\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "\n",
        "print(\"Purity:\", purity)\n",
        "print(\"F-measure:\", f_measure_value)\n",
        "print(\"Execution time:\", execution_time)\n",
        "print(\"Dataset with new labels:\")\n",
        "print(dataset[[\"x1\", \"x2\", \"labels\", \"new_labels\"]].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HN-W2oHloEnP"
      },
      "outputs": [],
      "source": [
        "#################با کرنل  گوسی k_median محاسبه"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKe7VlJHn-GA",
        "outputId": "0c77381d-6688-4a0a-acb7-a9933e6e61a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Purity: 0.85\n",
            "F-measure: 0.1400029726977676\n",
            "Execution time: 0.02628326416015625\n",
            "Dataset with new labels:\n",
            "     x1     x2  labels  new_labels\n",
            "0  1.85  27.80       1           2\n",
            "1  1.35  26.65       1           2\n",
            "2  1.40  23.25       2           2\n",
            "3  0.85  23.05       2           2\n",
            "4  0.50  22.35       2           2\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import requests\n",
        "from io import StringIO\n",
        "import time\n",
        "from sklearn.metrics.pairwise import rbf_kernel\n",
        "\n",
        "# بارگذاری داده‌ها\n",
        "link = [\"http://cs.joensuu.fi/sipu/datasets/flame.txt\"]\n",
        "numbers = []\n",
        "read = requests.get(link[0])\n",
        "content = read.text\n",
        "data = StringIO(content)\n",
        "df = pd.read_csv(data, sep=\"\\s+\", header=None, names=[\"x1\", \"x2\", \"labels\"])\n",
        "numbers.append(df)\n",
        "dataset = pd.concat(numbers, ignore_index=True)\n",
        "\n",
        "# تعریف تابع k_median\n",
        "def k_median_rbf(data, k, max_iterations=100, gamma=0.5):\n",
        "    centers = data.sample(n=k, random_state=42).to_numpy()\n",
        "    for _ in range(max_iterations):\n",
        "        similarity_matrix = rbf_kernel(data.to_numpy(), centers, gamma=gamma)\n",
        "        labels = np.argmax(similarity_matrix, axis=1)\n",
        "        new_centers = []\n",
        "        for i in range(k):\n",
        "            cluster_points = data.iloc[np.where(labels == i)]\n",
        "            if len(cluster_points) > 0:\n",
        "                new_centers.append(cluster_points.median(axis=0).to_numpy())\n",
        "            else:\n",
        "                new_centers.append(data.sample(n=1, random_state=42).to_numpy().flatten())\n",
        "        new_centers = np.array(new_centers)\n",
        "        if np.allclose(centers, new_centers, atol=1e-4):\n",
        "            break\n",
        "        centers = new_centers\n",
        "    return centers, labels\n",
        "\n",
        "k = 2\n",
        "\n",
        "# زمان شروع\n",
        "start_time = time.time()\n",
        "centers, labels = k_median_rbf(dataset[[\"x1\", \"x2\"]], k)\n",
        "labels += 1\n",
        "dataset[\"new_labels\"] = labels\n",
        "\n",
        "# تعریف purity\n",
        "def purity_score(dataset):\n",
        "    total = 0\n",
        "    for i in range(k):\n",
        "        cluster_labels = dataset[dataset[\"new_labels\"] == (i + 1)][\"labels\"]\n",
        "        if len(cluster_labels) > 0:\n",
        "            most_common = Counter(cluster_labels).most_common(1)[0][1]\n",
        "            total += most_common\n",
        "    return total / len(dataset)\n",
        "\n",
        "purity = purity_score(dataset)\n",
        "\n",
        "# تعریف f_measure\n",
        "def f_measure(dataset):\n",
        "    precision_list = []\n",
        "    recall_list = []\n",
        "    for i in range(k):\n",
        "        true_labels = dataset[\"labels\"].to_numpy()\n",
        "        predicted_labels = dataset[\"new_labels\"].to_numpy()\n",
        "        tp = np.sum((true_labels == i + 1) & (predicted_labels == i + 1))\n",
        "        fp = np.sum((true_labels != i + 1) & (predicted_labels == i + 1))\n",
        "        fn = np.sum((true_labels == i + 1) & (predicted_labels != i + 1))\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        precision_list.append(precision)\n",
        "        recall_list.append(recall)\n",
        "    precision = np.mean(precision_list)\n",
        "    recall = np.mean(recall_list)\n",
        "    f_measure_value = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    return f_measure_value\n",
        "\n",
        "f_measure_value = f_measure(dataset)\n",
        "\n",
        "# زمان پایان\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "\n",
        "print(\"Purity:\", purity)\n",
        "print(\"F-measure:\", f_measure_value)\n",
        "print(\"Execution time:\", execution_time)\n",
        "print(\"Dataset with new labels:\")\n",
        "print(dataset[[\"x1\", \"x2\", \"labels\", \"new_labels\"]].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g6-G27G_oNur"
      },
      "outputs": [],
      "source": [
        "#################         الگوریتم خوشه بندی طیفی"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bB_-SDDNoRl5",
        "outputId": "9aeca05e-98ee-4b25-f733-d321efe14fa4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Purity: 0.6375\n",
            "F-measure: 0.5555089400555338\n",
            "Execution time: 0.1491241455078125\n",
            "Dataset with new labels:\n",
            "     x1     x2  labels  new_labels\n",
            "0  1.85  27.80       1           1\n",
            "1  1.35  26.65       1           1\n",
            "2  1.40  23.25       2           1\n",
            "3  0.85  23.05       2           1\n",
            "4  0.50  22.35       2           1\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import requests\n",
        "from io import StringIO\n",
        "import time\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "from sklearn.cluster import KMeans\n",
        "from scipy.sparse.linalg import eigsh\n",
        "# بارگذاری داده‌ها\n",
        "link = [\"http://cs.joensuu.fi/sipu/datasets/flame.txt\"]\n",
        "numbers = []\n",
        "read = requests.get(link[0])\n",
        "content = read.text\n",
        "data = StringIO(content)\n",
        "df = pd.read_csv(data, sep=\"\\s+\", header=None, names=[\"x1\", \"x2\", \"labels\"])\n",
        "numbers.append(df)\n",
        "dataset = pd.concat(numbers, ignore_index=True)\n",
        "# تابع خوشه‌بندی طیفی\n",
        "def spectral_clustering(data, k):\n",
        "    adjacency_matrix = kneighbors_graph(data, n_neighbors=l, mode='connectivity', include_self=False).toarray()\n",
        "    weight_matrix = adjacency_matrix * adjacency_matrix.T\n",
        "    degree_matrix = np.diag(weight_matrix.sum(axis=1))\n",
        "    laplacian_matrix = degree_matrix - weight_matrix\n",
        "    eigvals, eigvecs = eigsh(laplacian_matrix, k=l, which='SM')\n",
        "    kmeans = KMeans(n_clusters=k)\n",
        "    labels = kmeans.fit_predict(eigvecs)\n",
        "    return labels\n",
        "l=9\n",
        "k =2\n",
        "# زمان شروع\n",
        "start_time = time.time()\n",
        "labels = spectral_clustering(dataset[[\"x1\", \"x2\"]], k)\n",
        "labels += 1\n",
        "dataset[\"new_labels\"] = labels\n",
        "# تعریف purity\n",
        "def purity_score(dataset):\n",
        "    total = 0\n",
        "    for i in range(k):\n",
        "        cluster_labels = dataset[dataset[\"new_labels\"] == (i + 1)][\"labels\"]\n",
        "        if len(cluster_labels) > 0:\n",
        "            most_common = Counter(cluster_labels).most_common(1)[0][1]\n",
        "            total += most_common\n",
        "    return total / len(dataset)\n",
        "purity = purity_score(dataset)\n",
        "# تعریف f_measure\n",
        "def f_measure(dataset):\n",
        "    precision_list = []\n",
        "    recall_list = []\n",
        "    for i in range(k):\n",
        "        true_labels = dataset[\"labels\"].to_numpy()\n",
        "        predicted_labels = (dataset[\"new_labels\"] == (i + 1)).to_numpy()\n",
        "        tp = np.sum((true_labels[predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fp = np.sum((true_labels[predicted_labels] != dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fn = np.sum((true_labels[~predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        precision_list.append(precision)\n",
        "        recall_list.append(recall)\n",
        "    precision = np.mean(precision_list)\n",
        "    recall = np.mean(recall_list)\n",
        "    f_measure_value = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    return f_measure_value\n",
        "f_measure_value = f_measure(dataset)\n",
        "# زمان پایان\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(\"Purity:\", purity)\n",
        "print(\"F-measure:\", f_measure_value)\n",
        "print(\"Execution time:\", execution_time)\n",
        "print(\"Dataset with new labels:\")\n",
        "print(dataset[[\"x1\", \"x2\", \"labels\", \"new_labels\"]].head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import requests\n",
        "from io import StringIO\n",
        "import time\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics.pairwise import polynomial_kernel, rbf_kernel\n",
        "from scipy.sparse.linalg import eigsh\n",
        "\n",
        "# بارگذاری داده‌ها\n",
        "link = [\"http://cs.joensuu.fi/sipu/datasets/flame.txt\"]\n",
        "numbers = []\n",
        "read = requests.get(link[0])\n",
        "content = read.text\n",
        "data = StringIO(content)\n",
        "df = pd.read_csv(data, sep=\"\\s+\", header=None, names=[\"x1\", \"x2\", \"labels\"])\n",
        "numbers.append(df)\n",
        "dataset = pd.concat(numbers, ignore_index=True)\n",
        "k=2\n",
        "l=9\n",
        "\n",
        "# تعریف تابع k_median\n",
        "def k_median(data, k, max_iterations=200):\n",
        "    centers = data.sample(n=k, random_state=42).to_numpy()\n",
        "    for _ in range(max_iterations):\n",
        "        distances = np.linalg.norm(data.to_numpy()[:, np.newaxis] - centers, axis=2)\n",
        "        labels = np.argmin(distances, axis=1)\n",
        "        new_centers = np.array([np.median(data[labels == i].to_numpy(), axis=0) for i in range(k)])\n",
        "        if np.all(centers == new_centers):\n",
        "            break\n",
        "        centers = new_centers\n",
        "    return centers, labels\n",
        "\n",
        "# نسخه دوم k_median (با فواصل مشابه نسخه اول شما)\n",
        "def k_median2(data, k, max_iterations=200):\n",
        "    centers = data.sample(n=k, random_state=42).to_numpy()\n",
        "    for _ in range(max_iterations):\n",
        "        distances = np.linalg.norm(data.to_numpy()[:, np.newaxis] - centers, axis=2)\n",
        "        labels = np.argmin(distances, axis=1)\n",
        "        for i in range(0, k, 2):\n",
        "            if i < k and np.any(labels == i):\n",
        "                centers[i] = data.iloc[labels == i].median(axis=0).to_numpy()\n",
        "            if i + 1 < k and np.any(labels == (i + 1)):\n",
        "                centers[i + 1] = data.iloc[labels == (i + 1)].median(axis=0).to_numpy()\n",
        "        if np.allclose(centers, centers.mean(axis=0)):\n",
        "            break\n",
        "    return centers, labels\n",
        "\n",
        "# K-Median با کرنل چندجمله‌ای\n",
        "def k_median_polynomial(data, k, max_iterations=200):\n",
        "    centers = data.sample(n=k, random_state=42).to_numpy()\n",
        "    for _ in range(max_iterations):\n",
        "        similarity_matrix = polynomial_kernel(data, centers)\n",
        "        labels = np.argmax(similarity_matrix, axis=1)\n",
        "        new_centers = []\n",
        "        for i in range(k):\n",
        "            cluster_points = data.iloc[np.where(labels == i)]\n",
        "            if len(cluster_points) > 0:\n",
        "                new_centers.append(cluster_points.median(axis=0).to_numpy())\n",
        "            else:\n",
        "                new_centers.append(data.sample(n=1, random_state=42).to_numpy().flatten())\n",
        "        new_centers = np.array(new_centers)\n",
        "        if np.allclose(centers, new_centers, atol=1e-4):\n",
        "            break\n",
        "        centers = new_centers\n",
        "    return centers, labels\n",
        "\n",
        "# K-Median با کرنل گوسی\n",
        "def k_median_rbf(data, k, max_iterations=100, gamma=0.5):\n",
        "    centers = data.sample(n=k, random_state=42).to_numpy()\n",
        "    for _ in range(max_iterations):\n",
        "        similarity_matrix = rbf_kernel(data, centers, gamma=gamma)\n",
        "        labels = np.argmax(similarity_matrix, axis=1)\n",
        "        new_centers = np.array([data[labels == i].median(axis=0) for i in range(k)])\n",
        "        if np.allclose(centers, new_centers):\n",
        "            break\n",
        "        centers = new_centers\n",
        "    return centers, labels\n",
        "\n",
        "# خوشه‌بندی طیفی\n",
        "def spectral_clustering(data, k):\n",
        "    adjacency_matrix = kneighbors_graph(data, n_neighbors=l, mode='connectivity', include_self=False).toarray()\n",
        "    weight_matrix = adjacency_matrix * adjacency_matrix.T\n",
        "    degree_matrix = np.diag(weight_matrix.sum(axis=1))\n",
        "    laplacian_matrix = degree_matrix - weight_matrix\n",
        "    eigvals, eigvecs = eigsh(laplacian_matrix, k=l, which='SM')\n",
        "    kmeans = KMeans(n_clusters=k)\n",
        "    labels = kmeans.fit_predict(eigvecs)\n",
        "    return labels\n",
        "\n",
        "# محاسبه Purity\n",
        "def purity_score(dataset):\n",
        "    total = 0\n",
        "    for i in range(k):\n",
        "        cluster_labels = dataset[dataset[\"new_labels\"] == (i + 1)][\"labels\"]\n",
        "        if len(cluster_labels) > 0:\n",
        "            most_common = Counter(cluster_labels).most_common(1)[0][1]\n",
        "            total += most_common\n",
        "    return total / len(dataset)\n",
        "\n",
        "# محاسبه F-measure\n",
        "def f_measure(dataset):\n",
        "    precision_list = []\n",
        "    recall_list = []\n",
        "    for i in range(k):\n",
        "        true_labels = dataset[\"labels\"].to_numpy()\n",
        "        predicted_labels = (dataset[\"new_labels\"] == (i + 1)).to_numpy()\n",
        "        tp = np.sum((true_labels[predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fp = np.sum((true_labels[predicted_labels] != dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        fn = np.sum((true_labels[~predicted_labels] == dataset[\"labels\"].unique()[i]).astype(int))\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        precision_list.append(precision)\n",
        "        recall_list.append(recall)\n",
        "    precision = np.mean(precision_list)\n",
        "    recall = np.mean(recall_list)\n",
        "    f_measure_value = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    return f_measure_value\n",
        "\n",
        "# اجرای الگوریتم‌ها\n",
        "def run_algorithm(algorithm, dataset, k):\n",
        "    start_time = time.time()\n",
        "    if algorithm == spectral_clustering:\n",
        "        labels = algorithm(dataset[[\"x1\", \"x2\"]], k)\n",
        "        centers = None\n",
        "    else:\n",
        "        centers, labels = algorithm(dataset[[\"x1\", \"x2\"]], k)\n",
        "    labels += 1\n",
        "    dataset[\"new_labels\"] = labels\n",
        "    purity = purity_score(dataset)\n",
        "    f_measure_value = f_measure(dataset)\n",
        "    end_time = time.time()\n",
        "    execution_time = end_time - start_time\n",
        "    return purity, f_measure_value, execution_time, dataset\n",
        "\n",
        "# نتایج\n",
        "results = []\n",
        "algorithms = [k_median, k_median2, spectral_clustering, k_median_polynomial, k_median_rbf]\n",
        "for algorithm in algorithms:\n",
        "    purity, f_measure_value, execution_time, dataset_with_labels = run_algorithm(algorithm, dataset.copy(), k)\n",
        "    results.append({\n",
        "        \"Algorithm\": algorithm.__name__,\n",
        "        \"Purity\": purity,\n",
        "        \"F-measure\": f_measure_value,\n",
        "        \"Execution Time\": execution_time\n",
        "    })\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "# مقایسه نتایج\n",
        "print(\"مقایسه نتایج الگوریتم‌ها:\")\n",
        "print(results_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZifn8gvN_lE",
        "outputId": "199125b1-a609-499b-c929-f411162f4b6b"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "مقایسه نتایج الگوریتم‌ها:\n",
            "             Algorithm    Purity  F-measure  Execution Time\n",
            "0             k_median  0.850000   0.140003        0.041200\n",
            "1            k_median2  0.850000   0.140003        0.512567\n",
            "2  spectral_clustering  0.820833   0.803947        0.082193\n",
            "3  k_median_polynomial  0.637500   0.389313        0.027694\n",
            "4         k_median_rbf  0.850000   0.140003        0.070983\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IBKgYHnysZ-x"
      },
      "outputs": [],
      "source": [
        "#############purity , fmeasure,محاسبات نشان میدهد که از لحاظ معیارهای زمان اجرا\n",
        "#نزدیکترین همسایه برای تشکیل گراف را خودمان مشخص کنیم .و این مورد منجر به بهبود عملکرد الگوریتم میشود بنیابراین میتوان گفت که عموما الگوریتم خوشه بندی طیفی در سناریوهای مختلف بهتر عمل میکندk الگوریتم خوشه بندی طیفی عملکرد بهتری دارد همچنین به"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-3uxhEcwxLI"
      },
      "outputs": [],
      "source": [
        "####وقتی تعداد خوشه ها زیاد میشود زمان اجرای خوشه بندی طیفی زیاد میشود"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}